{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baby Name Generator using simple RNN and Keras package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = pd.read_csv('names.txt',header=None)\n",
    "names_df.rename(columns={0:'input'},inplace=True)\n",
    "names_df['input'] = names_df['input'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>william</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>james</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input\n",
       "0     john\n",
       "1  william\n",
       "2    james\n",
       "3  charles\n",
       "4   george"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the start and end of a name using start(\\t) and end token(\\n)\n",
    "names_df['input'] = names_df['input'].apply(lambda x : '\\t' + x)\n",
    "names_df['target'] = names_df['input'].apply(lambda x : x[1:len(x)] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tjohn</td>\n",
       "      <td>john\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\twilliam</td>\n",
       "      <td>william\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\tjames</td>\n",
       "      <td>james\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\tcharles</td>\n",
       "      <td>charles\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\tgeorge</td>\n",
       "      <td>george\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input     target\n",
       "0     \\tjohn     john\\n\n",
       "1  \\twilliam  william\\n\n",
       "2    \\tjames    james\\n\n",
       "3  \\tcharles  charles\\n\n",
       "4   \\tgeorge   george\\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoding these values as numeric because machine learning models only accept numerical inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocabulary of Names dataset - set of all unique characters used in the dataset\n",
    "def get_vocabulary(names):  \n",
    "    # Define vocabulary to be set\n",
    "    all_chars=set()\n",
    "    \n",
    "    # Add the start and end token to the vocabulary\n",
    "    all_chars.add('\\t')\n",
    "    all_chars.add('\\n')  \n",
    "    \n",
    "    # Iterate for each name\n",
    "    for name in names:\n",
    "\n",
    "        # Iterate for each character of the name\n",
    "        for c in name:\n",
    "\n",
    "            if c not in all_chars:\n",
    "            # If the character is not in vocabulary, add it\n",
    "                all_chars.add(c)\n",
    "\n",
    "    # Return the vocabulary\n",
    "    return all_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27}\n",
      "{0: '\\t', 1: '\\n', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = get_vocabulary(names_df['input'])\n",
    "vocabulary_sorted = sorted(vocabulary)\n",
    "\n",
    "# character to integer mapping and integer to character mapping\n",
    "\n",
    "# Create the mapping of the vocabulary chars to integers\n",
    "char_to_idx = { char : idx for idx, char in enumerate(vocabulary_sorted) }\n",
    "# Create the mapping of the integers to vocabulary chars\n",
    "idx_to_char = { idx : char for idx, char in enumerate(vocabulary_sorted)}\n",
    "# Print the dictionaries\n",
    "print(char_to_idx)\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create input and target tensors - two tensors to encode the input and target sequences\n",
    "\n",
    "    - The input is a list containing all the names in the dataset.\n",
    "        - So, the first dimension of the input tensor will be the number of names in the dataset. Each name can be thought of as a string having length equal to the length of the longest name and each character in each name is a one-hot encoded vector of size vocabulary. \n",
    "        - So, the second and third dimensions of the input tensor will be the length of the longest name and the size of the vocabulary. \n",
    "        \n",
    "    - Similar is the case for the target tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of time-steps - length of longest name\n",
    "def get_max_len(names):\n",
    "    \"\"\"\n",
    "    Function to return length of the longest name.\n",
    "    Input: list of names\n",
    "    Output: length of the longest name\n",
    "    \"\"\"\n",
    "\n",
    "    # create a list to contain all the name lengths\n",
    "    length_list=[]\n",
    "\n",
    "    # Iterate over all names and save the name length in the list.]\n",
    "    for l in names:\n",
    "        length_list.append(len(l))\n",
    "\n",
    "    # Find the maximum length\n",
    "    max_len = np.max(length_list)\n",
    "\n",
    "    # return maximum length\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the length of longest name - time step\n",
    "max_len = get_max_len(names_df['input']) # Each name as a sequence of length maxlen\n",
    "\n",
    "\n",
    "# Initialize the input vector - 3-D vector of required shape for input\n",
    "input_data = np.zeros((len(names_df['input']), max_len+1, len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Initialize the target vector - 3-D vector of required shape for target\n",
    "target_data = np.zeros((len(names_df['input']), max_len+1, len(vocabulary)), dtype='float32')\n",
    "\n",
    "# The input and target tensors of appropriate shape containing all zeros\n",
    "# Now, we'll fill these with actual values. The input and target tensors contain all the names in the dataset. \n",
    "# Each name can be thought of as a string having length equal to the length of the longest name and each character \n",
    "# in each name is a one-hot encoded vector of size vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the vectors with data\n",
    "\n",
    "# Iterate for each name in the dataset\n",
    "for n_idx, name in enumerate(names_df['input']):\n",
    "  # Iterate over each character and convert it to a one-hot encoded vector\n",
    "  for c_idx, char in enumerate(name):\n",
    "    input_data[n_idx, c_idx, char_to_idx[char]] = 1\n",
    "\n",
    "# Iterate for each name in the dataset\n",
    "for n_idx, name in enumerate(names_df['target']):\n",
    "  # Iterate over each character and convert it to a one-hot encoded vector\n",
    "  for c_idx, char in enumerate(name):\n",
    "    target_data[n_idx, c_idx, char_to_idx[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Build and compile RNN using Keras\n",
    "      - Create Sequential Model\n",
    "      - Add RNN layer of 50 units, we are setting return sequences to true to make sure RNN outputs a sequence and not a single vector\n",
    "      - The output layer is then passed to a dense layer with softmax activation to generate the output \n",
    "          - The softmax activation predicts prob values for each char in the vocabulary\n",
    "          - The time distributed wrapper layer is used to make sure the dense layer can handle 3-dimensional input\n",
    "      - We can compile this model now using categorical cross-entropy loss and adam optimizer\n",
    "          - Categorical cross-entropy loss is used when we have more than two labels. Here the output will be a character from the vocabulary and so, the number of labels is the size of the vocabulary\n",
    "          - Adam is an advanced optimizer which converges faster\n",
    "          \n",
    "- We can verify the architecture of the model using the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Activation, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 13, 50)            3950      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 13, 28)            1428      \n",
      "=================================================================\n",
      "Total params: 5,378\n",
      "Trainable params: 5,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile RNN\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add SimpleRNN layer of 50 units\n",
    "model.add(SimpleRNN(50, input_shape=(max_len+1, len(vocabulary)), return_sequences=True))\n",
    "\n",
    "# Add a TimeDistributed Dense layer of size same as the vocabulary\n",
    "model.add(TimeDistributed(Dense(len(vocabulary), activation='softmax')))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the build RNN model\n",
    "    - Input and target vectors are 3-dimensional vectors whose first dimension is the number of samples or names in the datsset\n",
    "    - The second dimension is the number of time steps which we defined as the length of the longest name\n",
    "    - The third dimension is the size of the one-hot encoded vectors which is the size of the vocabulary\n",
    "    \n",
    "- We need to use these vectors to train the model we built\n",
    "\n",
    "- Keras fit to train the model. We need to pass the input and the target data. In addition, we need to specify the batch size and the number of epochs. It is efficient to adjust the parameters of the network after accumulating the error over a set of samples than to adjust after every single sample.\n",
    "    - The number of samples after which the model adjusts the parameters is specified by the batch size\n",
    "- We also need to iterate over the full dataset a number of times to get the best result\n",
    "    - Epoch specifies the number of times the full dataset will be iterated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 258000 samples\n",
      "Epoch 1/50\n",
      "258000/258000 [==============================] - 13s 49us/sample - loss: 1.1324\n",
      "Epoch 2/50\n",
      "258000/258000 [==============================] - 11s 44us/sample - loss: 1.0213\n",
      "Epoch 3/50\n",
      "258000/258000 [==============================] - 11s 44us/sample - loss: 0.9836\n",
      "Epoch 4/50\n",
      "258000/258000 [==============================] - 11s 43us/sample - loss: 0.9593\n",
      "Epoch 5/50\n",
      "258000/258000 [==============================] - 12s 45us/sample - loss: 0.9429\n",
      "Epoch 6/50\n",
      "258000/258000 [==============================] - 12s 45us/sample - loss: 0.9309\n",
      "Epoch 7/50\n",
      "258000/258000 [==============================] - 12s 47us/sample - loss: 0.9219\n",
      "Epoch 8/50\n",
      "258000/258000 [==============================] - 12s 47us/sample - loss: 0.9149\n",
      "Epoch 9/50\n",
      "258000/258000 [==============================] - 13s 49us/sample - loss: 0.9093\n",
      "Epoch 10/50\n",
      "258000/258000 [==============================] - 13s 52us/sample - loss: 0.9046\n",
      "Epoch 11/50\n",
      "258000/258000 [==============================] - 15s 57us/sample - loss: 0.9005\n",
      "Epoch 12/50\n",
      "258000/258000 [==============================] - 14s 56us/sample - loss: 0.8970\n",
      "Epoch 13/50\n",
      "258000/258000 [==============================] - 14s 55us/sample - loss: 0.8938\n",
      "Epoch 14/50\n",
      "258000/258000 [==============================] - 13s 52us/sample - loss: 0.8909\n",
      "Epoch 15/50\n",
      "258000/258000 [==============================] - 14s 55us/sample - loss: 0.8884\n",
      "Epoch 16/50\n",
      "258000/258000 [==============================] - 13s 52us/sample - loss: 0.8860\n",
      "Epoch 17/50\n",
      "258000/258000 [==============================] - 14s 53us/sample - loss: 0.8839\n",
      "Epoch 18/50\n",
      "258000/258000 [==============================] - 14s 53us/sample - loss: 0.8821\n",
      "Epoch 19/50\n",
      "258000/258000 [==============================] - 14s 53us/sample - loss: 0.8806\n",
      "Epoch 20/50\n",
      "258000/258000 [==============================] - 14s 56us/sample - loss: 0.8790\n",
      "Epoch 21/50\n",
      "258000/258000 [==============================] - 14s 55us/sample - loss: 0.8777\n",
      "Epoch 22/50\n",
      "258000/258000 [==============================] - 14s 54us/sample - loss: 0.8765\n",
      "Epoch 23/50\n",
      "258000/258000 [==============================] - 15s 58us/sample - loss: 0.8752\n",
      "Epoch 24/50\n",
      "258000/258000 [==============================] - 15s 57us/sample - loss: 0.8742\n",
      "Epoch 25/50\n",
      "258000/258000 [==============================] - 15s 58us/sample - loss: 0.8732\n",
      "Epoch 26/50\n",
      "258000/258000 [==============================] - 14s 55us/sample - loss: 0.8721\n",
      "Epoch 27/50\n",
      "258000/258000 [==============================] - 15s 57us/sample - loss: 0.8711\n",
      "Epoch 28/50\n",
      "258000/258000 [==============================] - 15s 58us/sample - loss: 0.8700\n",
      "Epoch 29/50\n",
      "258000/258000 [==============================] - 15s 59us/sample - loss: 0.8692\n",
      "Epoch 30/50\n",
      "258000/258000 [==============================] - 15s 59us/sample - loss: 0.8683\n",
      "Epoch 31/50\n",
      "258000/258000 [==============================] - 14s 54us/sample - loss: 0.8675\n",
      "Epoch 32/50\n",
      "258000/258000 [==============================] - 15s 57us/sample - loss: 0.8668\n",
      "Epoch 33/50\n",
      "258000/258000 [==============================] - 15s 59us/sample - loss: 0.8660\n",
      "Epoch 34/50\n",
      "258000/258000 [==============================] - 15s 58us/sample - loss: 0.8653\n",
      "Epoch 35/50\n",
      "258000/258000 [==============================] - 14s 56us/sample - loss: 0.8646\n",
      "Epoch 36/50\n",
      "258000/258000 [==============================] - 14s 56us/sample - loss: 0.8641\n",
      "Epoch 37/50\n",
      "258000/258000 [==============================] - 14s 55us/sample - loss: 0.8635\n",
      "Epoch 38/50\n",
      "258000/258000 [==============================] - 14s 55us/sample - loss: 0.8630\n",
      "Epoch 39/50\n",
      "258000/258000 [==============================] - 16s 62us/sample - loss: 0.8625\n",
      "Epoch 40/50\n",
      "258000/258000 [==============================] - 15s 57us/sample - loss: 0.8619\n",
      "Epoch 41/50\n",
      "258000/258000 [==============================] - 14s 56us/sample - loss: 0.8615\n",
      "Epoch 42/50\n",
      "258000/258000 [==============================] - 15s 56us/sample - loss: 0.8609\n",
      "Epoch 43/50\n",
      "258000/258000 [==============================] - 15s 60us/sample - loss: 0.8607\n",
      "Epoch 44/50\n",
      "258000/258000 [==============================] - 15s 56us/sample - loss: 0.8602\n",
      "Epoch 45/50\n",
      "258000/258000 [==============================] - 15s 58us/sample - loss: 0.8598\n",
      "Epoch 46/50\n",
      "258000/258000 [==============================] - 14s 56us/sample - loss: 0.8594\n",
      "Epoch 47/50\n",
      "258000/258000 [==============================] - 14s 56us/sample - loss: 0.8591\n",
      "Epoch 48/50\n",
      "258000/258000 [==============================] - 14s 56us/sample - loss: 0.8586\n",
      "Epoch 49/50\n",
      "258000/258000 [==============================] - 17s 66us/sample - loss: 0.8584\n",
      "Epoch 50/50\n",
      "258000/258000 [==============================] - 17s 66us/sample - loss: 0.8579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19bd2737d30>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model for 5 epochs using a batch size of 128 \n",
    "model.fit(input_data, target_data, batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We trained the model in such a way that it'll produce the next character given the current character as input. And, the first character is the tab character which is the start token.\n",
    "- We can feed the tab character to the network and get the most probable next character as the output. We can create a 3-dimensional zero vector for the output sequence and initialize it to contain the tab character\n",
    "- We can use the predict_proba method to get the probability distribution for the next character in the sequence. As we want to generate the first character after tab, we need to slice the probability distribution list to get the prob distribution for the first character\n",
    "- Now, we can find the next character by sampling the vocabulary randomly using this probability distribution\n",
    "- We can use the generated first character to predict the second character in the sequence\n",
    "- The same process can be used to predict the most probable second character given the tab and the first character\n",
    "- We can keep on generating characters in this manner until the end token/new line is encountered\n",
    "- We can also put a constraint on the maximum length of the names and stop when the number of generated characters reaches this maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3-D zero vector and initialize it with the start token\n",
    "# initializing the first character of the sequence\n",
    "output_seq = np.zeros((1, max_len+1, len(vocabulary)))\n",
    "output_seq[0, 0, char_to_idx['\\t']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first character:  o\n",
      "second character:  i\n"
     ]
    }
   ],
   "source": [
    "# Get the probabilities for the first character\n",
    "probs = model.predict_proba(output_seq, verbose=0)[:,1,:]\n",
    "\n",
    "# Sample vocabulary to get first character\n",
    "first_char = np.random.choice(sorted(list(vocabulary)), replace=False, p=probs.reshape(len(vocabulary)))\n",
    "\n",
    "# Print the character generated\n",
    "print('first character: ', first_char)\n",
    " \n",
    "# Update the vector to contain first the character\n",
    "output_seq[0, 1, char_to_idx[first_char]] = 1\n",
    "\n",
    "# Get the probabilities for the second character\n",
    "probs = model.predict_proba(output_seq, verbose=0)[:,2,:]\n",
    "\n",
    "# Sample vocabulary to get second character\n",
    "second_char = np.random.choice(sorted(list(vocabulary)), replace=False, p=probs.reshape(len(vocabulary)))\n",
    "\n",
    "# Print the second character\n",
    "print('second character: ',second_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate baby names\n",
    "def generate_baby_names(n):\n",
    "    \n",
    "    # Repeat for each name to be generated\n",
    "    for i in range(0,n):\n",
    "\n",
    "        # Flag to indicate when to stop generating characters\n",
    "        stop=False\n",
    "\n",
    "    # Number of characters generated so far\n",
    "        counter=1\n",
    "\n",
    "    # Define a zero vector to contain the output sequence\n",
    "        output_seq = np.zeros((1, max_len+1, 28))\n",
    "\n",
    "        # Initialize the first character of output sequence as the start token\n",
    "        output_seq[0, 0, char_to_idx['\\t']] = 1.\n",
    "\n",
    "    # Variable to contain the name\n",
    "        name = ''\n",
    "\n",
    "        # Repeat until the end token is generated or we get the maximum no of characters\n",
    "        while stop == False and counter < 10:\n",
    "\n",
    "            # Get probabilities for the next character in sequence\n",
    "            probs = model.predict_proba(output_seq, verbose=0)[:,counter-1,:]\n",
    "            \n",
    "            # Sample the vocabulary according to the probability distribution\n",
    "            c = np.random.choice(sorted(list(vocabulary)), replace=False, p=probs.reshape(28))\n",
    "            \n",
    "            if c=='\\n':\n",
    "                # Stop if end token is encountered, else append to existing sequence\n",
    "                stop=True\n",
    "            else:\n",
    "                # Append this character to the name generated so far\n",
    "                name = name + c\n",
    "\n",
    "                # Append this character to existing sequence for prediction of next characters\n",
    "                output_seq[0,counter , char_to_idx[c]] = 1.\n",
    "                \n",
    "                # Increment the number of characters generated\n",
    "                counter=counter+1\n",
    "\n",
    "        # Output generated sequence or name\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacey\n",
      "janine\n",
      "darkah\n",
      "enoy\n",
      "loynona\n",
      "kriselm\n",
      "rhadgia\n",
      "george\n",
      "scott\n",
      "hildo\n"
     ]
    }
   ],
   "source": [
    "generate_baby_names(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN's are not very effective for longer sequences and we need a different kind of recurrence to handle long sequences - LSTM(Long Short Term Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation in the author's style of writing\n",
    "-- LSTM - Long Short Term Memory\n",
    "- Does not suffer from vanishing and exploding gradient problems and as a result can handle longer sequences efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "    \n",
    "    return str_text\n",
    "text = read_file('shakespeare.txt').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"that, poor contempt, or claim'd thou slept so faithful,\\ni may contrive our father; and, in their defeated queen,\\nher flesh broke me and puttance of expedition house,\\nand in that same that ever i lament this stomach,\\nand he, nor butly and my fury, knowing everything\\ngrew daily ever, his great strength and thought\\nthe bright buds of mine own.\\n\\nbiondello:\\nmarry, that it may not pray their patience.'\\n\\nking lear:\\nthe instant common maid, as we may less be\\na brave gentleman and joiner: he that finds us with wax\\nand owe so full of presence and our fooder at our\\nstaves. it is remorsed the bridal's man his grace\\nfor every business in my tongue, but i was thinking\\nthat he contends, he hath respected thee.\\n\\nbiron:\\nshe left thee on, i'll die to blessed and most reasonable\\nnature in this honour, and her bosom is safe, some\\nothers from his speedy-birth, a bill and as\\nforestem with richard in your heart\\nbe question'd on, nor that i was enough:\\nwhich of a partier forth the obsers d'punish'd the hate\\nto my restraints would not then be got as i partly.\\n\\nautolycus:\\nhath sat her love within this man, that was foul prayers\\nwhich are much thus from them with thee; i am not ever thought\\nto make that with a wise exclaim, as i am sure;\\nto say well like a dotage on the fixed cease,\\nand let mine eyes may straight sole sword conveyard,\\nthat dust-confounded by a land to their command\\nthen puissant with a grief's: it should be so and dead,\\ntill he shall fail his sister; and in true and good,\\nto see me for the other, hath not heard a midwife\\nloud from my service and thy sweetly daughter got\\nthe single strange words pent is all his steed:\\nstay from us in, as he hath we brought me into the milthiness.\\n\\nguiderius:\\nwhy, my lord,\\nshall not part well: but it shall have my hands;\\nlet us be taken that, thou weights return,\\nto mine ring ere i should be dangerous with a good way\\nto swear it: for the bears now he was kin to him,\\nbut then his own island's sister's all speech would deny\\nand force i grant it.\\n\\nabhorson:\\nthou art a very earth. villain, reserves my keeping.\\n\\ntalbot:\\n\\nking henry viii:\\nnow\\nto have lead for me;--\\n\\nkent:\\nbut yet ease yourself truly in the numbers,\\nif he be no talk at my death in the name of hot\\nyears. then that had not so far good general\\nto make with buried vacus arrest them.\\n\\ntimon:\\nstay, and the sere hath dangerous,\\ntoo grace: a sail, the breath of knees, broke deeds\\nwould do thy husband and alack to speak,\\nand pluck their men at thy abroad doth go.\\n\\ncassius:\\nand in desire,\\nand call'd me ballant cassius.\\n\\nbardolph:\\ntost in it, what then take your madder?\\n\\nduke of york:\\nshe would be ready, this advice, say you a chaste.\\n\\nsecond neris:\\nnow, blessed france, and with thy speech can know?\\n\\nantipholus of ephesus:\\nnot i: outlive, lady! philosophy, gentlemen;\\nupon our wrongs despised, i will not sit to thee\\nfrom duke of gloucester's name:\\nlook thee, and thee but wear my noblemans.\\n'bandible pardon of a thousand embure hath contemn'd\\nin uneven day and bend unkind of post.\\n\\najax:\\no mattle! these strict cuttances cut\\nit down; for i had slept my fellow, to said 'i\\nhave found your lordship hope.\\n\\nmark antony:\\nhow! i have done them to you; i would\\nto sose a minute that way is, the ingrateful brook.\\n\\nmarcellus:\\ntell us to break it, for i hear not every shore.\\ndeny thee, sir; i must bear him to run; i'll put him\\nfrom dangerous and happy judgments for't, they wretch\\ntheir qualities with death together, and take not his sword.\\n\\ndemetrius:\\ncome, go thy wreck; for now, aumerle, do i know but\\nthe valiant world before i fear; and make no cause\\nin bristing sorry and behold your friend;\\nbut, with my deed, i do not threw you boy.\\n\\nking idar willoughby:\\no, then wouldst thou speak with me.\\n\\ngower:\\npoor queen, leave them along at.\\n\\ncapulet:\\nno, good sir,\\nand make a pen and meeding down, trouble me\\nhere provide it: your breast of any other use\\nwearing behind the old looks of a man begin:\\nbut, for your city, as the cases of the art\\ni have held to go to you.\\n\\nvalentine:\\nsir, in state, then tell me which are never fall'n.\\n\\ncaesar:\\n\\nsecond murderer:\\nmy lord, if virtuous scotland! is good chamber to\\nthe shepherd.\\n\\nsecond murderer:\\nhe is like to let her go.\\n\\nnorfolk:\\nwe'll come by thy sweet brother.\\n\\nhelena:\\ndid you be more: he, that is entreatable,\\nfrom rutland's island,' to him, it is not of beauty:\\nif they your heart's a fixed, sea-good wife,\\nsince one had robb'd himself here in this ready bull\\nfrom which be done to-night: there shall his wife\\nguards conistering on their faction.\\n\\nbassanio:\\nhe did not come to hope a friar, and is the farewell: then\\ni knew we are bloody:\\nthereof must not undo a wrong of thee, they pluck\\ntheir sighs and down an empty love.\\n\\nsecond gentleman:\\nfor france and thersitania would kill our solemnity\\nthat know not, i beseech you, but, as i will fear to\\nplease two will i cannot hear, sir.\\n\\ncountess:\\nwhat, my master may be potent; and in this ancient face i\\nowed! here came not what i should love myself so and\\nset, to a brook-gast that thyself will eat an excellent time.\\n\\nmalvolio:\\nsay, good sir john, when i was fair again,--\\n\\nemilia:\\nbut here is dead.\\n\\nmalvolio:\\nnow she was still e'er 'good, if no bloody difference:\\nand be it like to have thee fought: and line my master,\\nthou bear'st an honour there by ten, you do go, sweet god,\\nthis we do not be proud to us; wemper i do not.\\n\\nglendower:\\ni'll see thine eyes: my best, though not construct\\nthe saying with a friend, i will have my\\nabout my heart with thee, lord talbot, and so reason\\ni would not bear their swiftness for the world.\\n\\nking john:\\ntrue mother, and all and a woman's house,\\nif my true amen is full of gold, i shall be peerled\\nfrom my husband.\\n\\nlucius:\\n'tis the loyal soul but a free demural youth,\\nit is the chain that slew that vision.\\n\\ncleopatra:\\no the fight of hope, madam!\\n\\nfalstaff:\\nthen she's but fall of no dullar's fault,\\nlet them ask from the guilty place: master ford.\\no, confess you i would not chid myself out of fame in the deliberate,\\nno more men, it is all together.\\n\\najax:\\ni know not what.\\n\\nhost:\\nper me, 'tis babble. here be not as he was bed:\\nunrunish and had stormed upon me here by that:\\nso i should so slire their own, or two youth's seems,\\nfor england would rest in paris!\\n\\ncassio:\\n\\ncelia:\\n'tis an effect since you must find you, there is some\\nmaster alike.\\n\\ngloucester:\\nopen them for thy heart, back again. are you\\nhope to use? prithee, let him go, brutus. so much it is;\\ncount was of day, and i must raise a layful peace.\\n\\ncoriolanus:\\nlet us would see our ripe.\\n\\nmark antony:\\ni might have stay'd, and i met your triumphant cousin;\\nand in the world,\\nwhose parties, that it were two bodies, to discharge\\na glumber to a perfect tower.\\n\\noctavius caesar:\\na part to the tame.\\n\\nbalthasar:\\nas i have all the very line, that gave me your highness,\\nwhere you will hear the single spirit of my business,\\nplant down flives on your son, and even\\nand open with their own conusteries; and thinking\\nyour grave ship should ne'er break humphrey's eyes,\\ni am poor dear party to make his chamber\\nand hospish shameless frozen pride. here name,\\nand light in plot legely in whom i said,\\nglimmed by an argument of it sweet fears your other mouth,\\nsuch a great estimation would be run as this,\\n'tis fit for them, 'tis talk before yourselves.\\n\\nking henry v:\\nand i must not see her, but go'st with unhappy woe.\\n\\nking john:\\nby paris, it was fair.\\n\\nduchess:\\nnay, i'll ever throw his honour.\\n\\nothello:\\ngood morrow, amen.\\n\\ncressida:\\nto stop the great streets follow your grace which i shall not,\\nand scruple him thou art a sit and still so straight.\\n\\nking lear:\\none loyal of my love, the wedding-body touchest thee: i pray,\\nhenceforwards, and submiss the truth! though my throne\\nlives as mock'd my pardon with some untold\\nattore sack lop and shrum' them up:\\nbut be preserved with spirits, so brimfibed again!\\nmy voices were so early, i was enough.\\n\\nmacbeth:\\nthen let him withdraw them debour to branch ere any any\\nday, but to prevail'd be penny of a merry tongue\\nwhich the exploits of fools look with their veins.\\n\\nking lear:\\nthat bell beseems my wife at all, and i canst thou\\nsee. how! lend me your part.\\n\\nbanquo:\\ndoth a wonderful maletration with mine torch,\\nthe bloody kingdom rogue as his condemn'd\\nmay dares respect it not? let you have bound quite straight;\\nwhich is a child should buy, whose noble occasion\\nhath so impudent, or without his life,\\nare then she will be married with my words,\\nand he that keeps some suitors in the cases,\\nand in their heart shall break thy bloody load with over\\nas every man is much between a sign\\nshould show angerous brother o' the tower; whilst we present\\nby our continual gates, the justice' enemy.\\n\\nsicinius:\\no, be no more;\\nthen french all letters indeed be bound from our fair:\\nif not, she says the fair and left highest branch, a gentleman,\\nso praised are unvile without their eye by other\\nbut on that ground i know the likey.\\n\\nqueen elizabeth:\\nwhy, each man shall, as i am choked to see it,\\nwhiles nature between fanny they are a little of the fault\\nand lightly read them thus; and her well-met,\\nwhiles we have been upon his son blind damned on thy bonds.\\n\\nsecond citizen:\\nno.\\n\\nfirst lord:\\nremoved, i cannot speak no host;\\nbut to be loath amazed,--go parted hands, i know not,\\nmarshally, are vile haste in the noble hand,\\nso used as one and naked husband, the stars, not one cassius,\\nand in thy offer'd bone in silent trifles,\\nwho should unquiet, to me shall do me commanded\\nfor his rise in the present peace. but know'st thou\\nbring me my love? were all these sleep command.\\nwhat had thy hand your wit and conceit's bed?\\ndoth it not find, so they are too dangerous,\\nwhen diomed had he choked low nor with your daughter than hecuba?\\n\\nsecond lord:\\nis all his oaths? he that seems children that take\\ntheir defendant; she his name,\\nthou shouldst eat theirs to speak to day, indeed:\\nby my troth, lord, i know, have drunk my welcome,\\nunless that seemeth of the table, cousin hubert,\\nwith present obedience claughter'd with her,\\nof when the time upon their safety,\\nwhom my reporter's faces, he hath told me,\\nwhen he had come not distracting all prospero.\\n\\naeneas:\\no thou man, a traitor for myself and hector's hatch!\\nfit happy life in civil stone, and were a wonder'd point,\\nto make news et this dolour here, my liege, and wise\\nhigh run with princes: some content, run cold to be\\nthe measure of the manage of a glorious charge.\\nsir, i'll asleep.\\n\\nmercutio:\\ni would not regreet but your tribunes suffoce you?\\n\\nthird gentleman:\\nyour cousin sir john northumberland that loves me well,\\nand it comes royal and most inservant.\\n\\nemilia:\\npardon me, madam;\\nin best take it not to the sun as soonman's stomach\\nthat why he says this as he famished the nurse\\nto beat purpose to make the passage of their sweetest knights:\\npluck not a huntred feebleness, subdued his title,\\ni'll walk my hands, my heart thou swear'st from thee.\\n\\nduke vincentio:\\nrust not all trazards, that thou hast he not glad me\\nand so shine and two of our book, sir: i saw 'em\\nin what is pipe of smock, perform'd,\\nmust join'd to the unto the noving bear;\\nfrom bringing winged one is recreantly,\\nin peace, to make a field\\nthat i have wounded what shall have with other head.\\ngive me thy recompense are out of death,\\nor else resolved too ground.\\n\\nlieutenant:\\nhow fares thee to command? do it so.\\n\\npistol:\\nstrumpet from my name, unto't, philomelius, lay the garland.\\ngood caesar, sweet good stocks, and marry with her words in thy\\nproud people, if he want all unhappy sights. revenge\\nto be so means to you and honour for my flesh.\\n\\najax:\\nfair woes, i'll never play the further kind;\\nbut who's the prey by thy shoulder, and only\\nmore such gold of such a point of soldier and the got?\\n\\nking philip:\\npeace, you had not the subjects laughman's\\ncrown! o, sir, i am the house. be here in the king.\\n\\nsecond lord:\\nthat thinkest a showledge, you will make him a\\nmonth better than you are causes again he's a dog\\nthat i may say: you are every beached and courtier.\\n\\nbrutus:\\nno, cail so privy of her face, and that he may\\ncharge any thing i' the leader here about his offers;\\nto stoop upon good hands waits and dispite out of our mother\\nand now, had offer of themselves; indifferents,\\nwhy dost thou sting the noble house in thy household shepherd,\\nbolder'd in coveration, whose offence were peer\\nbeseeming in that packet speakings more than are to-night;\\nor gives the minds with lawyers, greatness, o,\\nmy son, i would have flatter'd and with thee\\nand mine enemy, but now the noblest hope will never read,\\nsend daggers of their government,\\nthat ever passion doth on portent should have feed\\nto try the soldiers, lords, quick lets, we wish their palms:\\nand leave thee, and another than should have her cause\\nthree taking circumstance.\\n\\nimogen:\\nby romeo, i will strike without state.\\n\\niago:\\nsir, you are put a mirror.\\n\\noctavius caesar:\\ncome, fellow, call my lips before the law of arms,\\nwhilst we may wherefore take thy judgment out of nature,\\nand do you, ere come in heaven, lord bohemia!\\n\\nantonio:\\nhere comes capulet.\\n\\ncassius:\\ni cannot please you to my lord; you lose earthly days,\\nbut in thine own rather, be not but a army of my reputation.\\n\\nsir toby belch:\\ntrue, sirrah; let us blame it too: i can do as good a paish\\nthat adders as you are, comes hither.\\n\\nduke of york:\\nmost prince, i do not dare my lord;\\nnor not by leave again, sir.\\n\\nlady macbeth:\\nit is not to be so.\\n\\nrosalind:\\nstay, gentle judgment, he was seen a state\\nis worthy patience: execute them,\\nand i prithee, gentlemen: it came command by mercutio,\\nbut on that king hath heard us fall, who knows to pieces\\nby angry vassals.\\n\\ncrimon:\\no ho! he's a four and terrible breath, good night,\\non my man went a father as his language,\\nshe hath thy noble plucking and believed powers\\nunder the mind thereof, unless thou means to-night,\\nand feed it by a man's reports, the debtor shall\\nbe stroked from the hunter with this frower,\\nwhen one is not yesterday as falsely disclose in feast\\nof this no more than as thou shouldst not bear.\\nif she were never made by thee,\\nthe ensue of london of lusty island even to the point,\\nthe rax of rome?\\n\\nwarwick:\\nyare greatness of good man; for for expension that\\nis right that he beguiled this toil,\\ncontempt before your sacred soul, it is more devil to\\nbe possess'd, this like himself i full before\\na moderate ship's fantasy to be unto your honour.\\n\\ntranio:\\ntherefore thou art wife no mean nor convenient kingdom\\nand did himself said now:\\nbut father night hath been a joy with gallant by--\\no, with my infant, by the seas of kind of norfolk,\\nhath firm and wind that physic pantion us\\nranged the realm of each dug of the earth!\\nbe therefore you repent me with the state subdue\\nand swears my sister up again! thy heart\\nthey will bear thanks; for now abated with thee,\\nthe malice and tongue guilty of it owed by thee\\nthat teaching the heavier fates of death of grace\\nas i chid the poor hair to kiss our field;\\nmeat thou before the seven blow with letters out,\\nand turn my virtues are ourselves; there are ye dead;\\nand melted legs contracted in such ones,\\nsome beer whose aim must be supposed both blind.\\n\\nisabella:\\na warrior of the sway.\\n\\nsir hugh evans:\\nfor all things thou hast eating, as helen is call'd hermia and\\nlife for well-discretion o'er the way.\\n\\nsicinius:\\nnever to discredit you, my master.\\n\\ndon adriano de armado:\\nnow, what's the matter?\\n\\ntheseus:\\nwe may washed her: there's\\nmost conduct but a spirit of horns.\\n\\nhostess:\\ncome, my lord;\\nhow does the proper country's wife? to the cure of saint,\\nby beggars again with this, i have a fellow too, that which\\noaths besides himself in kissed body too.\\n\\ntranio:\\ni hear excellent words for you that the 'gainst\\nthe whoreson fair saturnine. bark, i fear,\\ni am a tew, he throws me what to you;\\nthis is not titus.\\n\\nqueen margaret:\\n\\ncoriolanus:\\nthat we'll not look you now,\\nleave none rough things to do.\\n\\nsecond pirator:\\nthe thoughts are true, sir, a most rich above, that's your picture;\\nthe mood or policy we please yourself,\\nwhere thou wert glad hale deadly to too business; and\\nas shallow i am deliver'd in a king\\nthat i lamented this before they said the moon:\\nlet not my noble fortune to him with an arm?'\\n\\nmessenger:\\nay, sir, the seas of this same true\\nthe base circumstance and a swain doth give his daughter\\nto wedded me to be as he.\\n\\nemilia:\\nwhere is the loss, is his guilty eyes?\\n\\nduke vincentio:\\nwhat is this?\\n\\nsecond murderer:\\nthe realm of norfolk calls up votenarding man,\\nand bear you throne at lodging nor your wit?\\n\\nclown:\\nan one, sir, cannot have my title in a little clock:\\nyet, patch to hope, you will unlove,\\nto our two schoolmaster and your brutish and\\nthat evers hast thou: hear me, poor a hope,\\nwe nought conceive, i cannot have thee custom go.\\n\\ntitus andronicus:\\nshe doth to coriolanus.\\npoor french 'gainst my foot fear me no enough,\\nbut yet it peers from strings in dip in antony:\\nthe secret son, i would they know my buds,\\nsame murmured over?\\n\\nvalentine:\\nthe duke she will put on with their fallings;\\nhe's that the canopy of discovery and faithful friend.\\ndidst thou be your dear lord, with grief? o, let us call\\nmy wife, the earth! good morrow: for i'll see\\nremuneration.\\n\\nhamlet:\\nhe's the man.\\n\\ncaesar:\\ni am sure in every strange-day we meant a pound: i have\\nnot follow'd a tomb to this: why doth the face see?\\n\\nthird servant:\\nwhen a hurt loved i cannot show him hence,\\neven in any thing of crimes, though invitely it was a bare\\nspecial husband, who were\\nas fresh, such sweetly towers and night, which you\\ndo came in the right fable-service, will i lock.\\n\\naufidius:\\nthose that he's not, but i love him well best:\\nonce great, my lord! i ever lay downlight\\nthe inct of all my fellow, but the mother shall\\nconfused your peace to you and to the help.\\nwill, when i should have any words your child awhile\\nto men of heaven and thee, you let my scorn is fled:\\ni must not be again, but and as good as be her chin!\\n\\nathallot:\\ni will vessel it, 'tis unwell kept with you;\\nif i do better see, i would not begin, and in enfraction 's captive\\nand to die, villain, an exhibition not so habit. but i will\\nwear you are jealously, and i am a mouth of christenders.\\n\\nbaptista:\\nit was a great bond broke, and brought him to excuse.\\n\\nking philip:\\nand, if you know it, if he remember.\\n\\ncassius:\\nmistress a fellow, here in natural commoner, will you title?\\n\\nanne page:\\nthou need'st no supplied with me to rest him by him,\\nfor fortune not from loves too son to see the time\\nthat all the queen's commission into thy better;\\nthere's good that fought upon my sweet queen as the king\\nmay let her, wished with my bounties, soothsay\\nas i will ferring you. come, you are fear.\\n\\nhoratio:\\nsir, his shippus yuts so fast as vile as est.\\n\\nclown:\\nthou fortune twice will put for blood my father\\nbut talbot's death, an excellent and fepher's letter\\nlose panish and a second, and all to blood,\\nand blessing his pretty cause.\\n\\nbrutus:\\nwe do not take it, nurse.\\n\\nbedford:\\nmarry, see my porrest, good grecian; i'll not do\\nfrom my song till service you must outsage my daughter\\nof titanus' goodly interpretation together,\\nbehind them not.\\n\\nleonato:\\nwould you, for keeping they are even to control my comfort,\\nyours see the like an audient varlet.\\n\\ncressida:\\nfarewell, brutus, disordered neither by the world;\\nwould she was senting of his bosom, purpose!\\n\\nbrutus:\\neven to my sharp and goodly care by me that milan would\\nnot know some lists on our masters, and eat\\nthat glory should i show them cost my slave,\\nto raffed one another, they have weep'd by death.\\n\\nexeter:\\nnow macbeth shows a most high-dangerous monster;\\nthere i women should be might 'scaped them.\\n\\ncelia:\\nif you will mine, though i may presently be so.\\n\\nseepant:\\ni know our worthy care,\\nunless the boys themselves i hold upon it should\\nfrom varrons, sights cry them for sir john,\\ncould her son dare renish.\\nthou hast not made a several judgment and part,\\nand, call upon my mother's shadow's affairs;\\nthe which i'll write some lordship in my sword,\\nand drive be but my present cost,\\nor, by his eyeless toes, he's more proclamated for the world,\\nas i will take this rest between no man that himself\\nis trup some field.\\n\\ntalbot:\\nthou shalt put heavens bring out his patroclus.\\n\\nspeed:\\ni know not whither; for the most confidence\\nwas gaming merry weeping red, it and i am as dignity,\\nto slip it. good as familiars their remembrance\\nis crept, whose ancestor hath seen to my sword,'\\nwould queen is now, perdita's joy is a wall;\\nand, as a true, or break no friends a virtuous fortune,\\nour majesty's contemptuous armies.\\nwhat news?\\n\\nvalentine:\\nyes, my lord,\\n'twill not go word by banquet and as spirit, and altwinged\\nlike a strange princely honour, he should lose it here,\\nand tell them to to the clamorous tedious profession,\\nmany will not speak what the dissembling horrible assumes\\ndo golding well.\\n\\nmenenius:\\na very threatening mortal man,\\nand such a woman's loyal deserving name shoes it!\\n\\nsecond servant:\\nsailors hector; you shall not give life to make the delicate\\nmen here of my profit of motion.\\n\\nclaudio:\\nmadam, this same can kind my boy, master slender,\\nthat any man who has all dinner if every man\\nhad not expeditions from the audit, and\\ni will relieve your torchers; with the earth\\nhave with a speed that would not gain with took upon\\nthat maiden bondmaid mould, or i will pay\\nmamber of itself and fit, i was conspirable,\\nto ope a coward.\\n\\noctavius caesar:\\nif you cast those that rape and breathe me, sir.\\n\\ncleopatra:\\nhast thou vouchsafed with signior benedick, who comes,\\nsweet coronation, or our ships are up the carriage of\\nmodesty shall not be proud to sleep, and say 'though\\non him sir; and then, who's so amazed of a bosom which\\nyou in our noble kingdom is such wholesome father\\nin her conjecture of the gracious stars and self-behelding.\\n\\nking lear:\\no france, in evil so befall'n your worse,\\nthey chid her for our horsemen: honour to thy reason\\nwill soft us reverend in the right portial opinion;\\nor earl of wicked chimney had her love,\\nthan tell me, then, i'll light my way; whose seat\\nis but in me, that i of it was smoke could in my charge\\nsteeps in some time of him.\\n\\nmalvolio:\\nas i love them, since your hands we break some goodness.\\n\\nhenry bolingbroke:\\nhow should i, goodman wife? is there no cause?'\\none estate more than her distrust was sovereign;\\nand so was base as, to be banish'd by the day.\\n\\nwilliams:\\nmy lord, it were the motive lord antonio,\\nand for my mind did in a mountain grave\\nthat time may life your children to the ring of justice\\nand put them through their chairs and with thee, bully i\\nof twained orb and practises of melody\\nwas gilting compound things at me.\\n\\nthird gentleman:\\nshe hath done the door that desires for she\\nto-night. o, not to\\npray, and therefore i have been hang'd without many things.\\n\\nophelia:\\nthere's mine.\\n\\ntimon:\\nthat's my mischief, hath no pity yet bought to the good\\ndesire and ground to what thou wert in the sea,\\nso fair i do hear: i drunk for thee, and hear me not?\\n\\nangelo:\\nyet you'll come in?\\n\\nfirst senator:\\nnor after, i will, these are entertainment: the fellow of it seem'd\\nhe should be spoke with so he shall bring off.\\n\\ntroilus:\\nso peasantly, for the king's tent.\\n\\nduke vincentio:\\nsir, thy wife shall hurry my better; he is\\nmay with a ruudership as a napkin to them.\\n\\noberon:\\nthou know not. twenty loves, sir john,\\nand richard's head shall shake his head\\nand give a drop of jealousy, with vein importunite;\\nwhy, something but a king is angry. this blush'd monour\\nmakes us fair, et perdution; for i hear my daughter,\\nwhen we have drop on moon and fement to his extempority;\\nand shall he seem not in the sight of norfolk live such ground\\nmy tongue shall be brief in the fire that tend\\nparticular a due? mercy was your remain!\\n\\njohn of gaunt:\\nthen, if they shall not rid of thee! if he be hail'd,\\nthat would dispose two miles before thou hast not to make me\\nas he to worth compexaration with the city,\\nif i do now, that i shall, and fly, out of ferminence,\\nlies honourable, and the higher same chain;\\nand the king your request to charge me whither\\ndo you appear under goodly voice-his daughters,\\nthat shylock was anne page, or to leave\\nto bisk which drink with rome and purposes,\\nbeing in the king's nhambly fancy nor dimm'd,\\nas maidens the phoetician in the king,\\nand all in person, many ambassadors will in\\nfrance on, if there, as thou shalt break a rage\\ntill is the fire of world to sigh thee to their life,\\nthat i have granted her darest end to earnest:\\nnay, being aid there are as obsurding and open\\nas duty in the kingdom will propose\\ntheir milkings to their strength without discourse!\\nfie! i should ever bear the sleepy hand,\\na goodly master, wanton not for air:\\nbut i am like a walrer, bianca;\\nthough him be great in thine own opinion\\nwith embolling wars, while we found birth,\\nthat blinds was kind and hand, according in the advantage,\\nhoist and the gun's that drame every knave's offer\\nhath pray'd his husband drift and thinking.\\n\\nsebastian:\\nwith days,\\nmost talk of care it should be patient.\\n\\nmenenius:\\no, so. say you well, indeed,\\nhe shall not mine own peace gave you a stand.\\n\\nvarro's murderer:\\nwell, they say 'didst thou so? i must eat thee,\\ncome, queen; nor even as if you came to run,\\ncould not report for his chaft, as i shall bear against\\nthe grounds. i do beseech you, if you would hang.\\n\\nprovost:\\na proparable pitch could point prefer with you?\\n\\nduke of york:\\ni saw those tale of heaven that fled for thee.\\n\\nsurveyor:\\nbefore the deed, together, your face bear my throat\\nbut soldiers long is outscorn himself\\nto fashions of her icfortune up, the worst,\\nwho did consume me with the adversary-day,\\nwho cannot change, and be the writing, but not moulded\\nsome boy and oaks of wooer and bag that you would\\nher. but what's he like a misery? i swear behind\\nyou, because most ready i am so fraught up.\\n\\nbeatrice:\\nnow, by my troth, 'tis guilty on the ground.\\n\\ndostard caius:\\no man!\\n\\nanne page:\\nshall i cure me to give on our friends without great arm?\\n\\nnorfolk:\\nand tell me, provide her, good talbot.\\n i speak ere you will bring me thou go with me;\\ngo there with this.\\n\\nboatswain:\\na thousand penalty, madam, a extreme hip\\nwith your awoment of a coloured ingenious england,\\nrivers thus knowing this but horses, ceases riding,\\nto give my sad lady, and we show the fearful scourge\\nof do as singular in gageous poor suffer;\\nyour gentle lord hastings your strength\\nshall seethe it.\\n\\ntalbot:\\nalas, with him.\\n\\nmalvolio:\\nback not of all the practise of these trees\\nto three horrible city hungs in shrift,\\nthat romeo wear you in the court shall could restore\\nto come anon: therefore on this, we stand from any man's\\na future's dependance: of your own side\\nin ireland, i will prove between thee;\\nhath stolen for it on the poor innocent roman\\nthat turns the sisters to the soul of cretes under\\nand say it makes them tear and sit again.\\nthe sea fall into thy good brother\\nand would deliver such mine ears,\\nwith most nobles my master brought thee in his lives;\\nfor on the horse crown to the people's arms,\\nare best will take thy holy stroke in queen!\\ngood morrow, uncle margaret, gentlemen, let us have more\\nenglish to you.\\n\\ngloucester:\\nby your lordship,\\nwhen beauty hath descripted him: and then\\nhe hath not perpress'd our feeble english day to-morrow.\\n\\npage:\\nindeed, she's your will, and his profit.\\n\\ndesdemona:\\no god! so long i never draw,\\nthat every one were made his book, the wise of love!\\n\\nking henry viii:\\ncan you not?\\n\\nmacbeth:\\nbe not true. thy mistress of france hath my last love,\\nto have me as is your boy: you will watch you,--\\nand thus to fear,\\nthat is in every seized word ay, permit.\\n\\nchamberlain:\\nwhat never dare?\\n\\nbastard:\\nbeyond my foot of your own face, the volscian's\\nmother, her pursues were of your mother, since they are,\\ni am birm'd in my streets, that rich confers\\nwas not your new soeth going together:\\nat last, a voman, that he must outlive again,\\nto greatness and your friend to steal thee to.\\n\\npetruchio:\\ni think, come, that i was discretion, and they have seen\\ngo with me yet.\\n\\niago:\\nbut, i will make the marriage, sir.\\n\\nboyet:\\nay, sir john! and this was so many as the field\\nas i do my day's will be gone!\\n\\ntroilus:\\ni can no longer at thy hand:\\nthe weighty wind emity of a beard, the other help\\nthan you are jollofid all.\\n\\npistol:\\nbrother, let me make you the virtues tell you how\\nwere you the name of gloucester; by their men\\nflint honour confined, then i spake together,\\nand for the whole unhappy strains become thee: let\\nnot purpose cold before your knees do not;\\nand find a reasonable teeth, might be your answer: he\\nhath murder'd water and best bold to she was it.\\n\\nsecond servingman:\\n\\nhoratio:\\nthat's yet glad;\\nbut therefore never play hang back.\\n\\nedgar:\\nsound absence, lichard part!\\n\\nnurse:\\nay, if you do remain; and so you do.\\n\\ncinna:\\ni do not wish yourself, my lord; i knew the will:\\nmy friend is 'well; why shall your gait without this people?\\n\\nduke of york:\\n'tis cleft together!\\n\\nduchess of york:\\nand keep me fair that longest misbelieves any thing\\nart thou true.\\n\\nking john:\\nthe frond of strength i saw them wrongfully to arms.\\nsome pillows sing from you, for your very crimson and\\nlove for it.\\n\\nbeatrice:\\ni'll see your reason's fool, we will affright.\\n\\nlady macbeth:\\nhave you resolved?\\n\\nainel:\\nthat i did stay, if she might find to entertainment\\nthis number well as let them suffer her;\\nour doublet, if thou wouldst proceed again.\\n\\ndauphin:\\ntrue: o, i pray, away!\\n\\nnurse:\\npray you, do you will:\\nhenceforth high sweeter have done.\\n\\nearl of douglas:\\nfeed me by our exhibition? honour with thee,\\nfor 'tis so sweat, i saw thee strength.\\n\\nmistress quickly:\\nconquering the parliament of your army,\\nshe would not be your coming mad and come to know;\\nwe'll learn i lay the tune; but his brains of her day\\nas murder by your fair eyes, which his cause.\\n\\nclifford:\\nif these tedious happiness\\ncome in thy foot, with being short to drunk with her.\\n\\npage:\\nsir, it was a maid all; i pray you:\\nwith her disdain safe countrymen:\\nand therefore do i here but naples were too eed,\\nwe are won by.\\n\\nmarcus andronicus:\\ni will not withdraw, and to get thy brother's shame.\\n\\nking henry vi:\\ncome, my good lord.\\n\\nrosaline:\\nworse leawer, unless i play i do again to be behavior.\\n\\ntidings:\\nbut let me know not, but for your own face.\\n\\nyork:\\ni tell you, that's ild. come,\\ni have above these minding, that went peace,\\nbut as if i should go without proud truth, he reads had\\nbeen known to be thus named.\\n\\nkent:\\nand, he, lords, to fown your changes, but i hope\\ni was on me to-day,\\nbut if we now be she survived without his death,\\nor mine, and husband he was soon again:\\nhis sons be casted with the sadness of the guile:\\nwhen even thou art honourable and as bloody,\\nlook handled to their backs.\\n\\noswald:\\nfellow, thou art like wrong'd of man, and may i die.\\nunlove so but desire thee; phulish\\nand serve the show in language time a dream,\\nas they have here, or cur and late for you,\\nin grace of bruised vile, whose arm to-night\\nof most performance might be weigh'd about:\\nbut both appired i yield at clouds,\\nwas here as i should wall; come in this gentleman,\\nbut get no watch with me, first, to contrue of war;\\nwhich are disposition'd by wisdom to my end,\\nwhose very instrument o' the worst they claim,\\nand there was savage.\\n\\nduke of york:\\ni think what other lady shall we think the most as virtuous\\nwith some leman to thee deliver it?\\nha? he!\\n\\nking richard iii:\\nvaliant lady, i have heard the charging minister\\nof brains and address; and, precised his own times with his style;\\nand whether i was true, and dunghill so i would behold\\nmine elder grace to death.\\n\\nviola:\\nand i would grant thee, i'll not do him not.\\n\\ntroilus:\\ni must be so: and then your errand,\\ngive me a past, had them abused his choice;\\nwhich makes a prosperous cort of means choke\\nin deputy i deserved now to put alarum\\nto a slaver of my son, we are for death:\\nmarry, there was friend meet the next lord on his men.\\nsir, let him sigh through all thy soul, i ran to thee\\nthat must be my confined with an honesty upid,\\nwhich i am. chiron should not stir on faith.\\nthe coins are well eyes of this head.\\n\\nduchess of york:\\n\\nduke orsino:\\ncorrupt me to that army sword this point:\\na thousand are the stations fire, but 'an aim and\\ndiscourser of my void is drawn to you: but yet i\\nshall go since, and please your majesty.\\n\\nduke of york:\\ni'll poison friendship. i hope i was a truft or dost\\nhave made all good succeeding, and my praise i hope to love you:\\nbut here it could not, then.\\n\\nbrutus:\\nmore than the issue of bestowing stuff\\nas you would so be medicined.\\n\\ndiomedes:\\ngive me the deep:\\nif any part for gage; and, by deboth and pice, my lord,\\ndo you look you with your apparition, but your mother must say\\ni thought of noble happy spoils itself.\\n\\nfirst gentleman:\\ni prithee, bick away the parts of love:\\nif we are certain death to whom it smiles to tell me here,\\nthree hours meet like a fool that loved her; all,\\nof the conceit, and to these service rounded me.\\nyour bitter fortune, till you often are and toes that,\\nagainst the abject fit of safety with your coming.\\n\\nrosalind:\\nshe's publicly a fault, sir.\\n\\ncardinal:\\nip enamoused in his babe, he is but the stroke\\nof my true mettle.\\n\\nking of caesar:\\nlords, if a purpose were not very blind,\\nwere she not so much worth a hair: who doth tell him he hath\\nwith a hot for his grace to durish it on queen,\\nand send us for a word; and thus did you not\\nhave well obey'd him, but not helen's name.\\n\\nprovost:\\nthere are the heart of these you underneared:\\nlook to't!\\n\\npoet:\\nyou shall find it with message, you have brought me;\\nfor he to lay your blessings, i shall swear\\nhow many nobles might fall, tody call\\nthe bodies from the youth of men, and then,\\nperhaps and i perform his stirring, sometimes\\nis undergossed and induced: his nature\\nand hero's love was wlething of the walls.\\n\\nking john:\\nis it your ear shine?\\n\\nduchess:\\nsolons have no crown-hearted happier's heels.\\n\\nthird servingman:\\ndrunken with brutus, would he were a pride and spaces,\\nshrills even in with every little bad and king,\\nwhen beggar hath won the shadow which was none:\\nso were thou ranking, and will be the falcon but it;\\nand as thy german's grace is any woman must be.\\n\\ntimon:\\ndecrees, a sister: no less than i should clap on him.\\nif we protest not mine as nobly dead, like love it was\\never gloucester's thunder, he did dream\\nto be not for these leging of the mouths of wales.\\n\\nduke of aumerle:\\ncall me befall thee: what nuptial prince!\\n\\njoan la pucelle:\\ngood, sir, i say, and like a rank of mistress,\\nmy heart. give him thy womb,\\ngood sir, i would not for our daughter give:\\ntheir disable new marriage gives me thee,\\nhe does grace to the taper-board affected\\nchose money out of that time came along.\\ni cannot pluck with thee with the longest consliping gentleman.\\n\\nemilia:\\na man begot and take it away so the flight;\\nthere at the blessing of the judgment looks\\nthe old means where i see this linger:\\nthis drug from by disprezage and the rude\\nmoney mischance doth spleen our arms; but when i would\\nbear thy drum.\\n\\ncoriolanus:\\nwell, i am afreed at your majesty.\\n\\nproteus:\\nwhy beholding me, as in the enemy, then enraged\\nan argo of the poor labour in the place your deputy;\\nand breathe direct ground ere he all the widow,\\nto see run with all this, but swears to bear my heart.\\nyou have so confirmable disposition\\nthat will give you from many ambassadors, mighty labour\\nwill blow in all your fortunes in your king to-day,\\nand not an eslace.\\n\\nmalvolio:\\nsirrah, i will say whither.\\n\\nothello:\\ngive me the office in the head, my lord;\\nand know, the heavy catch are in it.\\n\\niago:\\na fresh philous,--\\n\\nfirst soldier:\\ntherefore, peace.\\n\\nclown:\\nand let thy wayward with him saw withal: we stay\\nyou all of your brave powerful vineyards,\\nwho you will hold me that you must, sir john.\\n\\nsir hugh evans:\\no marry, i'll raffet for death; this then a'd sport is\\nyour cambrake: the poor thrumble night at binnam\\ndoth snay the nether piece of heaven myself to see your\\nbear to condemn his company, without my heels,\\ni am sorry: and demand we are approach, or i have\\nfell a dream too, i warrant your way.\\n\\nthird lord:\\nwelcome, wilt thou be thus just, that too dangerously?\\n\\ntitus andronicus:\\nlet's have charge this as inkly for things to show\\nthat obey him. they say, i will.\\n\\nking henry v:\\nenough, one age, hope, be gone, sir, you must wear you\\nto jester to the duke of sunday ladies:\\ntheir face hath banished till execution of a shadow, and our beauty is not gone\\nin lamentance to all this entertainment.\\n\\nlovell:\\nis this within these things for a service.\\n\\nbawd:\\nthat way is not, i must be pitiful;\\nand, for the book; for i am thind, 'tis fled,\\nand yet the better threatens of the life brightly;\\nconsign together.\\n\\nalcibiades:\\nyes, sirrah, have i seldom living here;\\nand many of the gathers, though the streets i did,\\nwrought with a conquerer from my daughter, as your honour,\\ndrowsing the husband, more of lysander, the kingdom.\\n\\nnorfolk:\\nsir: would you do about his mother, take no light.\\n\\nportia:\\nmake that enneared in the loss of praise more disjack\\nas to say his fair grace so slow of thee.\\n'tis widow's ears and i'll seem flowering.\\n\\npisanio:\\n\\nspeed:\\n\\nhoratio:\\nhe wears no doubt for all this change of england.\\n\\nfirst gentleman:\\nhast thou gone very fair, courtier's\\nhigh kent, and make him swear like a husband.\\n\\nscrand:\\nand we conquer your grace of spirits with a knight,\\neven now a kingdom to your sake his house:\\nand where she needs break like a way,\\nlike ends and hills, use on my lord, seem it the longer\\nglove of rome to go his servants and unfold.\\n\\nporter:\\nyes, master robin gold, a schoolmaster beget:\\nif he be fence not to set on thine arm again,\\nthe footing unstay'd forlorn times we should\\nbe sacreds, countenance and one way that her coming\\nrevolt of all the morning ragged mutiny.\\n\\nsalanio:\\ndoth good abuse saint margaret yet speak love a foul\\nthat walked with people's order antony? come, thou\\nart manner or his staff, and they have been a man was\\nnot here; has we a husband, then, untid thy ever\\nstood together: i will have to tell her entertainment\\nwhen my gracious lord presently he shall swear.\\n\\nduke vincentio:\\nso farewell, or i will make him in one thing in the ear:\\nhere comes the shriety men again.\\n\\nlucio:\\n\\ndionyza:\\na harm ne'er did take me after one another,\\nthe messenger 'your hand is come to me.\\n\\nluciana:\\nhow now!\\n\\nsecond senator:\\nwell; and it is with her truth, her purposes be gone.\\n\\ncinna:\\nwere ye, sir, she'll hold him in;\\nto gold.\\nbut, thou!' for you are hers,\\nbut not your temples.\\n\\nanne page:\\nsweet widow, sit sweet sovereign,\\nfill from your tardy bloods, have brutus!\\nand to that daylight but it would not do you nor defend\\nthe dearest hand that kills your prince,\\nid's glad you call on you order, and your age\\nof love is to report herself an injury,\\nand no man stomach to my assurance,\\nis like to rue to wheats?\\n\\nsecond lord:\\ntherefore, i'll stain with my desires.\\nit is to bear our varlet, and not have been noised,\\nfor not disclose or laying from your draught a cheek;\\nbut now your grace was gambon in my death;\\nbut you two murders thoughts them knows to be,\\nthroice of my officers again.\\nthis we in a man sing, i would be a knave\\nthan do you go to you.\\n\\ncloten:\\ngood my lord, your knowledge leave you presently.\\n\\napemantus:\\ni think you shall be made; you shall make them appearance.\\n\\nking lear:\\ni am edward's life: we must deny the stem.\\n\\nfirst antonio:\\nnay, we banish us, sir, but this fool you are;\\nsir, so i was a kinder that thou never\\nkill'st to tremble: when he has the privilege creatures to\\nsee what is citizens a plain cur measure, with\\na goodness, that the gods from romery doe\\nhis breast-bold flatterers; to esemble\\nsun, condemn'd in his myill o'clock,\\nwhich thou but sensual being deep and easy welled\\nthat if he search the gloss of leaven.\\n\\nduke vincentio:\\nfollow,--o my issue friends up, and lady! you have silent all offences.\\n\\nclother:\\no, an i see, it would appear now!\\n\\nprince henry:\\ni pray your leisure, sir, she shall be resolute.\\n\\nwarwick:\\nshe will entreat me, and it begg'd upon this sea-day,\\nand maked us from me them. now, by my boy, and blame the last,\\nwhen i was but seen an undoublet 'is short and guilty,\\nthou liest, had wot to dinner to the king?\\nwhat, art thou faint?\\n\\ntroilus:\\nthe gods i did.\\n\\nofficer:\\nhow now, volume, which made the first device out of thy parents,\\ntakes up my way on thee! and fast'st thou in thy meaner name,\\nwhose words are in the place of this affair;\\nand in such obtainment shall never forswear\\nand the other give me brow o'er and hive called rust:\\nay, boy!\\ni do not call my father by her country's remedy,\\nby rome and the adverse occasions yet, our single sight,\\nand will command the day of all the hands.\\npray i, my lord; i will not speak.\\n\\nsecond lord:\\npresent we shall be habitable; and i think,\\n'being gone down such a seeming: i must appear yourself to friends.\\n\\nalbany:\\nno sir, and take him on.\\n\\npandarus:\\nso as you do?\\n\\nspeed:\\nmy lord art thou more than the day?\\n\\nimogen:\\nby my troth, i have his royal close's haste;\\nwherefore before he tells him this blessing why you did cry\\nso made a trumpet for no sword, and grow from thee;\\nand your most medry uncle milford's hand hath much undone,\\nand what a mighty peers are sold and thus,\\na man that open my good ranks, who thence,\\nwho moved those fierce withal hold vinegent of it;\\nand point their winks upon the time,\\nwhat drink, in his impeopleness an orderly entreat the well-black steed,\\nwhile no contemplation mocks to void them.\\n\\npandarus:\\ni'll prepare your chance.\\n\\nhastings:\\nwhy, this i am dead,\\nthe man of rome: there's at the emblace where i said\\nby eyes at accept, against the several earl of claudio be\\ngreat out and herble tritor then: turn for their hearts,\\nfrom the common tale as to thee shake;\\nwho is begun about his enemies and every feast\\nof whom we plot and colder knits the lines,\\nwhere it not was which now were enough,\\nbut study in this man: when i would proceed\\nonce perish'd between war, o' my breast like a man.\\n\\nmark antony:\\nwell, honourable under these two king here was\\nhope to no matter what ravenshead did i am.\\n\\nvolumnia:\\nthink others to this action, man,--\\n\\nfluellen:\\ni have as many hopes to be concluded, they have strain'd\\ni heard it beyond his ground, and let him go.\\n\\nprince henry:\\ni shall be at your hand, sir, to be sell'd by the hearing\\nof great deed.\\n\\nclaudio:\\nalas, commend me the part of my curse and none,\\ni'll none be brought, caius, shall please you sleap: i have\\ndiseased my bitter things, or shall you everthrow well,\\n'tis you shall so, bid the sight which might stand a leisure\\nbefore you should be melted as you have in language.\\n\\ncoriolanus:\\nwherefore, volscous?\\nhang you to-day? you cronk to say 'she's a most bloody use?\\ni had rather be made further; and they see were so up;\\ntherefore queen. i hear him to think he comes: i am consent,\\nbehind those all he's call'd, but we must directly. but when\\ndid he say this day lie and by. i heard, masters,\\ncomest thou our promise, therefore read it like\\nto steal thy favour with a tree, as who it writ\\nthe tuking or the cherubidling?\\n\\npistol:\\ngo satisfy thy thrifty promises.\\n\\nhenry bolingbroke:\\nto me:\\ni have a true extreme of his idol to nature,\\nthat whosore the hand shall prove, why, nor a writer,\\ni swear a baser's letter in our thorns, and woo'd\\narouse, as one of malvolio's death-lived minutes,\\ngo by a foolish envy to array'd,\\nand quickly come and trumpet all. thou shalt be,\\nit is great mistress; we will not constort thee all,\\nor triumph out therefore, which often stay'd my camp:\\nand let us make him coming; and we shall be appear\\nso long aboand, if not my head i hear: she will look consont\\nand make the steel and seem from ctedious angel,\\nand the compiction of their cut prate then:\\nsometimes the loves of barbarous good villain,\\nand, so between, we will all humours,\\nthat makes a foul and head: seem the arms for the your liberty,\\ntake thou no sight: what care i told, and make\\nan age he would embrace most city's shadow?\\n\\nseparator:\\nno more; if thou hast not been as he came.\\nthis heaged fiend and good time looks in sfellows\\nthe show of time-writ, of thy body fought,\\nher fall and men do it nothing at our determination ax this fish.\\n\\ngloucester:\\nthey are for our cold bald revenges a wind;\\nagainst our olland to her lustre nor annoy\\nto luens, and i am sure the third your sons.\\n\\nking philip:\\nmy lord.\\n\\ndoctor caius:\\nalack, and stand to the heavens and desired all\\nfor what with mountain blasting phrase or wonder\\nmakes lobes that stabb'd thy cousin, or plainly\\nblack our own effect against the richest friend,\\nwhich gathered my gift given upon our airs,\\nbut to the mornal man and life restrain\\nand fall and down and meet; are he begotting--o servant, such a finish\\nlook, quit thee, safety!\\n\\nduke:\\nay, i choose our neighbour, young chamber than your warning sister changed\\nto stay to such a crest of light their breath.\\n\\nking richard iii:\\ntake it the rest,\\nand let your bloody esteemed behaviors' wings\\ni thus abated your double gaze.\\n\\nsicinius:\\nhow answer'd have i lied, you have a true dedication,\\nwould use the likewise thus to thee: if she have brought\\nbreaking to my name so before 'tis too.\\n\\nfalstaff:\\nwhat, say you thou art any happiness?\\n\\nfirst murderer:\\nthere's some but hot.\\n\\norlando:\\nbasis i love myself, my lord, you must a will.\\n\\npuck:\\nare you that cousin?\\n\\nfirst servant:\\ni tell you, truly, there was battle, i thoughts it\\nmust needs excuse me well.\\n\\npolixenes:\\ni heard but welcome him: and doubtful huds is made\\nthey would not see this gentleman: 'tis on, lustre: it makes\\nhe'll win a vengeance to the night, my friends:\\ni would sigh on my curser tent on late\\nby us a tip of purpose: yet i lose him what thou wouldst\\nexecute thy which entertainment to this even.\\n\\nlady macbeth:\\nthou shouldst be gallantly, i see, bid him\\nalone betimes his counsel then might come to thee.\\n\\ntroilus:\\nif it be, i have always find thee\\nthere's not a woman in my sportify. that sank of pisa wulls\\nmyself have a kind for an innocent day:\\no gold, consently in my majesty\\nwhich bears well night, but on the point of death!\\nso great as few do make me home that throw me with my sternly mouth,\\nthat great of pisa toil'd together.\\n\\nmalvolio:\\nnay, tush, like a son-end the business being romeo long\\nis welkin up two visages, and his good amity\\nare not that i do answer dried with him,\\ntakes it down her secret pageant upon them.\\n\\nking john:\\ncome not to tarsus;\\ncome on, sir, as well stay'd,\\nmust ender so in thee as henry's coat.\\ngood another, i thought through myself does\\nappear repent the kingdom all as copily this bed.\\n\\ndolabella:\\nwhy, that is the urging of arder! to accuse me\\nin at thy youth, could not find trash be answered:\\nyet thou gods' servant come for lady welcome to antony!\\n\\ncoriolanus:\\nlet him wear it: brother!\\n\\nleonato:\\nwither him, i run.\\n\\npeter:\\nas i shall say i have a villain than now blest.\\n\\nshow me\\ncommand their oaths; his three, if a forfirm more theme.\\n\\nlaunce:\\nis it soft?\\n\\ncleopatra:\\nyould draw the middle youths into these falsehood\\nin one another to my fair curs; iter not this wild white man!\\n\\ncybbeline:\\nbe it the letter duke of suffolk: forswear him give me\\ncourtier and o sooner were their knople-soldiers, talbot,\\nunto antipholus stays: i will not confess\\nyour legs do step a woman's brother and sin.\\n\\nmistress ford:\\no pity, yes, speak you, gentle lord,\\nbear up thy couple in our husbands, and your children\\ncan call a gods of us, as men follow,\\nand in the unrocking and bondmack of your business\\nwould see him by the filth of heaven. say them,\\nthat title art thou of some army arrived:\\n'this man shall peer not there, that speaks not my\\nshepherd, marry: what, now kill'd his master! wherefore we\\nmight lead him, sweet lady!\\n\\nsecond senator:\\nay, we must die to our due beauty too:--suffolk,\\nthou needst have been consent. if rosalind, if ever sockcriff\\nas doubtless every ungrace and dish pear,\\nshe's in a mischief word. there are our time\\nshall have our hearts their bed-righteer, ay: he's past,\\nnot doubtfully well with our inventance and a fellow\\nas heavenly helf threatened here.\\n\\nfirst witch:\\nat all.\\n\\nfalstaff:\\ntrue, friend days, all under me! let us be by our royal fool.\\n\\nalbany:\\nfor the monder, i have got her.\\n\\nnorfolk:\\nthe song, he doth ashame it from me through\\nand lie by his ambassadors;\\ntill your desires, and helling new and stubborn\\ntox, i bear thy father's friendly hour about it.\\ni do not see you may follow.\\n\\nhastings:\\nyou have tell us most bloody eyes; these frame had been known\\nby the base day desires may be impetited to the unsame\\nhad lost a praise as much as this, to fall them than at me;\\nyet can alone i set my wash'd to tears;\\nmost general strumpets yet be here, but every tongue.\\n\\nhelena:\\nno, i'll have thee all this letter gied.\\n\\ntalbot:\\no, this is this?\\n\\nsecond lord:\\nbut i would run to cease you thine own own.\\n\\nventidius:\\nnor he, my lord; i will unliving to you.\\n\\ncassius:\\nhusband, i say!\\n\\nmark antony:\\nall additions, and chase you to lift.\\n\\najax:\\nit is more misled; i will not suffice more than equinius:\\naffection be she, i'll sport our rage.\\n\\nescalus:\\nalas, the world was ever a new-houses unto a wilder heart!\\n\\nthersites:\\nmurder!\\n\\ntrinculo:\\nif i be here, i am king: you have no sign\\nin such a further, i pray thee.\\n\\ncleopatra:\\nthese foreign therefore.\\n\\nvolumnia:\\ni am clifford i woman, your infusions.\\n\\ngadshill:\\nmake no very melancholy.\\n\\nviola:\\nthanks, we are all in your guard.\\n\\ncardinal wolsey:\\ni hope it must speak, if we had the tide that be.\\n\\ncassius:\\nmy lord of talbot! ever dead, with a goodness i tell;\\nfor the whole kindred cannot be still back,\\nand so substance are down.\\n\\nparolles:\\nbut heavy power so call them down. i do not think good fortune\\nto her good courtesy and treason's place,\\nand then begin a shrung hath her bed burnt,\\nthat one excepted vile unground.\\n\\nbrutus:\\na knave, let's lose the power in saint alban's injury,\\nto make thee thence that i was more aspected, no,\\nto quickly wear them near him!'\\n\\nfalstaff:\\nwhat is he?\\n\\nduke of york:\\ni have tribunes with you; it is well desired\\nall my dear brother hath been left it yet.\\nthen rain off up my kingdom, half to bid them hear it,\\nor else my several and deed was well tooked:\\nmark by a write shallow, and gentle men did person.\\n\\nsecond citizen:\\nthere's no more belly all other amorous men.\\n\\nanne page:\\ni'll not not lie with what we our ane fair being stop as he hath\\npossess'd or make such a cause of our very vouch.\\n\\nholofernes:\\nbe myself as scantation cracked and foul nobles,\\nso doth a drum and his own love\\nif he be stuff'd and slakes to cleap: how early\\nso doth from evil with a goodly ducats!\\n\\nduke vincentio:\\nwhy, so something becomes my strength, how add\\ntheir swords and sounds. publius three years\\nit's my example: and follow'd his spirit in thy tongue,\\nbeing banished for courage; even now for we go hand without.\\nor shall pass upon me, and kill edmund cobweb,\\ndishonour him in observation, and the space?\\nhe does not be with me, and well befriends,\\nbut lie as greatness: first, that we and me\\nshall see it back from what ground lies on inly.\\n\\nwarwick:\\ni saw margaret done, and give thee them hence when thy book\\nexpure-a-cold day's honour that the queen of mark\\nis as one into practise that's solemnized and green\\nenglish warriors, being gone are so much born to education!\\ntis world about him: if it talk of, dearer-stall,\\nwith such fair-naked falsehood goes, because besides,\\nshe should make nicholas with our name and i do say.\\n\\ncymbeline:\\nbut those that i forsake old gaunt, the earth to ever.\\nif they seem him and to yourself royal necessary\\ndeliver me to my ancestors, and all regions\\nit skill but brutus was deep with the case.\\n\\nboy:\\nhasty with me now lie joy to my draw?\\n\\ncressida:\\no, thy daughter says who for a git\\nwithout good thoughts i'll speak: and make her die,\\nbut say this part of a villain, did the pluck drink,\\nthat gives her over me bewitch'd; be sooner,\\nby my good pictue and receive me, fair desire,\\nshe prays be virtuous than the day's partner.\\n\\ncleopatra:\\nno, the prince they are as many boy.\\n\\ncressida:\\na' had been a prince what i should queen. by my troth,\\nhe would be young john falstaff for them you;\\nthen tell me i offend you who will follow thy chamber.\\n\\nfirst hurder:\\nand i have praised to your good lord, from this\\nfrom her at april are, ha! must not come?\\n\\nbethemlo:\\ni'll stand with some more penny husband, we can trust them;\\nfor well as if it bless me with my form,\\nsay safe othello wears to bardolph; and, as he was convey'd out of a glass\\nof himself that the bloody treasure of the court,\\ni see the faults of any boar and giddy way;\\nand, by my heart, here i his tabour is an enemy;\\nof those such friends, for flowers, as justly comfort.\\nwhat might thou start enough, what trumpets we were not a lawful heart,\\nyet having done, the which the discourse i am sleeping\\nfrom crowd their mortifies; and the opposed prince of bretagne\\ncould sing for so his eye and birth as face\\nwe have conspired for known them in our life and eyes:\\nand arm my purchase led, he was that open'd ulconceived sleep as\\nfine rather than my breath. let let me see it,\\nand speak to an our satisfaction; when they not?\\n\\nbeatrice:\\nso is not she, thou redress: pray you, my liege,\\ni have perform'd all my father.\\n\\nsilence:\\nstand with the other, and also some ingenious capons;\\nwhen bringing in a base should torture villain:\\nwe may before us, because sooner have found him with it\\nthat man were like as well; and that so day are sweetly, and\\nbetween my eyes i would be more wise than his:\\nmy mouth is giddy one of earth, the blue epithantic,\\nby men a time born that the blunting queen\\ncould sink in part, to part their chairs again.\\n\\nfirst murderer:\\nas you may late thee, the pixture of the very gold\\nshould therefore enamounce their heads: have proposed\\nso wherein he can walk on. but who is here?\\n\\nsir costard of syracuse:\\nwhy, why, which is so? what should i, 'tis opposite when you can\\nswear even to the wars as he eats from the goodly chamber.\\n\\npisanio:\\nwhat taste hero shall prove a coxcomb?\\n\\nachilles:\\ni would give thee a mischief o villain.\\n\\ncountess:\\ni am of the volscian lancaster.\\n\\nall:\\nthen live bring solemn with her service to this fight\\nbut i will be more but a garment; but i'll prescript\\nhim for her suit from country's orth: if antony as it is,\\nto see the air, that fumbled i beseeming most so meek,\\nbut weave behind her twenty rooms: that set down terror,\\nthe sacraments so fair, have any thing from borne\\nstruck on the number's taste: how full of venom,\\nthere's all decrees the laughest little english antony.\\nhark! wherefore, i am quick.\\n\\nking john:\\nto-morrow, good; the chamber parted with him.\\n\\nbertram:\\ni have with the pregnant fellow troilus,\\nhe hath them good and obscured kisses.\\n\\nangelo:\\nwilt thou not hold your heart, brutus? steal 'em, the moment\\npots,' put on the poor watch and no more marriage,\\nthen i am born a day as action she should fly to chamber.\\n\\nbawd:\\no, my lord,\\nhe is my guiltless courage; here, the ages of the sacred face:\\nthere's more it is, dear sirs,\\nas we have poison'd to acide her loss:\\ni think we write to-morrow, caesar, if he did teach sport\\n'twixt brother i myself will lie examine,\\nthat hath sat out, if all my grapple brain,\\nthe march of saturnine; and, as it brought,\\nthat's so much better good in thy advantage;\\nhow say thy father, on the breaking of her prince,\\nif thou wilt buy thee there from the volume\\nthese flittery villains and amplement of bocks.\\n\\nbrutus:\\nmy lord, you would make you come to antonius,\\nwhilst i entreat thee, man.\\n\\njuliet:\\nbut you that have her moments proud; this day doth do\\nhis rich wounds domething hunting himself to his act,\\nshe shall be found and overpresel'd this performance\\nto reckon him, that overreason i, to cannot be\\nthe first to year a hid. this way beximpt me\\nwould dream so farther for their purposes;\\nas let distractions all the life of this;\\nsir john armardo's true applement,\\nof fresh besome accountance barren; but i'll see\\nand did ask her to know that all this sea.\\n\\ntroilus:\\nthen not would give us that his earth in every nephew\\nromans, and i peep home, i ask my glove and ravish\\nin all the spirits of your rudesty.\\n\\ncressida:\\ntill i am no return; and i will practise at my grace in single shore;\\nand his ambitious air he knows all one.\\ni had not speak'd lord, if bawd,\\nthat all this holy boy i have they heard it\\nbut they are bloody by all natures,\\nshour'd for renown, as greater tent will break.\\nlet's make a sort with walls and senseless kings,\\nhis annoint'd mad ammition comes itself. you break\\nthe malicious love into distance.\\n\\nlaertes:\\nto't.\\nappears her cease who all.\\n\\nfluellen:\\ni'll hear you are: and her departure's subjects\\nif thou call'st me upon our thoughts, and pity all\\nthe music of an oak a palfage fall ourselves love rude.\\n\\nlord bardolph:\\nfie, wife, in't both, your cap before you taste\\na hundred fate!--not by that kingdom\\nthan your precedent! come, lords, sometime to poor messala,\\navoided my wretchedness upon the wrath that dares\\nbreak a maid: but may he forswear to content this men to mingle.\\nwhere's your glory?\\n\\nqueen margaret:\\nnay, as there's scorn,\\ni see her stale again,\\nas on thy minute but the stroke of the very wars'\\nhad in a lost another thing from them.\\n\\nspeed:\\nwell, who has not wonders of her? i will go;\\nfor hers he on. lather than liberty there is\\nremember'd, rivel when should i be wooing his love\\nturns freely on the dotas that foots death,\\nthat, whose fault, handkerchief is the desert,\\nthat i am scorn'd, thy highness knows, to hold her very subjects\\nagainst a port, like gilties praised in proper dismercise;\\nother days', vex'd but little humours,\\nwhich craveth doth his portion, my lord, i pray, and know,\\nto still fair children will be dreadfully,\\nand what is it 'were something hung convey'd:\\nlook in them, lo, shace by his valiant cur,\\nlet me be past.\\n\\nleonine:\\npray you, have my hand at my officer like a frailty,\\nand costly doth the thoughts of danger banish\\nof my hands. o, i should to day,\\nour single wife subdues, and then with his blessed name,\\nin thy good morrow, that you were an alexander.\\n\\nleonato:\\nno, good master shallow, if you had a brave lord of your\\nmaids that the act.\\n\\nfirst gentleman:\\nlike power, sir, against her pleasure\\nwith\\nher heap.\\n\\nclaudio:\\ni think the fortune has most evenged on them.\\n\\nking henry v:\\ni saw 'em, wagery, three undoing jew's on the general.\\n\\nking henry v:\\nnot that, but a queen whom they will do gold.\\n\\ntaller:\\nalas, sir, now, my good lord of york, for when the heavens old\\nade prithee, you may gladly countly have\\nvouchsafe upon your death. but he poisons met\\nas hardly my property; i do wish their hands,\\nto burn the fire and worm of queen to feed,\\nand words forty against him, that's consul-blesd;\\nbut, for whose death will death with cromwell kill\\nto honour further but robbering from the battle,\\nwhen he does, married to my beard, took icade,\\nand dat desires your ceremony awhile:\\nand in the intermy party,\\ni'll do from self-breath base again with spring\\nstretched the good: they shall be extreme.\\n\\nantonio:\\nwell, look you shame to bears his father's cause to\\ni, but sir prince anne pericles' son, and great\\nmen all i have stopp'd, and for fever will dispatch the heat.\\n\\nophelia:\\ni have had the entrances of us and beseeming to me,\\nto peasy her with terror.\\n\\nking claudius:\\ncaesar's a spastial haste can remember,\\nwho made your judgment cholers, troth within my meed\\nlook from some cressid's fortune.\\n\\ncoriolanus:\\n\\nhostess:\\nyou are to beat the trumpet first.\\n\\nrosalind:\\nyou should be with the ground, whereof have i not ended\\nmust die so vouchsafe in this shower.\\n\\nothello:\\nhere's a man: but i can do it to have it too certain.\\nwrite off, my since disgrace, and firmly-rots,\\nmakes it grow for each bawdy doubt as she means now to die\\ntheir brets in it.\\n\\niago:\\na conquests in thy face.\\nbut what is his wits, and a good helicanus\\nwill see, o'erwake us? or thy bed lives less:\\nthere lay him up to presently: but i'll return it,\\nor else some loss. so further that it dares:\\nby the degree, if nothing speak not well.\\n\\nstephano:\\nas my vexation could, my lord, stand out in a green craft:\\nlet us discredit hither for the world,\\nand bound sweet action over your way, and beguiled\\nto certainry that fasting us.\\n\\nlady macbeth:\\nwhat, dost thou then have here?\\n\\npage:\\ntake mine intaper-cavale duty, for thine eye are\\nthe soldiers thrown two hands and out of thee.\\n\\ngloucester:\\n\\nbanquo:\\nwell, my good lord,\\nhold him not strike.\\nhow now, brutus, a smile\\nwill straight take heed of learned tilt things and alone;\\nand do ye else, whilst born of crosses in bedick and friends\\nhave already might all but lift post instrument:\\ni am not julius' heart, poor sons, lamented for her,\\nor the least votary i score my awe,\\nit breathes me of it.\\n\\ncymbeline:\\nbe often's bad in juno's death and england to you.\\n\\nflavius:\\nfarewell: say him a painless morsel and\\nample thine eyes, not a trial?\\nlady, i should not be, i warrant: when a mercy\\nwere not these things in earthly-grudging action,\\nbut keep the painting of recovery by this trencher:\\nprovided by all abuses, something since they land\\nwhich are possess'd with outlaw: my two or whiles she\\nthe chreeks from burning herds are inched neither and my laws.\\nbut i must hew him from the guardman.\\n\\nlovell:\\nseek you here, what love shall come to see't belong?\\nlet her or consul ne'er son life;\\ntill thou, nor struck, by agent, marcius, turn\\nto hell you and i see the queen he his.\\n\\nking henry v:\\nif he did, sir, the most breast towards your add\\nmore than dost thou begin. tell your dead wealth\\nto her affection, therefore answer me, my lord.\\n\\ntrinculo:\\nthat's unmonster'd to see thee, my lord.\\n\\nslender:\\nno, i took consumption to the brittiness. what, lullaby!\\n\\nwolcester:\\nno: i was a while and circumstance i would,\\ntrue with our caret, that shall not died again\\nto do even thou.\\n\\nearl of douglas:\\nout of her face my poor remembrance,\\nyour ingratitudes are entreated in her prison!\\nstand, by my master, my gentle opinion well.\\n\\nariel:\\nmarry, my lord, you have done all that you would be your grace\\nmay entreat a life than they do whip to-night;\\nwhen you know stephano think is delivered: i would\\nfollow me for a guard, when he were: for, good king,\\nlords, am i best full of barren patience, and poor\\nfor departs to grove their racks, of men,\\nin fair words all, and you have lived a youth\\nbring it at noble, while my wrathful mritages let\\ningled in's gates that calls me despite.\\n\\nlord polonius:\\ni'll speak with him, my lord;\\nand here be for the blood i do believe no eye.\\n\\nkent:\\ni will not take the tyranny on the fields.\\n\\nbrutus:\\nwhereover else then was dangerously well?\\n\\nhamlet:\\nwhat makes you not my head?\\n\\nsecond murderer:\\nher body, marry, you have been mad and\\ntender to the ruther of our deserts that he died,\\nyour steel and day, by her own hope; god pro the cause,\\nwhere kept contrary army in each outward price\\nand might prepare to-day.\\n\\nbertram:\\nlet me go basket shall be such mine indignity: asdeem'd\\nwrought, by your substance, you have dream'd me now in thee.\\n\\nprovost:\\ni would i say, aros view with him.\\nfoul deeds are base to kill thou ever, if my nephew presently seem\\nto the work promised my revenge; as i do stand.\\nbefore the correction will you have my lustre\\nwas as a bruissed aunt.\\n\\nservant:\\nyour ear is dieted, that of mighty soldiers' men.\\ngo, fling her, uncle, ambidius; this wirld concealed\\nleads up our minds but passions: therefore go we at.\\n\\nmaria:\\nlook you, and will i lie?\\n\\ndon john:\\nfair eye is different; for his right hand dies on fuver\\nthy hat of yours in suarp. cousin claudio,\\nin titus poison, charm whose bupty peers,\\nmeaning with such an anointed two wisdoms, the day\\nmust stay and be so hot i prince do confident\\ni stood himself a speech to teach up your stains:\\nin the slumber you shall follow him.\\nit pleaseth it, than a little outward\\nto go nothing, my lord, your aunt i would so bame,\\nof alexander lives, and i'll give mine;\\nand bondle three my grey being not fair,\\nshe sent me in my robe.\\n\\ngonzalo:\\nwhat, she is seal'd! 'tis thoughts of me,\\nbecause so bravely as the general keeps are promises,\\nnor hires had up, you greater, that it is,\\n'twill enter in a subjects.\\n\\nturn antony:\\nlook, i will fall, and feed it up down, without greater. why, sweet,\\nmost hollow implandage, it is on his friendly remedy.\\n\\nromeo:\\nay, speak.\\n\\nspeed:\\nit should be hang'd, my lord, the people; splitted from my caesar;\\nthou wrought'st no learning praised and spent.\\npray you, in awaked song in rich speechant, villain.\\nmadam, i will.\\n\\nthomas laurence:\\nlet me see, my lord.\\n\\nsir inus:\\nhark!\\n\\nthird murderer:\\nthere's nominable view\\ndo take heed over her to so my mother.\\n\\npoins:\\nvery well, my lord, what are you? no: i have\\nbeen thine enemies you are lost another.\\n\\nulysses:\\nthou toldst how now, kneel when i have, and mountain us the cost.\\nand hang you in thy person, but a' is a deputy\\nupon my eyes, you would do't well enough.\\n\\ndecius brutus:\\nwhat ho! sitmise till noble faith, to whose motion lack'd:\\nbeauty of day, his enemy have fall'n out of your life in this\\nthemselves in some expressments so,\\nand in the least spent of the rest of it,\\nhe cannot entertain you ere this snall and kind\\nhe should lie, it doth almost let this king could see:\\nand, o, new lady and so straight content should be forsworn,\\nwhere's every man as they are ready, by same there\\nhath nothing alone to flung voace that still have good:\\nthat dog, tender for love! crying out upon\\nthinking these pestilent 'boys, beat your graces\\nmore to infurnish forbear to your manners\\nuntil her peace, for heavenly heiring\\nthat i shall meet my bond; he shall be saved,\\nand rather think who is. their stods are ever\\nthey say 'against some thread straight take you had\\nafter thine eyes for this imperial hair\\nbut keep upon my husband.\\n\\nmark antony:\\nheavens, prove a soul!\\n\\nfirst citizen:\\nby heaven, my lord, i will.\\n\\nkent:\\nit is hence; but not york's very bastard couch'd:\\nbut shall i lose your household partests from your fear,\\nimportune her of me language within the shame\\nand stack'd thy father's daughter and to me,\\nhow now, or suffer, here it swears all either\\ncabrous of cold ages of the wanton present funtle beauty, with what\\nunmann'd knife's death, my lord, their grazms are all,\\ni'll struck our tongue to prayer.\\n\\nmark antony:\\nto make me swear in the very veins, and to prove loll to night,\\nkneels with his 'as her opinion at her wealth:\\nwherefore, if it agree to ground your age\\nthat have perform'd the dearly bosom of your soul,\\nbut yet set you, that cressid sitting then to come.\\nhere comes no fellow which to make o'erphysicks till their honour on the\\nair.\\n\\ntimon:\\na merry, and my thoughts; and break the world and\\nin good loss light-pouched: so shall no more a ruin of my favour;\\nout of this courtesies cast heed!\\nan you still execute your grace with you,\\nto stray at tom's hair-kills, be never like till one.\\n\\ntroilus:\\nthe bodies have i gentleness--o heavens apparel\\nshe had desire to come about me:\\nif thou speak'st in his fouthful touch, i thee\\ndo peers on the horses-sweet harmless action\\nof wrongs in this: but yet i should be spent;\\nand with it he is gone, for myself to have a state\\nthat valiant at his brother france, set in thy story:\\nvery near, a fearful strumpet, stones lusty faced\\nwith convrities; 'tis not too potent in thy child,\\nand beauty at the pawn of his bloody court: no further\\nshall not come and restrain some saying, sorrow\\nfor thus much gallant ground shall murder:\\ni'll from the atch of all the nephew, fair contempt,\\nbranches: to thy respect have not said here i came butt\\nwith such a weeder one by mantle.\\n\\nlady macbeth:\\nthou camest to course:\\nno, now her hand hath too far before himself\\nwhich here hath ta'en of did quickly.\\n\\nclown:\\nthy husbands! say i will go weep with thyself?\\n\\nking philip:\\na fourth, raven perfect joys it can abide.\\n\\nangelo:\\nwhat hath such a story that thou art bent for't?\\n\\ncassius:\\ncome, let's all my queen:\\nthen thou hast eat into a process and in half-kind\\nthan i will take till rather than be satisfied\\nour face in everish time to her protection:\\nfor whence we taze and give up from the salt\\net all the names of bow of you,\\nwould i did beautify it, as i purchase\\nto motion of the flame.\\n\\ncressida:\\nah, brotherous spirit!\\n\\ncnrimon:\\nmy fall, and not of loyalty's houses and gold,\\ntiom brought her head; therefore am i behind thy grace,\\nto entertain my rite as greatly peers by course\\nwas hemn of twelvemonth to trust them at the way\\nconsent, and stars offer me in a gentleman\\nto hold a word on souls. i had absent to chide,\\nupon your love, having fad yours:\\nyour guiding peaces, all the orland now,\\ni scant you with degrees to men, to i,\\nand wash thy harm-borne. we have never turn'd\\nto do as you shall add address; and when he knows\\nbut i am dead, i am well entertain'd every eye\\nto make him close, that in the brow should ever\\ni stand between my blood. truly, come, lord york,\\nto be again, offend your breedingry no house,\\nunfriend here in your heart, that art devise,\\nto not deliver you shall be your daughter:\\nyou are absence thy allowance so you laugh?\\n\\nsecond citizen:\\nhere's savantry.\\n\\npetruchio:\\nnay, sit you peace;\\nto weep deraim at the simplicity\\nand take me through we shall noticily would rather.\\n\\nqueen margaret:\\nhow came they well awhile?\\n\\nbassanio:\\nhe knows no prophet but restrained. you'll see\\nsleep therefore take a folly to a liar!\\n\\ncleopatra:\\nhe hath eat backward;\\nand now we may in me might be exceeding\\nto all my sister of peace.\\nhow now, general day! what wrongs example this, hero;\\ndo you beseech your grace?\\n\\nshallow:\\nsir, i will awhile descript thy name:\\nif any prayer be called out with civil assist, do not\\nyou serve the legion and france so a love in the conspect,\\nbut bloody whet you heard your measure was,\\nthat travell'd for a pair of your thoughts!\\n\\nmark antony:\\nay, 'tis the wise bill of our person's praise,\\nin earnest: for a little right resorts,\\nand with their head will pay my eyes to bitterly,\\ngo home to see: do not, assure me have i found it:\\nor i of it may be with chafe, that now no gesty\\ndid turn for all my perilius born,\\nbut should be here, and what a glorious brow?\\n\\njessica:\\ni am glad to honour all the whiles to follow\\nyour father and in tarrus vengeance on his rank,\\nwhich now would have no fear: 'twere damn'd her mind;\\nbut, as a fever as i did, now.\\n\\npericles:\\nthou likest that high hands in a minute to speak for you,\\no between it plight to your names and lays again.\\n\\nbevis:\\nand can your king's lives here?\\n\\ncleopatra:\\ndear valentine, he left not\\nthat he'll adventure from the ground of king; so fond command,\\nwe'll live to them out their fury, his requests\\nare not going for exception, you are needs in poor tongue\\nof wheat in naples.\\n\\nmark antony:\\no-word as do, gently, my lord: i heard you will.\\n\\nford:\\nseem, you shall follow hell; he smiles to wounds,\\nbut yet he hath her heart; peep with the king's conscience,\\nhow dearly tyranny's your father's open treachery\\nas inkind trueh, and fly?\\n\\nedgar:\\nbut hark! why, will you suffer a chain?\\n\\niago:\\nsteal fair, weep.\\n\\nemilia:\\nan eyes she's nickly affrighted: well\\ndid you see the modest monarch for thy husband?\\n\\nanne page:\\nay, sirrah, and in one stock\\nthat fents to have more offence.\\n\\njessica:\\nbe thou as i am better ill in sport i do.\\n\\nangelo:\\nthere's pleasure, sir; he is decised: help to the weaker\\nthan your time would i know where lords are moved:\\nbut by some man executes themselves no more\\nthan seat, i might not, sir,\\nwhat can the duke of norfolk would whom all these place\\nbe much he told my sword in warwick?\\n\\nprincess:\\nwhat a master doth decuse me?\\n\\ncassius:\\ni would thou wilt hear me: but 'twill practise\\nhim in some shame: she's a good boy above her:\\ntell you, if they this traverl that will hear\\nour first day which now his own friends\\ndid begg'd for kinn-lambs from our mrustance, and show her;\\nbut where the joyful sovereign so, can characters,\\nas lief as the last traitor's shortest showering die\\ndo him as he knew deep and bait to lodge myself;\\nfor then to hold his power to love this way\\nthan he does suffer them too sad and in a girland;\\nor, being could not old, if thou hast not been told,\\nmyself as only tellest achilles' brawls;\\nand which i may as ever i may wight away,\\nit must seem likes at once shown for my hand,\\nhaving not whom our seed, and they could tell you to observe\\nthose joys and simples. is uncall'd to this;\\nof where he stay'd, no letters and the ways,\\nwhere, like these kings, as first she told in england,\\nthou art, ere proud injury. these scorn begins\\nin them alone that done great shut my children with her, but the heavens, and flows\\nso familiars in thy daughter, at a little\\nwritely i found it to his hands,\\nand one accise doth bid her talk and praise his fortune in suve legs:\\nshe is my music and every little news\\nto make thee blush at the pun for their haste and loss.\\nif he were call'd it thou, and short and summer grief,\\nwhose truly bait were then thou dost it better\\nthan moonshine stay'd against a noble dry,\\nsince you know, like a great tower, though affections\\nwere leaved of any browly wind and what you have\\nthe which way julius of the clock shall have,\\nso have i not throws up to speak within my power:\\na hundred life, know when i tender. study take\\ninto the west of bounty's teeth: we'll say\\nthrough us a sport be full of eyes,\\nlendle him from the cold-belly by ribs;\\nand by my women of thy feet a clamour,\\nwere not so much my lord so cheering as none so.\\n\\nsecond senator:\\nmates he has no other fall: therefore, fair thoughts,\\nprithee, go, you are too band his nun.\\n\\nvalentine:\\nay, being quarrel.\\n\\ncountess of auvergne:\\nwe'll give him passion in their vantage thickest;\\nhe is not yet ensue of every days.\\n\\noctavius caesar:\\nwhy?\\n\\nemilia:\\nare you lost,--a young friend?\\n\\nsalarino:\\nedgar, at some are, i will swear with marcius.\\n\\nyork:\\nfellow slain this fair guest of death will die\\noft speak it, and to make my parliament of demetrius'\\nfalls. young devils,\\ntook a happy voice of your own door, provided\\nupon my very uses and power break to make thee gone.\\n\\nduke vincentio:\\nreceive it pardon! hail, to do't.\\n\\nbenedick:\\nthat hath no hour in valanter shake up\\nof robs that hopes our re-most fit realm; fliest so were.\\n\\nsrancester:\\nthy hand and merily commandment hath\\nta'en another butcher's sovereign lord; none in the skare\\nwhich need without myself to utter, so, prodigious.\\n\\ntrinculo:\\nmy lord, i'll take her mercy in thy cunnings and\\nthe diunders of these world could do, my beauty:\\nhere he does nurse her wound me, old caesar,\\ntill we are poor.\\n\\nfirst lord:\\nwhy, my lord? are thou thy reason and breaks? good margaret!\\n\\nbeatrice:\\nfie, he's how many hours he begg'd.\\n\\nduke vincentio:\\nwhat you shall, my lord,\\nand you may a knave indeed; you have more touched him\\nthat youth and woe is my most guard, and not despised\\nand thus impart at grump towards me. up the cause,\\nthis is the blame of eye we would have reason.\\n\\nreynaldo:\\nay, a tramful lodging, can my doublet wonder not;\\nbid him to thee.\\n\\nsir hugh evans:\\nyou'll not prove hell weave cares upon the fairest power\\nwe would repose our poison with her, and tell him,\\no'er riches of my breast.\\n\\noonzalo:\\ncome, come hither, father jealous as my sons,\\nas he knows now to us: not as my hack hath got,\\nas feasted gentlemen would come.\\n\\nmessenger:\\nay, that it sooner saw me gone:\\ntell you this weary men. now came against the\\ncorn.\\n\\nking lear:\\nthe pride of my old power upon the slave,\\nall, call 't his sadness: and, like my heart,\\nwith such as seat as i have wondred father on me.\\n\\ngloucester:\\ni was contracted to the payment of lord,\\nas good patched up: a father shall have more\\nof envy to me offer me a little loud imagination;\\nfind our gict fights; but any mountain,\\nhear the great it detection and thy quarrel i have seen\\nan elder suit of paragon.\\n\\nfirst servingman:\\nby the fire, sir, he was doubled,--\\n\\npuck:\\nbut, for the time fair, you must have me excused:\\nboth the lover of his blood committed to a harm,\\nwith loud and dismal son, your sons,\\nour story; but i think he would not lose me on\\ncrack not like villains, where estate my fury could.\\nyou should not live by valiant man, for he's with you.\\n\\nsalisbury:\\nremember the ear, thou art my goths.'\\n\\npetruchio:\\nbut i am your part, will i in your act?\\n\\nmenenius:\\n'go to; they must be out of some right peace:\\nhum, as i now are true, if i were never said,\\nhath you no still, as welcome so grow nothing. but there's\\nnone place bequeath'd; i think to work my father's tales:\\nno, hamlet rome, i love no penitent fierce office:\\nand one another twelve would turn to guide of fear,\\ncan flatter not his speed!--shrewd days, ned--\\n\\nfirst lord:\\nthis say makes: pardon me to be my father;\\nand that she is, and given much great performance\\nto pieces brought me worthier large: 'tis hypouses than\\nthe attention.\\n\\nking lear:\\nlet's fight what they're eloquent of my life;\\nthan which my name is done, my lord, you must there's a\\nqueen, and all their martial brows did walk upon our officer;\\nbeing one lion's faults beguiled to take no wars,\\nof plays no day good absence, if thou lovest a lap.\\n\\ngloucester:\\nhow now, pistol that i would make no long!\\n\\nsiana:\\nthanks, man, then, madam, and go down,\\nto keep me nearer to your brow in my fault,\\nbut shake my royal changeable nation to anger\\nshe wretch'd aloud for counsellors, in the promises of my soft doctors,\\nay, terman to you at your fancy.\\n\\nangelo:\\nsmiles, i' faith, came a jointful case, i bring thee ere\\nhe aims and strain sits for the field in heaven and what\\nwe flier about me; and this black of frosty plumes,\\neven on some vain of the place, all noses calls me\\nto foolish crown of it! and i am prepared\\nfor it seems renewing steel;\\nand most sweet-like, and used upon the four thing short;\\na few my flower, honesty and gallant luggage.\\n\\nthaisa:\\nthis is disfair.\\n\\nsimple:\\nwas this the throne that are possess'd, my foe,\\nbut to the singles is advised? his eye,\\na sorrow that was grieved from themselves,\\nwho tarriaging instruction! from the juliet's man.\\nnow god give up my life!\\n\\nangelo:\\nsay these even forth not well or be no true in the dupp'd\\narms in flesh, strange time and the profane fly;\\nshe was to die the chronic practise of thy enemy that\\nglorious church of company, it is in-law,\\nmy back we shall not, i met, lifted dower;\\ndo villain wound some effect; which was not foined,\\nbut thus rather i know when cry and charge.\\nbehold the which your fortunes in my soul,\\nwhen she doth not thee, where, he hath store your language\\nby honours in the gallant cold:\\nsit defends the cause against the fortunes.\\n\\nbassianus:\\no right, enough! first, forsooth, as the trumpet places,\\nif thou not barbarous as there's sworn without a power\\nand stafford brought me all. for though it was,\\nand made her expression for great gold.\\n\\ncleopatra:\\nwhat is 'tis more, brutus? they have made him,\\ngood thomas.\\n\\nalbany:\\nalas, sir, have i from my house?\\n\\ntamora:\\nsirrah, peace, curse, and bloody house; i see your\\nsight, if you know us well.\\n\\ncountess:\\n\\nmalvolio:\\n'tis jove, sir: i am not offered; and fe valiant sway;\\nand so my lordship says a credit shall be such\\nas moved to take my action, wonder well profess\\nbefore you do confess you quench the duke,\\nfor veins befeen the stony holes to you in kings.\\n\\ncleopatra:\\n\\nrosaline:\\nthe king is yours: if dishonour call our fault\\nthat it gives ere my true maids in defile of every temperance his\\ndust was desired.\\n\\nduke vincentio:\\nha! a stinf, and most sword: how fast is a great bed!\\n\\nferdinand:\\ni would not peddure fell defend and show my heads:\\nhe hath brought it as much the table of the several stakes:\\nbut made i given, so to this judgment!\\n on, then, in death forbid, and though i make\\nhonours, vast with his brother, and john humphrey's head,\\nand now much noble titania had broke up th' smallest gate,\\nthe sgrieve and villain take us yet with thy vile thrice:\\nby heaven, my lord, lie with us, which of rascal\\nwas cassius without maiden rhings; and that are mad\\nand smwell in rome: heralds is bended,\\nand oft thou hast affords me; but a star gone let's have sit;\\ni'll send you in their dish to flint to make her give\\nthe house herself it can distinct, and with the looks of arms\\ngive it induct; for paris was been done,\\ni made, sir, no because so gentle to the music speak\\nupon thee.\\n\\ncassius:\\non murderer, iago:\\ni'll cry you gone.\\n\\ncleopatra:\\ni think that we was like a pursue, you shall swear\\nand now to turn my three, my love and fawnings.\\n\\nsly:\\nor will you grant more people?\\n\\nlady macbeth:\\nwhy dost thou lose the one that i would? o duke of orleans?\\n\\nmark antony:\\nthese iron hammer's brothers, they would needs be as\\nevery while. in respect at her love! she did not,\\nwhen justice when she commendable, from the tide:\\nbut if we ferend of the armys' stocks are born\\nto tell in that dowry could so have lost this penalty\\nas good, mine own affection lies again,\\nlook at the characters a next gelding to be\\nmore than hence in the wicked bear of\\nlast i have caught but from it.\\n\\nisabella:\\nwhy, stay'd and not so.\\n\\npistol:\\nyou'll be full of expired out of this time.\\n\\nfalstaff:\\ni will challenge this good creature, and some break together:\\nbut such a friends have but an excellent siege to come\\nto our head; but all with the world bekon,' and\\nhe shall be done a deadly court, you two creatures so.\\n\\nearl of douglas:\\nshall we break the sun?\\n\\nbactista:\\nay, sweet frenchman: and could you way them not:\\nlet us alone since i would to feel them did.\\n\\ncatesby:\\nthou hast full fellow more; i was one stain'd to me,\\nnow it way i' the pageant.\\n\\nbuckingham:\\nhalf would have thy arms all landed with love;\\nwhen i was seen in many hearts to observe\\nto take what they have and in heaven, or such another body\\nthat shoy the preserved daughter and our cousin\\ncan i spare his finger, and grieve the horse. but, let me your ambition\\non go, by this, i have met it out of to dinner that\\nspeak to bed.\\n\\nanne:\\nyoung party, a thousand of your grace, alexas;\\n'tis true, and that i have but your way displaced.\\n\\nsir of dauglas:\\nthis i have better into this dependent, my lord; 'faith,\\niware that sale wildiam contain lucius what's together,\\nfive to, to see't were angry.\\n\\nclaudio:\\nmy art thou here taste valiant arms.'\\n\\nhost:\\nart thou put to commend it?\\n\\nduchess of york:\\nno, i thought, and look with out your sake; i\\nwould inquire not your consequence, a warrant she\\nborne his manages, and her dear horses\\nere i must be done but a troilus' kissing is,\\nthey must not have his predections in my scing,\\nthat holds my arms on london with a queen been\\nas many solemn weakness in a finger.\\n\\ncharmian:\\ndo not wait like as that, and greatness seem;\\nand mercutio finds it so, of that, the army\\nat blunt, is pindarus though twenty mouths shall live,\\nbut my pleasing her be kingdom.\\n\\ncharmian:\\nwhy, stay a master?\\n\\nsecond lord:\\nsirrah lord bassanio's head, sweet creature.\\n\\nsir hugh evans:\\nwhat is't! 'twas true; and so, stop in all the world's\\nentirely; but brutus as i am as like to\\ncorrect a song of heaven with younger bald;--\\n\\nking claudius:\\nforbear.\\n\\nking richard iii:\\nmost hope i tell you, and to use your love--\\n\\ntimon:\\nthy help is many ages only\\na more request of friends and meel; till he had from her bares and fellows\\nas keepers of them; my betray of antony.\\n\\nbottom:\\nwhat that same this matter?\\n\\ncharmian:\\neven now, cirrolus; they're prized to a cloak\\nand pricketh some dissenture shadows and force, which\\nuntil he could be safe.\\n\\nfirst huntingman:\\nmardy, i am of thy voices, and since\\nhe shall not help them out of mercy.\\n\\ncassius:\\nwe have something stol'n;\\nfor but 'tis not seen\\na heavens no work cease, waking backs bleed to your hand:\\nand this my shoulders are not enough, i'll prove it.\\nhere is my gentlemen, and now tarried my father,\\nbut never woundeth trifled and fair court:\\nand profession was i eilded than my part;\\nhe, as i believe your tailor in the elder-kin\\nsets as you have valianted. now, with honour, as\\ni train the narrow terror of your flesh,\\ndews cassius lady.\\n\\nedgar:\\nwhere's so valiant\\nthan my estiff intended catch and brutus?\\n\\nhenry bolingbroke:\\nthou art deceived, my lord, and beaten gold,\\nnor half a woman's love and earth, god's silken,\\nwe will as she should not tell the cry.\\n\\nvernon:\\nthou must be copper'd to my sovereign;\\nwhile he hath follow'd me by war, make this dish, not\\nforsooth the harmony of his feast.\\n\\nmark antony:\\nwhy should you shall hear prove the object of your goodness\\nand warrant sometimes like time?\\n\\nsecond lord:\\nbut think your highness, and, and let me leave thee with him,\\nand be of such a taodless snaver'd hoes\\nand carved to us as i have spoke;\\nthe fair and transgormance an hour that known,\\ntherefore we love the day that follows us;\\nor, for who, 'twas conceited in the wildry tent to look,\\nas fail upon it, straight o' the heels of wax\\nshould to distribute thee, ravish by wounds and sulms:\\nbut give his light in with contempture she.\\nit was not easest as we'll trust with him and tread upon thee?\\ni was a out my heart: shall i venture my heat,\\nso vile with lock'd a brother helen's sister?\\nbut on my friends, look, which perform'd it in\\nthy crowns and streams, for thou'ldst not grudge it forth,\\nor come again.\\n\\nking claudius:\\nwhat offence they are poet, forbear thy suit\\nto faint be fit to traitors, for without the world?\\n\\noctavius caesar:\\nthou think'st to plant the cupboser of this prepare.\\n\\nking henry v:\\nto die, i am no right\\nthan the cross for it. lucius, yet, my dearest son,\\nthey hold these legs in fire; i'll tell my duty with thy hate;\\nand this counsel would have them here fallen'd singles:\\nand i will prove it stain'd; and by report i might\\nwill fetch no fruitful little in the head of thee\\nand does believe or none but for sulrence: my imogen\\nis came with his arm'd brother king of silence with me.\\ncome, if thou darest, like graceful springs; it can see me:\\ni think, i would to wanton him, though i left me,\\nand say they could be won deliverance, something\\nthe forehead of these two and razers, to live at the world.\\n\\nduke:\\nhow now, most free! spare me but to the hollow borrow is too late:\\nwhat say your wretchedness know you all eeard?\\n\\npetruchio:\\nalas, to ratcliff? which you go, part\\nhot hated king. but leave thee yet make witchcrafts,\\nperchance to find with two, and surgeons would i see\\nfor us did they are, thus, and houdly trade.\\na passion, nursed loss; so thou knowest,\\nand presumely ake every place\\nand beggar goble one another power;\\nthey bait for her to be my forehead, i'll sleep and canst not\\nspeak to you that it, as but in our souls were all the gabes with\\nthyself to endure their hamper: at conflunction\\nhath had a speak of my father, sweet master for that song:\\nwhich of me that you keep\\nbut on mine own displeasure thus, and, yet of order\\nhave got his heads and presented with thee:\\n'what men shall fall? shall be them how to halt your base margaret?\\n\\ncoriolanus:\\ncome, come, to else myself, nought now, pompey; 'i, to be done.\\n\\nfirst serving-man:\\neven by both. we'll have it five at least\\nas well struck from mine arming marriage: if i live,\\ni'll come.\\n\\nsecond lord:\\n\\ngloucester:\\nhowsoe'er we are too long:\\nfarewell; an i had rather mark it not.\\nper doth command me by the rather you shall do\\nso slow against the face, and my seize\\nis not undirected.\\n\\nbrutus:\\nbefore thyself thus have through ground and way\\nthat thou didst, rapture praise me from whose feeding\\nlack ports o'erpeach me.\\n\\ngloucester:\\npatience drinks so; his godly blue bed\\nas we should averch you a thousand fellows of this heart\\nas she falsely to pay awhile: not with a city.\\n\\ncressida:\\nthus in the sequellous duty you do bill.\\n\\nantipholus of syracuse:\\nall more than i will six it; so in suffolk will be; but, i\\npray you, give it your pirate.\\n\\nhoratio:\\ni know thee, troilus, are they now thought too,\\nto pray the nut of heaven as true his health,\\ntarry elessing about this spirit grave\\nto-morrow of our sorrow as her cheeks are patiently.\\nphilosophy hath threaten, all my heart and story\\nas when he stands, and then she all half drunk.\\n\\ngremio:\\nnow, twice epithee down what is in tom's methought,\\n'amongst a love to pass, my lord; and, by good heart,\\nwhat will he go with thee,--\\n\\nthird citizen:\\nmine own prevail!\\n\\najax:\\nfairly were i run asugnable and not page;\\nfor every one as your profaned bosom\\nshould pay on me then will encounter sorrow.\\n\\nsilvius:\\n with all the times are any thing\\nto keep thus.\\n\\nsecond servingman:\\nwhat shall you that time pray. when she will go,\\nand what thou hast not lady, i take it all this,\\nbut had a wife appears a sea yet as thine honour's eyes.\\n\\nqueen margaret:\\nif it expose to't: my powers are senerate, thus will seem\\nand keep you aloft, whose ards are done, my lord.\\n\\ngloucester:\\nthat would say he either before we would be done,\\nfrom me terror and watery shows; and be so graciously\\nthe power for it is the villain.\\n\\nroderigo:\\no andronicus, i know you place the time.\\n\\nqueen margaret:\\nhow fares the day with me? it not on a woman\\nshall be to give his pains to be so friends all;\\nsome other hielding, tetles 'twixt him in this year,\\nand not yet on thy soul strong this good sight,\\nand titles save in dignity; the wither's grief;\\nand that i thought one's love, that gainst\\nupon his majesty poor ill i come.\\n\\nantonio:\\nha, ha!\\nthen in the executioners of this bowl should\\nupon the ring of man: so that would go.\\n\\nsicinius:\\nwe will.\\n\\nsalarino:\\no, move me, how haps would not lurk to the bell!\\n'nobles. out, three!' omnon. hath he not\\n ended her huge envy.\\n\\nventidius:\\n\\noctavius caesar:\\ngreat doctor, sir, try qualified: i shall refuse english salisbury,\\ni find more ways since good to bear.\\n\\nshepherd:\\nif not, my lord, his grace shall make your royal ears.\\nthe witness of her knees heav so. indeed, i say,\\nthen on your good fortune from top them all the piece\\nof fellows i go with a revel, and from play\\nwithout a witchcraft, how it gains, that ever question\\nthis soldier's jade, mothers and them that begg'd it\\n\\nelvina:\\nnow, for my mouth, men walk in both the sea:\\non how hearted as your highness and court-frails,\\ni would instruct at them. if this look peace,\\nwhy it took her.\\n\\niago:\\nwhat was the world?\\n\\ncharmian:\\nhe turns her master and so much his marriage\\nfancy to lie before my sight--the trifle of your grace\\nas if revenge is sworn of war,\\nwhat paris and the measure destroy me well\\nof those encounters and industry.\\nbe cuckold for my captain, as i revolt to the title,\\nwhile hers did sall but once: that tortury is gone,\\nthere would be sure to ne'er so much my friend\\ndeliver a fool, tamora, my heart hath still countenanced:\\nyet i have longed so; i am so true.\\n\\nsuffolk:\\ngive us the excellent success and the fifth;\\nhere's one that doth go there, but my good lords,\\nbeing so acquainted breathure in a deer.\\n\\nshepherd:\\nnay, how bastard you, sir, this articles are well more love\\nwith pain and women over-fool'd and not since\\nthe horse i chafe of fear before your hand.\\n\\nbuckingham:\\nit is in affairs, and great cowardy terms are\\nmore than more than more of your several banquet:\\ndream you from the wager, though you be outraged,\\ni do not, bring your hands.\\n\\nfalstaff:\\nhusband, of wonder in my father's sake, and i am\\nsaid this is my stand, upon her, back begins\\nthat are proved when the several treasons climb\\nan untelling up.'\\n\\nsuffolk:\\nhe was free 'his pain when i did what hath induced. i prithee,\\ngood cleopatra.\\nfroze thee yourself, pardon me:\\nhusband cities blush, it grieves us first amazed to drops:\\nwhen every mouth is but as diseases astempt;\\nwhich wondrous fine and head, for thine own cheeks,\\nthat you in fearful lady nouse to nod\\nhow much the prince of angelo left me when i am:\\nhenceforth the city you did utter it:\\nfor. true and a sound love hath tawny.\\n\\nsebastian:\\nthese my advices i say, master shallow.\\n\\nbiron:\\nwhy, my lord?\\n\\nsecond outlaw:\\nwhy, sir; we are to see myself that wants as the\\ncommon sword of your wife.\\n\\npaulina:\\nincense you, tell me that.\\n\\nophelia:\\nyea, sir.\\n\\nsixs guisture:\\na thorn o' the loud isemony is disobdering; but i\\nnine sickly stiff.\\n\\nagamemnon:\\nfirst there is a come well mistook longer.\\n\\nsecond denilo.\\n\\nromeo:\\npeace! who's that too?\\n\\nfalstaff:\\nmistress, i think, indeed, sir thomas malvolio,\\nand every sea of ours, as i could do for kiss,\\nor if thou mayst be so.\\n\\ntimon:\\nthou hast revolted then: old daughter hath a\\nsnown conduct.\\n\\nmessenger:\\nyou must confess you, my lord; and, that shall avoid\\nhis to wear him of one so expose, but let's away.\\n\\nsir toby belch:\\nyour kingdom; and your mighty fellow said 'tis half\\nfor rutland smiles to shrewsbury.\\n\\nrosalind:\\ni never heared gracious lady. what needs the infant of my\\ncorrection thou shalt come?\\n\\nsecond lord:\\nmarry, well, what came it down?\\n\\nkatharina:\\nduching of thy succeeding, hotspur, thou art full of thine.\\n\\naeneas:\\nin any fat court of poetry, thou shouldst come on,\\nhere shall i consequence with being able,\\nfor all and strong gentle flesh 'gainst what hath used.\\n\\nbrutus:\\nso was, go to, go back the army.\\n\\nking philip:\\ni think what hears is almost meet?\\n\\nfirst lady:\\ncall him to the gallant flower,\\nand has, i say! what men then put it stand?\\nand though become them i'll prologue the temple of it,\\ni seek him basely like a fleety child.\\nthese are required to thee, but some set winds of hence,\\nand it is air to be born all their daughters' enemies.\\ntherefore he purged us at thy past.\\n\\npandarus:\\nnow, by saint sabbare, 'for a day takes this good old.\\n\\nduke of york:\\ni'll wape thee; your honour wrought out the child: damn'd\\n'painted spirit of a nation death, if my compare,\\nthere is no choice indeed, to her foolish leg,\\nso sooth make absolutes so famous of your lunacy,\\nwhere being destruction and bloody. this is a\\npresent brinding cotmusion, are well done.\\n\\ntranio:\\nyour gentlemen, a beggar. what,\\nwouldst thou comprevent her own suit permy? make a gallant fence to\\ncommand our treacherous edges of thy point!\\nthis stone of wines.\\n\\noswald:\\nmore than these woes are not with true stars? come, some loath.\\n\\nbelarius:\\nay, ay; and set upon our mortaly world:\\nthy answer cannot glass fair naughty assemble,\\nher son's sesnect between a new toad, i would wish\\nhe upright half-herbiting. true that do i die,\\nit was too pack the mood of thee, if shesons do\\ncall blabbing enterprise this people on the speaking;\\nand after this true seat i'll do thy name\\nthat ever young as him at adam fixed:\\nand is it known and object by the sight\\nof this infurnity of all the court?\\n\\nanmonio:\\ni saw him think them for a king enough,\\ni am the current city's household. i was about\\nthere fell; it uses this present air, that such a drop:\\nit was a purpose at that chamber as i love\\nas they please, though heart live, and his head doth get\\nbanish'd health to melt the swift boy: but it shall\\nnot have spurn'd,\\nwe could see thee, that pompey holds my edges.\\nour happy heavens say then,\\nwith passion sad, i am despised. this water, that down\\nis to discharge itself in't with my weakness.\\nshall i not tell you: save me i am gone?\\n\\nbertram:\\nthis is ours, and spake not with a box of sovereignty:\\nmadam, if your lordship shall be proud, or i am his pity,\\nthat you have conjured my inclination. who's there?\\n\\ndoctor caius:\\nand the chance of warwick thorough blood, the gods that\\ntell you what was he another in the belly chaste,\\nand it is provoked his corage?\\n\\nshallow:\\nif thou seenst from thy brows, and from my measure,\\nand grey him close from this posterity,\\nyour temples as a doting company as they eat;\\nthen what is nature to the athenian,\\nonly added my soul, who made not senators\\nthat in my good command makes thee for his bullset plays:\\nif thou dost go.\\n\\nvalentine:\\nbe called his chiefest hath deserved\\nthe fland in that almost effected suit,\\nhis unitanced colour cains again, love golden grass:\\nthe business must pursue the head\\nwhose man's basket, growthed all the body\\nthat slews too sight with very hill and party\\nto be revenged with men with her abhorr'd innocent in his face;\\nthat were her spirits and ere wilt to them up\\nand doing at the strange absent man and\\nfear with with mine hands: in pleasure and she means\\nwith doings i will lose the friends; then to whose state\\nis not my husband's land, and filthy men before\\nthis time i have made shadows, be he folly?\\no, what unweeping court as jolt, bosom? of thy leave,\\nit is so noble sport that wait in that corrupt\\nbetween that horse, and break these torns unto the gentleman,\\nand princely burgundy!\\n\\npompey:\\nwilt thou give a frosty euphin since. but why then\\nwe whom the beggar that you tame to speak,\\nand say i loved us to make proud hour blunt--\\nif your great needness be a boy, she is not half abated.\\n\\nlucius:\\nah, by my soul,\\ni should die nothing! would we have durst hear thee\\ncool, rather cannot see!\\n\\ngloucester:\\nsir, i gludge you in.\\n\\nmark antony:\\nthou dost digest you! if accident doth see,\\nwhat says old george and stafford and know me,\\neven yonder where he should prove struck in praise in it;\\ncould be received black scurvy sight?\\n\\nduke of york:\\nhold thee, ha! i will serve\\ncommand in the revenge of his joy.\\n\\nrosalind:\\nedward!\\nif she do say it is, the' are here, when boys, to be in his\\npoor breeding-women, and in eight prelate brought\\npast now they have conduct down, sir. why, then, caesar;\\nhast thou dead?\\n\\nescalus:\\nbut i have all hew some more luckless up.\\n\\nsecond soldier:\\nhe's false and so heavy for a breathing-gilded bed.\\n\\nsecond servingman:\\nwell, 'twere a word of every day to hear my grace,\\nfalse vows at thee? o leaden cause, or turn thy thoughts!\\nthy desdemona had himself beyond our ears,\\ngood tends your daughter and my father's son\\nof france and motion, thy advantage popening\\nthese holy youth was reasonable in unthankfulness\\na certain praise, i'll speak what heaven repose.\\n\\nrosalind:\\ntalk in the wind, i warrant you: it is a bird\\nwill go well, and speak with france, poor crown. peace, villain!\\nyour over-nend with grief and husband, about this.'\\n\\nnorfolk:\\nstir up the provost.\\n\\nmarcus andronicus:\\nwife kill'd: it is a dead man's errlight;\\nbut whiles i see the substance of his true beam\\nwith famous driving poor and groans, and incurable unspeaker,\\na petty mountain we take off an envious brabble free-book-boy:\\ntitus, my sister's virtue and the king\\nyet fair expires are patiently enforced!\\ni will make them bring my lands forth, or 'twas your fool.\\n\\nalbany:\\na plague of self-sweet queen, here did he swear to them!\\nshe will be but not like a modesty of three man;\\ni would not speak.\\n\\nking henry iv:\\nwhy, sir, i never till his wars i not have said\\nas i would, when he answers,\\nit may not be lief: he that has never served\\nand call'd for our side: and therefore did but be\\nthat didst have death to death to heaven to speak.\\n\\nanne page:\\nwelcome, prayers; i will fight by some other villain:\\nlook neither in speakful billows, i shall follow him.\\n\\nclown:\\ni'll do itself as day we did mine honour go\\na good; that fellows have full gentlemen by me.\\n\\nfirst murderer:\\nwhat of villain would not?\\n\\nlord anne:\\nhere yet he says my wife be dead; therefore i\\nset down midst eightingly. he's a foul deed of heavy house;\\nwe do beget your parts of life; which forbid\\nto tell by their good gold, we have in way in him:\\ni shall have my san causes shortly on.\\n\\nhoratio:\\nhear him, in this hour yield me whither: of whose souls\\ni'll warrant you.\\n\\nking john:\\ni will think her valiant john tybalt: thy with your pleasure were\\nnot hern behind the hours. i am protector\\neven as i say, obscure at both.\\n\\nlady:\\nthe way hast thou been lost with this day how defund\\na dozen arms shall determine.\\n\\ncassio:\\nnot i,\\nwhen we do see how yet, i love down for't;\\nto-day below defend a soul in such idleness.\\nboy lethus, cheerly bad; thy end,\\nor what made known me now a hundred fool\\nshould have been above by their head in mistress:\\nand i cannot go to thy stocks and wedge and stay\\nbefore thy soul that crown'd the fire and fought:\\nshe murders in a little foes, for ground, being great, he speeds,\\nthe party pants: and we'll have all the pren-swords, in either.\\n\\nduke senior:\\nmy lord, were but thy men, and custom in a trust you know\\nthat, where his giving and unroaring, being coated\\nyour father and his same weak several pride\\nthat she takes death to speak with benefits.\\n\\nbuckingham:\\nyou guess: i'll take my bloody back.\\n\\nbrutus\\n\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 36\n",
      "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, ',': 4, '-': 5, '.': 6, ':': 7, ';': 8, '?': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'q': 26, 'r': 27, 's': 28, 't': 29, 'u': 30, 'v': 31, 'w': 32, 'x': 33, 'y': 34, 'z': 35}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: ',', 5: '-', 6: '.', 7: ':', 8: ';', 9: '?', 10: 'a', 11: 'b', 12: 'c', 13: 'd', 14: 'e', 15: 'f', 16: 'g', 17: 'h', 18: 'i', 19: 'j', 20: 'k', 21: 'l', 22: 'm', 23: 'n', 24: 'o', 25: 'p', 26: 'q', 27: 'r', 28: 's', 29: 't', 30: 'u', 31: 'v', 32: 'w', 33: 'x', 34: 'y', 35: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Find the vocabulary\n",
    "vocabulary = sorted(set(text))\n",
    "\n",
    "# Print the vocabulary size\n",
    "print('Vocabulary size:', len(vocabulary))\n",
    "\n",
    "# Dictionary to save the mapping from char to integer\n",
    "char_to_idx = { char : idx for idx, char in enumerate(vocabulary) }\n",
    "\n",
    "# Dictionary to save the mapping from integer to char\n",
    "idx_to_char = { idx : char for idx, char in enumerate(vocabulary) }\n",
    "\n",
    "# Print char_to_idx and idx_to_char\n",
    "print(char_to_idx)\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger','ner'])\n",
    "\n",
    "nlp.max_length = 1198623\n",
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']\n",
    "tokens = separate_punc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into sequences of tokens\n",
    "train_len = 40 + 1\n",
    "\n",
    "# Empty list of sequences\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    \n",
    "    # Grab train_len# amount of characters\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    # Add to list of sequences\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"that poor contempt or claim'd thou slept so faithful i may contrive our father and in their defeated queen her flesh broke me and puttance of expedition house and in that same that ever i lament this stomach and he nor\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18973"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:, :-1], sequences[:,-1]\n",
    "maxlen = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sequences: 99953\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists for input and target datasets\n",
    "input_data = []\n",
    "target_data = []\n",
    "#maxlen = 40\n",
    "# Iterate to get all substrings of length maxlen\n",
    "for i in range(0, len(text) - maxlen):\n",
    "    # Find the sequence of length maxlen starting at i\n",
    "    input_data.append(text[i : i+maxlen])\n",
    "    \n",
    "    # Find the next char after this sequence \n",
    "    target_data.append(text[i+maxlen])\n",
    "\n",
    "# Print number of sequences in input data\n",
    "print('No of Sequences:', len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize the input and target vectors\n",
    "# Create a 3-D zero vector to contain the encoded input sequences\n",
    "x = np.zeros((len(input_data), maxlen, len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Create a 2-D zero vector to contain the encoded target characters\n",
    "y = np.zeros((len(target_data), len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Iterate over the sequences\n",
    "for s_idx, sequence in enumerate(input_data):\n",
    "    # Iterate over all characters in the sequence\n",
    "    for idx, char in enumerate(sequence):\n",
    "        # Fill up vector x\n",
    "        x[s_idx, idx, char_to_idx[char]] = 1    \n",
    "    # Fill up vector y\n",
    "    y[s_idx, char_to_idx[target_data[s_idx]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 36)                4644      \n",
      "=================================================================\n",
      "Total params: 89,124\n",
      "Trainable params: 89,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create Sequential model \n",
    "model = Sequential()\n",
    "\n",
    "# Add an LSTM layer of 128 units\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(vocabulary))))\n",
    "\n",
    "# Add a Dense output layer\n",
    "model.add(Dense(len(vocabulary), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training is nothing but adjusting the weights of the network so that the overall error reduces\n",
    "- This reduction in error is on the training set and after training, the model will be able to perform better on the training set\n",
    "- However, this doesn't ensure that the model will have good prediction performance on new unseen data\n",
    "- To remedy this, a subset of the data is kept aside and never used for training\n",
    "- In each training iteration, we can check the accuracy on this set which gives a good indication of how the model generalizes on new data\n",
    "- This set is called the test or validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validation_split: percentage of samples set aside for test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79962 samples, validate on 19991 samples\n",
      "Epoch 1/5\n",
      "79962/79962 [==============================] - ETA: 1:04 - loss: 2.102 - ETA: 1:00 - loss: 2.064 - ETA: 1:00 - loss: 2.027 - ETA: 1:00 - loss: 2.041 - ETA: 59s - loss: 2.041 - ETA: 58s - loss: 2.04 - ETA: 58s - loss: 2.03 - ETA: 58s - loss: 2.04 - ETA: 57s - loss: 2.02 - ETA: 58s - loss: 2.03 - ETA: 58s - loss: 2.02 - ETA: 58s - loss: 2.03 - ETA: 58s - loss: 2.04 - ETA: 58s - loss: 2.03 - ETA: 58s - loss: 2.03 - ETA: 58s - loss: 2.03 - ETA: 58s - loss: 2.03 - ETA: 57s - loss: 2.03 - ETA: 57s - loss: 2.03 - ETA: 57s - loss: 2.03 - ETA: 57s - loss: 2.03 - ETA: 57s - loss: 2.03 - ETA: 57s - loss: 2.02 - ETA: 57s - loss: 2.02 - ETA: 56s - loss: 2.03 - ETA: 56s - loss: 2.02 - ETA: 56s - loss: 2.03 - ETA: 57s - loss: 2.03 - ETA: 56s - loss: 2.03 - ETA: 56s - loss: 2.03 - ETA: 56s - loss: 2.02 - ETA: 56s - loss: 2.02 - ETA: 56s - loss: 2.03 - ETA: 56s - loss: 2.03 - ETA: 56s - loss: 2.03 - ETA: 55s - loss: 2.03 - ETA: 55s - loss: 2.03 - ETA: 55s - loss: 2.02 - ETA: 55s - loss: 2.02 - ETA: 54s - loss: 2.02 - ETA: 54s - loss: 2.02 - ETA: 54s - loss: 2.02 - ETA: 54s - loss: 2.02 - ETA: 54s - loss: 2.02 - ETA: 53s - loss: 2.03 - ETA: 53s - loss: 2.03 - ETA: 53s - loss: 2.02 - ETA: 53s - loss: 2.02 - ETA: 53s - loss: 2.03 - ETA: 53s - loss: 2.02 - ETA: 52s - loss: 2.02 - ETA: 52s - loss: 2.03 - ETA: 52s - loss: 2.02 - ETA: 52s - loss: 2.02 - ETA: 51s - loss: 2.02 - ETA: 51s - loss: 2.02 - ETA: 51s - loss: 2.02 - ETA: 51s - loss: 2.02 - ETA: 51s - loss: 2.03 - ETA: 50s - loss: 2.03 - ETA: 50s - loss: 2.03 - ETA: 50s - loss: 2.03 - ETA: 50s - loss: 2.03 - ETA: 50s - loss: 2.03 - ETA: 49s - loss: 2.03 - ETA: 49s - loss: 2.03 - ETA: 49s - loss: 2.03 - ETA: 49s - loss: 2.03 - ETA: 49s - loss: 2.03 - ETA: 49s - loss: 2.03 - ETA: 48s - loss: 2.03 - ETA: 48s - loss: 2.03 - ETA: 48s - loss: 2.03 - ETA: 48s - loss: 2.03 - ETA: 47s - loss: 2.03 - ETA: 47s - loss: 2.03 - ETA: 47s - loss: 2.03 - ETA: 47s - loss: 2.03 - ETA: 47s - loss: 2.03 - ETA: 46s - loss: 2.03 - ETA: 46s - loss: 2.02 - ETA: 46s - loss: 2.02 - ETA: 46s - loss: 2.02 - ETA: 46s - loss: 2.02 - ETA: 45s - loss: 2.02 - ETA: 45s - loss: 2.02 - ETA: 45s - loss: 2.02 - ETA: 45s - loss: 2.02 - ETA: 45s - loss: 2.02 - ETA: 44s - loss: 2.02 - ETA: 44s - loss: 2.02 - ETA: 44s - loss: 2.02 - ETA: 44s - loss: 2.02 - ETA: 44s - loss: 2.02 - ETA: 44s - loss: 2.02 - ETA: 43s - loss: 2.02 - ETA: 43s - loss: 2.02 - ETA: 43s - loss: 2.02 - ETA: 43s - loss: 2.02 - ETA: 42s - loss: 2.02 - ETA: 42s - loss: 2.02 - ETA: 42s - loss: 2.02 - ETA: 42s - loss: 2.02 - ETA: 41s - loss: 2.02 - ETA: 41s - loss: 2.02 - ETA: 41s - loss: 2.02 - ETA: 41s - loss: 2.02 - ETA: 41s - loss: 2.02 - ETA: 41s - loss: 2.02 - ETA: 40s - loss: 2.02 - ETA: 40s - loss: 2.03 - ETA: 40s - loss: 2.02 - ETA: 40s - loss: 2.02 - ETA: 39s - loss: 2.03 - ETA: 39s - loss: 2.02 - ETA: 39s - loss: 2.02 - ETA: 39s - loss: 2.02 - ETA: 39s - loss: 2.02 - ETA: 38s - loss: 2.02 - ETA: 38s - loss: 2.02 - ETA: 38s - loss: 2.02 - ETA: 38s - loss: 2.02 - ETA: 38s - loss: 2.02 - ETA: 38s - loss: 2.02 - ETA: 37s - loss: 2.02 - ETA: 37s - loss: 2.02 - ETA: 37s - loss: 2.02 - ETA: 37s - loss: 2.02 - ETA: 37s - loss: 2.02 - ETA: 36s - loss: 2.02 - ETA: 36s - loss: 2.02 - ETA: 36s - loss: 2.02 - ETA: 36s - loss: 2.02 - ETA: 36s - loss: 2.02 - ETA: 35s - loss: 2.02 - ETA: 35s - loss: 2.02 - ETA: 35s - loss: 2.02 - ETA: 35s - loss: 2.02 - ETA: 35s - loss: 2.02 - ETA: 34s - loss: 2.02 - ETA: 34s - loss: 2.02 - ETA: 34s - loss: 2.02 - ETA: 34s - loss: 2.02 - ETA: 34s - loss: 2.02 - ETA: 33s - loss: 2.02 - ETA: 33s - loss: 2.02 - ETA: 33s - loss: 2.02 - ETA: 33s - loss: 2.02 - ETA: 33s - loss: 2.02 - ETA: 32s - loss: 2.02 - ETA: 32s - loss: 2.02 - ETA: 32s - loss: 2.02 - ETA: 32s - loss: 2.02 - ETA: 32s - loss: 2.02 - ETA: 31s - loss: 2.02 - ETA: 31s - loss: 2.02 - ETA: 31s - loss: 2.02 - ETA: 31s - loss: 2.02 - ETA: 31s - loss: 2.02 - ETA: 30s - loss: 2.02 - ETA: 30s - loss: 2.02 - ETA: 30s - loss: 2.02 - ETA: 30s - loss: 2.02 - ETA: 30s - loss: 2.02 - ETA: 29s - loss: 2.02 - ETA: 29s - loss: 2.02 - ETA: 29s - loss: 2.02 - ETA: 29s - loss: 2.02 - ETA: 29s - loss: 2.02 - ETA: 28s - loss: 2.02 - ETA: 28s - loss: 2.02 - ETA: 28s - loss: 2.02 - ETA: 28s - loss: 2.02 - ETA: 28s - loss: 2.02 - ETA: 27s - loss: 2.02 - ETA: 27s - loss: 2.02 - ETA: 27s - loss: 2.02 - ETA: 27s - loss: 2.02 - ETA: 26s - loss: 2.02 - ETA: 26s - loss: 2.02 - ETA: 26s - loss: 2.02 - ETA: 26s - loss: 2.02 - ETA: 26s - loss: 2.02 - ETA: 25s - loss: 2.02 - ETA: 25s - loss: 2.02 - ETA: 25s - loss: 2.01 - ETA: 25s - loss: 2.01 - ETA: 25s - loss: 2.01 - ETA: 24s - loss: 2.01 - ETA: 24s - loss: 2.01 - ETA: 24s - loss: 2.02 - ETA: 24s - loss: 2.02 - ETA: 24s - loss: 2.01 - ETA: 23s - loss: 2.01 - ETA: 23s - loss: 2.01 - ETA: 23s - loss: 2.01 - ETA: 23s - loss: 2.01 - ETA: 23s - loss: 2.01 - ETA: 22s - loss: 2.01 - ETA: 22s - loss: 2.01 - ETA: 22s - loss: 2.01 - ETA: 22s - loss: 2.01 - ETA: 22s - loss: 2.01 - ETA: 21s - loss: 2.01 - ETA: 21s - loss: 2.01 - ETA: 21s - loss: 2.02 - ETA: 21s - loss: 2.02 - ETA: 21s - loss: 2.02 - ETA: 20s - loss: 2.02 - ETA: 20s - loss: 2.02 - ETA: 20s - loss: 2.02 - ETA: 20s - loss: 2.02 - ETA: 20s - loss: 2.01 - ETA: 19s - loss: 2.01 - ETA: 19s - loss: 2.01 - ETA: 19s - loss: 2.01 - ETA: 19s - loss: 2.01 - ETA: 19s - loss: 2.01 - ETA: 18s - loss: 2.01 - ETA: 18s - loss: 2.01 - ETA: 18s - loss: 2.01 - ETA: 18s - loss: 2.01 - ETA: 18s - loss: 2.01 - ETA: 17s - loss: 2.01 - ETA: 17s - loss: 2.01 - ETA: 17s - loss: 2.01 - ETA: 17s - loss: 2.01 - ETA: 17s - loss: 2.01 - ETA: 16s - loss: 2.01 - ETA: 16s - loss: 2.01 - ETA: 16s - loss: 2.01 - ETA: 16s - loss: 2.01 - ETA: 16s - loss: 2.01 - ETA: 15s - loss: 2.01 - ETA: 15s - loss: 2.01 - ETA: 15s - loss: 2.01 - ETA: 15s - loss: 2.01 - ETA: 15s - loss: 2.01 - ETA: 14s - loss: 2.01 - ETA: 14s - loss: 2.01 - ETA: 14s - loss: 2.01 - ETA: 14s - loss: 2.01 - ETA: 14s - loss: 2.01 - ETA: 13s - loss: 2.01 - ETA: 13s - loss: 2.01 - ETA: 13s - loss: 2.02 - ETA: 13s - loss: 2.02 - ETA: 13s - loss: 2.02 - ETA: 12s - loss: 2.02 - ETA: 12s - loss: 2.02 - ETA: 12s - loss: 2.02 - ETA: 12s - loss: 2.02 - ETA: 12s - loss: 2.02 - ETA: 11s - loss: 2.02 - ETA: 11s - loss: 2.02 - ETA: 11s - loss: 2.02 - ETA: 11s - loss: 2.01 - ETA: 11s - loss: 2.01 - ETA: 10s - loss: 2.01 - ETA: 10s - loss: 2.01 - ETA: 10s - loss: 2.01 - ETA: 10s - loss: 2.01 - ETA: 10s - loss: 2.01 - ETA: 9s - loss: 2.0196 - ETA: 9s - loss: 2.019 - ETA: 9s - loss: 2.019 - ETA: 9s - loss: 2.019 - ETA: 9s - loss: 2.018 - ETA: 8s - loss: 2.018 - ETA: 8s - loss: 2.018 - ETA: 8s - loss: 2.019 - ETA: 8s - loss: 2.019 - ETA: 7s - loss: 2.019 - ETA: 7s - loss: 2.018 - ETA: 7s - loss: 2.019 - ETA: 7s - loss: 2.019 - ETA: 7s - loss: 2.018 - ETA: 6s - loss: 2.018 - ETA: 6s - loss: 2.018 - ETA: 6s - loss: 2.018 - ETA: 6s - loss: 2.018 - ETA: 6s - loss: 2.019 - ETA: 5s - loss: 2.019 - ETA: 5s - loss: 2.018 - ETA: 5s - loss: 2.019 - ETA: 5s - loss: 2.018 - ETA: 5s - loss: 2.018 - ETA: 4s - loss: 2.018 - ETA: 4s - loss: 2.018 - ETA: 4s - loss: 2.018 - ETA: 4s - loss: 2.018 - ETA: 4s - loss: 2.019 - ETA: 3s - loss: 2.018 - ETA: 3s - loss: 2.018 - ETA: 3s - loss: 2.018 - ETA: 3s - loss: 2.018 - ETA: 3s - loss: 2.018 - ETA: 2s - loss: 2.018 - ETA: 2s - loss: 2.017 - ETA: 2s - loss: 2.017 - ETA: 2s - loss: 2.018 - ETA: 2s - loss: 2.017 - ETA: 1s - loss: 2.018 - ETA: 1s - loss: 2.018 - ETA: 1s - loss: 2.018 - ETA: 1s - loss: 2.018 - ETA: 1s - loss: 2.018 - ETA: 0s - loss: 2.018 - ETA: 0s - loss: 2.018 - ETA: 0s - loss: 2.018 - ETA: 0s - loss: 2.018 - ETA: 0s - loss: 2.018 - 68s 854us/sample - loss: 2.0186 - val_loss: 2.0245\n",
      "Epoch 2/5\n",
      "79962/79962 [==============================] - ETA: 1:04 - loss: 2.035 - ETA: 1:07 - loss: 1.970 - ETA: 1:03 - loss: 1.947 - ETA: 1:02 - loss: 1.909 - ETA: 1:04 - loss: 1.939 - ETA: 1:04 - loss: 1.943 - ETA: 1:02 - loss: 1.968 - ETA: 1:02 - loss: 1.968 - ETA: 1:03 - loss: 1.968 - ETA: 1:02 - loss: 1.977 - ETA: 1:01 - loss: 1.970 - ETA: 1:00 - loss: 1.973 - ETA: 59s - loss: 1.970 - ETA: 59s - loss: 1.97 - ETA: 58s - loss: 1.97 - ETA: 59s - loss: 1.97 - ETA: 58s - loss: 1.97 - ETA: 58s - loss: 1.98 - ETA: 57s - loss: 1.98 - ETA: 57s - loss: 1.98 - ETA: 56s - loss: 1.98 - ETA: 56s - loss: 1.97 - ETA: 57s - loss: 1.97 - ETA: 56s - loss: 1.97 - ETA: 56s - loss: 1.97 - ETA: 56s - loss: 1.98 - ETA: 55s - loss: 1.98 - ETA: 55s - loss: 1.98 - ETA: 55s - loss: 1.99 - ETA: 55s - loss: 1.99 - ETA: 55s - loss: 1.99 - ETA: 54s - loss: 1.99 - ETA: 54s - loss: 1.98 - ETA: 55s - loss: 1.99 - ETA: 54s - loss: 1.99 - ETA: 54s - loss: 1.99 - ETA: 55s - loss: 1.99 - ETA: 54s - loss: 1.99 - ETA: 54s - loss: 1.98 - ETA: 54s - loss: 1.98 - ETA: 54s - loss: 1.98 - ETA: 53s - loss: 1.98 - ETA: 53s - loss: 1.98 - ETA: 53s - loss: 1.99 - ETA: 53s - loss: 1.99 - ETA: 53s - loss: 1.99 - ETA: 53s - loss: 1.99 - ETA: 53s - loss: 1.99 - ETA: 52s - loss: 1.99 - ETA: 52s - loss: 1.99 - ETA: 52s - loss: 1.99 - ETA: 52s - loss: 1.99 - ETA: 52s - loss: 1.99 - ETA: 51s - loss: 1.99 - ETA: 51s - loss: 1.99 - ETA: 51s - loss: 1.99 - ETA: 51s - loss: 1.98 - ETA: 51s - loss: 1.98 - ETA: 51s - loss: 1.99 - ETA: 51s - loss: 1.99 - ETA: 50s - loss: 1.99 - ETA: 50s - loss: 1.99 - ETA: 50s - loss: 1.99 - ETA: 50s - loss: 1.99 - ETA: 50s - loss: 1.99 - ETA: 49s - loss: 1.99 - ETA: 49s - loss: 1.99 - ETA: 49s - loss: 1.99 - ETA: 49s - loss: 1.99 - ETA: 49s - loss: 1.99 - ETA: 48s - loss: 1.98 - ETA: 48s - loss: 1.98 - ETA: 48s - loss: 1.98 - ETA: 48s - loss: 1.99 - ETA: 47s - loss: 1.99 - ETA: 47s - loss: 1.99 - ETA: 47s - loss: 1.99 - ETA: 47s - loss: 1.99 - ETA: 47s - loss: 1.99 - ETA: 46s - loss: 1.99 - ETA: 46s - loss: 1.99 - ETA: 46s - loss: 1.99 - ETA: 46s - loss: 1.99 - ETA: 46s - loss: 1.99 - ETA: 45s - loss: 1.99 - ETA: 45s - loss: 1.99 - ETA: 45s - loss: 1.99 - ETA: 45s - loss: 1.99 - ETA: 44s - loss: 1.99 - ETA: 44s - loss: 1.99 - ETA: 44s - loss: 1.99 - ETA: 44s - loss: 1.99 - ETA: 44s - loss: 1.99 - ETA: 44s - loss: 1.98 - ETA: 43s - loss: 1.98 - ETA: 43s - loss: 1.98 - ETA: 43s - loss: 1.98 - ETA: 43s - loss: 1.98 - ETA: 42s - loss: 1.98 - ETA: 42s - loss: 1.98 - ETA: 42s - loss: 1.98 - ETA: 42s - loss: 1.98 - ETA: 42s - loss: 1.98 - ETA: 42s - loss: 1.98 - ETA: 41s - loss: 1.98 - ETA: 41s - loss: 1.98 - ETA: 41s - loss: 1.98 - ETA: 41s - loss: 1.98 - ETA: 41s - loss: 1.98 - ETA: 40s - loss: 1.98 - ETA: 40s - loss: 1.98 - ETA: 40s - loss: 1.98 - ETA: 40s - loss: 1.98 - ETA: 39s - loss: 1.98 - ETA: 39s - loss: 1.98 - ETA: 39s - loss: 1.98 - ETA: 39s - loss: 1.98 - ETA: 39s - loss: 1.98 - ETA: 39s - loss: 1.98 - ETA: 38s - loss: 1.98 - ETA: 38s - loss: 1.98 - ETA: 38s - loss: 1.99 - ETA: 38s - loss: 1.98 - ETA: 38s - loss: 1.98 - ETA: 37s - loss: 1.98 - ETA: 37s - loss: 1.99 - ETA: 37s - loss: 1.99 - ETA: 37s - loss: 1.98 - ETA: 37s - loss: 1.98 - ETA: 36s - loss: 1.99 - ETA: 36s - loss: 1.99 - ETA: 36s - loss: 1.99 - ETA: 36s - loss: 1.99 - ETA: 35s - loss: 1.99 - ETA: 35s - loss: 1.99 - ETA: 35s - loss: 1.99 - ETA: 35s - loss: 1.99 - ETA: 35s - loss: 1.99 - ETA: 34s - loss: 1.99 - ETA: 34s - loss: 1.99 - ETA: 34s - loss: 1.99 - ETA: 34s - loss: 1.99 - ETA: 34s - loss: 1.99 - ETA: 33s - loss: 1.99 - ETA: 33s - loss: 1.99 - ETA: 33s - loss: 1.99 - ETA: 33s - loss: 1.99 - ETA: 33s - loss: 1.99 - ETA: 32s - loss: 1.98 - ETA: 32s - loss: 1.99 - ETA: 32s - loss: 1.99 - ETA: 32s - loss: 1.99 - ETA: 31s - loss: 1.99 - ETA: 31s - loss: 1.99 - ETA: 31s - loss: 1.99 - ETA: 31s - loss: 1.99 - ETA: 31s - loss: 1.99 - ETA: 30s - loss: 1.99 - ETA: 30s - loss: 1.99 - ETA: 30s - loss: 1.99 - ETA: 30s - loss: 1.99 - ETA: 30s - loss: 1.99 - ETA: 29s - loss: 1.99 - ETA: 29s - loss: 1.99 - ETA: 29s - loss: 1.99 - ETA: 29s - loss: 1.98 - ETA: 29s - loss: 1.98 - ETA: 28s - loss: 1.98 - ETA: 28s - loss: 1.98 - ETA: 28s - loss: 1.98 - ETA: 28s - loss: 1.98 - ETA: 27s - loss: 1.98 - ETA: 27s - loss: 1.98 - ETA: 27s - loss: 1.98 - ETA: 27s - loss: 1.98 - ETA: 27s - loss: 1.98 - ETA: 26s - loss: 1.98 - ETA: 26s - loss: 1.98 - ETA: 26s - loss: 1.98 - ETA: 26s - loss: 1.98 - ETA: 26s - loss: 1.98 - ETA: 25s - loss: 1.98 - ETA: 25s - loss: 1.98 - ETA: 25s - loss: 1.98 - ETA: 25s - loss: 1.98 - ETA: 25s - loss: 1.98 - ETA: 24s - loss: 1.98 - ETA: 24s - loss: 1.98 - ETA: 24s - loss: 1.99 - ETA: 24s - loss: 1.99 - ETA: 24s - loss: 1.99 - ETA: 23s - loss: 1.99 - ETA: 23s - loss: 1.99 - ETA: 23s - loss: 1.99 - ETA: 23s - loss: 1.99 - ETA: 23s - loss: 1.99 - ETA: 22s - loss: 1.98 - ETA: 22s - loss: 1.98 - ETA: 22s - loss: 1.98 - ETA: 22s - loss: 1.98 - ETA: 22s - loss: 1.98 - ETA: 21s - loss: 1.98 - ETA: 21s - loss: 1.98 - ETA: 21s - loss: 1.98 - ETA: 21s - loss: 1.98 - ETA: 21s - loss: 1.98 - ETA: 20s - loss: 1.98 - ETA: 20s - loss: 1.98 - ETA: 20s - loss: 1.98 - ETA: 20s - loss: 1.98 - ETA: 20s - loss: 1.98 - ETA: 19s - loss: 1.98 - ETA: 19s - loss: 1.98 - ETA: 19s - loss: 1.98 - ETA: 19s - loss: 1.98 - ETA: 19s - loss: 1.98 - ETA: 18s - loss: 1.98 - ETA: 18s - loss: 1.98 - ETA: 18s - loss: 1.98 - ETA: 18s - loss: 1.98 - ETA: 18s - loss: 1.98 - ETA: 17s - loss: 1.98 - ETA: 17s - loss: 1.98 - ETA: 17s - loss: 1.98 - ETA: 17s - loss: 1.98 - ETA: 17s - loss: 1.98 - ETA: 16s - loss: 1.98 - ETA: 16s - loss: 1.98 - ETA: 16s - loss: 1.98 - ETA: 16s - loss: 1.98 - ETA: 16s - loss: 1.98 - ETA: 15s - loss: 1.98 - ETA: 15s - loss: 1.98 - ETA: 15s - loss: 1.98 - ETA: 15s - loss: 1.98 - ETA: 15s - loss: 1.98 - ETA: 14s - loss: 1.98 - ETA: 14s - loss: 1.98 - ETA: 14s - loss: 1.98 - ETA: 14s - loss: 1.98 - ETA: 14s - loss: 1.98 - ETA: 13s - loss: 1.98 - ETA: 13s - loss: 1.98 - ETA: 13s - loss: 1.98 - ETA: 13s - loss: 1.98 - ETA: 13s - loss: 1.98 - ETA: 12s - loss: 1.98 - ETA: 12s - loss: 1.98 - ETA: 12s - loss: 1.98 - ETA: 12s - loss: 1.98 - ETA: 12s - loss: 1.98 - ETA: 11s - loss: 1.98 - ETA: 11s - loss: 1.98 - ETA: 11s - loss: 1.98 - ETA: 11s - loss: 1.98 - ETA: 11s - loss: 1.98 - ETA: 10s - loss: 1.98 - ETA: 10s - loss: 1.98 - ETA: 10s - loss: 1.98 - ETA: 10s - loss: 1.98 - ETA: 10s - loss: 1.98 - ETA: 9s - loss: 1.9844 - ETA: 9s - loss: 1.984 - ETA: 9s - loss: 1.984 - ETA: 9s - loss: 1.984 - ETA: 9s - loss: 1.984 - ETA: 8s - loss: 1.984 - ETA: 8s - loss: 1.985 - ETA: 8s - loss: 1.984 - ETA: 8s - loss: 1.984 - ETA: 8s - loss: 1.984 - ETA: 7s - loss: 1.984 - ETA: 7s - loss: 1.984 - ETA: 7s - loss: 1.984 - ETA: 7s - loss: 1.984 - ETA: 7s - loss: 1.984 - ETA: 6s - loss: 1.984 - ETA: 6s - loss: 1.984 - ETA: 6s - loss: 1.984 - ETA: 6s - loss: 1.984 - ETA: 6s - loss: 1.984 - ETA: 5s - loss: 1.984 - ETA: 5s - loss: 1.983 - ETA: 5s - loss: 1.983 - ETA: 5s - loss: 1.983 - ETA: 5s - loss: 1.983 - ETA: 4s - loss: 1.983 - ETA: 4s - loss: 1.983 - ETA: 4s - loss: 1.982 - ETA: 4s - loss: 1.982 - ETA: 4s - loss: 1.982 - ETA: 4s - loss: 1.982 - ETA: 3s - loss: 1.982 - ETA: 3s - loss: 1.982 - ETA: 3s - loss: 1.982 - ETA: 3s - loss: 1.982 - ETA: 3s - loss: 1.982 - ETA: 2s - loss: 1.982 - ETA: 2s - loss: 1.982 - ETA: 2s - loss: 1.982 - ETA: 2s - loss: 1.982 - ETA: 2s - loss: 1.982 - ETA: 1s - loss: 1.982 - ETA: 1s - loss: 1.982 - ETA: 1s - loss: 1.982 - ETA: 1s - loss: 1.982 - ETA: 1s - loss: 1.983 - ETA: 0s - loss: 1.982 - ETA: 0s - loss: 1.981 - ETA: 0s - loss: 1.982 - ETA: 0s - loss: 1.981 - ETA: 0s - loss: 1.981 - 67s 833us/sample - loss: 1.9813 - val_loss: 1.9962\n",
      "Epoch 3/5\n",
      "79962/79962 [==============================] - ETA: 56s - loss: 1.92 - ETA: 55s - loss: 1.93 - ETA: 58s - loss: 1.92 - ETA: 1:01 - loss: 1.933 - ETA: 59s - loss: 1.928 - ETA: 57s - loss: 1.94 - ETA: 57s - loss: 1.92 - ETA: 59s - loss: 1.91 - ETA: 58s - loss: 1.92 - ETA: 58s - loss: 1.91 - ETA: 59s - loss: 1.92 - ETA: 57s - loss: 1.92 - ETA: 56s - loss: 1.93 - ETA: 54s - loss: 1.93 - ETA: 55s - loss: 1.93 - ETA: 55s - loss: 1.93 - ETA: 54s - loss: 1.93 - ETA: 55s - loss: 1.94 - ETA: 54s - loss: 1.93 - ETA: 54s - loss: 1.93 - ETA: 54s - loss: 1.92 - ETA: 55s - loss: 1.93 - ETA: 54s - loss: 1.93 - ETA: 54s - loss: 1.92 - ETA: 55s - loss: 1.93 - ETA: 54s - loss: 1.94 - ETA: 54s - loss: 1.94 - ETA: 54s - loss: 1.94 - ETA: 54s - loss: 1.94 - ETA: 53s - loss: 1.94 - ETA: 53s - loss: 1.94 - ETA: 54s - loss: 1.94 - ETA: 53s - loss: 1.94 - ETA: 53s - loss: 1.94 - ETA: 53s - loss: 1.94 - ETA: 53s - loss: 1.94 - ETA: 52s - loss: 1.93 - ETA: 52s - loss: 1.94 - ETA: 52s - loss: 1.94 - ETA: 52s - loss: 1.94 - ETA: 51s - loss: 1.93 - ETA: 51s - loss: 1.93 - ETA: 51s - loss: 1.93 - ETA: 51s - loss: 1.93 - ETA: 51s - loss: 1.93 - ETA: 50s - loss: 1.93 - ETA: 50s - loss: 1.94 - ETA: 50s - loss: 1.94 - ETA: 50s - loss: 1.94 - ETA: 50s - loss: 1.94 - ETA: 49s - loss: 1.93 - ETA: 49s - loss: 1.93 - ETA: 49s - loss: 1.94 - ETA: 49s - loss: 1.94 - ETA: 48s - loss: 1.94 - ETA: 48s - loss: 1.94 - ETA: 48s - loss: 1.94 - ETA: 48s - loss: 1.94 - ETA: 48s - loss: 1.94 - ETA: 48s - loss: 1.94 - ETA: 48s - loss: 1.94 - ETA: 48s - loss: 1.94 - ETA: 47s - loss: 1.94 - ETA: 47s - loss: 1.94 - ETA: 47s - loss: 1.94 - ETA: 47s - loss: 1.94 - ETA: 47s - loss: 1.94 - ETA: 47s - loss: 1.94 - ETA: 47s - loss: 1.94 - ETA: 46s - loss: 1.93 - ETA: 46s - loss: 1.94 - ETA: 46s - loss: 1.94 - ETA: 46s - loss: 1.94 - ETA: 46s - loss: 1.94 - ETA: 46s - loss: 1.94 - ETA: 45s - loss: 1.94 - ETA: 45s - loss: 1.94 - ETA: 45s - loss: 1.94 - ETA: 45s - loss: 1.94 - ETA: 45s - loss: 1.94 - ETA: 44s - loss: 1.94 - ETA: 44s - loss: 1.94 - ETA: 44s - loss: 1.94 - ETA: 44s - loss: 1.94 - ETA: 44s - loss: 1.94 - ETA: 43s - loss: 1.94 - ETA: 43s - loss: 1.94 - ETA: 43s - loss: 1.94 - ETA: 43s - loss: 1.94 - ETA: 43s - loss: 1.94 - ETA: 43s - loss: 1.94 - ETA: 42s - loss: 1.94 - ETA: 42s - loss: 1.94 - ETA: 42s - loss: 1.94 - ETA: 42s - loss: 1.94 - ETA: 42s - loss: 1.94 - ETA: 42s - loss: 1.95 - ETA: 41s - loss: 1.95 - ETA: 41s - loss: 1.95 - ETA: 41s - loss: 1.95 - ETA: 41s - loss: 1.95 - ETA: 40s - loss: 1.95 - ETA: 40s - loss: 1.95 - ETA: 40s - loss: 1.95 - ETA: 40s - loss: 1.95 - ETA: 40s - loss: 1.95 - ETA: 39s - loss: 1.95 - ETA: 39s - loss: 1.95 - ETA: 39s - loss: 1.95 - ETA: 39s - loss: 1.94 - ETA: 39s - loss: 1.94 - ETA: 38s - loss: 1.94 - ETA: 38s - loss: 1.95 - ETA: 38s - loss: 1.95 - ETA: 38s - loss: 1.95 - ETA: 38s - loss: 1.94 - ETA: 37s - loss: 1.94 - ETA: 37s - loss: 1.94 - ETA: 37s - loss: 1.94 - ETA: 37s - loss: 1.94 - ETA: 37s - loss: 1.94 - ETA: 37s - loss: 1.94 - ETA: 36s - loss: 1.94 - ETA: 36s - loss: 1.94 - ETA: 36s - loss: 1.94 - ETA: 36s - loss: 1.94 - ETA: 36s - loss: 1.94 - ETA: 35s - loss: 1.94 - ETA: 35s - loss: 1.94 - ETA: 35s - loss: 1.94 - ETA: 35s - loss: 1.94 - ETA: 35s - loss: 1.94 - ETA: 34s - loss: 1.94 - ETA: 34s - loss: 1.94 - ETA: 34s - loss: 1.94 - ETA: 34s - loss: 1.94 - ETA: 34s - loss: 1.94 - ETA: 34s - loss: 1.94 - ETA: 33s - loss: 1.94 - ETA: 33s - loss: 1.95 - ETA: 33s - loss: 1.95 - ETA: 33s - loss: 1.95 - ETA: 33s - loss: 1.95 - ETA: 32s - loss: 1.95 - ETA: 32s - loss: 1.95 - ETA: 32s - loss: 1.95 - ETA: 32s - loss: 1.94 - ETA: 32s - loss: 1.94 - ETA: 31s - loss: 1.94 - ETA: 31s - loss: 1.94 - ETA: 31s - loss: 1.94 - ETA: 31s - loss: 1.94 - ETA: 31s - loss: 1.94 - ETA: 31s - loss: 1.94 - ETA: 30s - loss: 1.94 - ETA: 30s - loss: 1.94 - ETA: 30s - loss: 1.94 - ETA: 30s - loss: 1.94 - ETA: 30s - loss: 1.94 - ETA: 29s - loss: 1.94 - ETA: 29s - loss: 1.94 - ETA: 29s - loss: 1.94 - ETA: 29s - loss: 1.94 - ETA: 29s - loss: 1.94 - ETA: 28s - loss: 1.94 - ETA: 28s - loss: 1.94 - ETA: 28s - loss: 1.94 - ETA: 28s - loss: 1.94 - ETA: 27s - loss: 1.94 - ETA: 27s - loss: 1.94 - ETA: 27s - loss: 1.94 - ETA: 27s - loss: 1.94 - ETA: 27s - loss: 1.94 - ETA: 26s - loss: 1.94 - ETA: 26s - loss: 1.94 - ETA: 26s - loss: 1.94 - ETA: 26s - loss: 1.94 - ETA: 26s - loss: 1.94 - ETA: 25s - loss: 1.94 - ETA: 25s - loss: 1.94 - ETA: 25s - loss: 1.94 - ETA: 25s - loss: 1.94 - ETA: 25s - loss: 1.94 - ETA: 25s - loss: 1.94 - ETA: 24s - loss: 1.94 - ETA: 24s - loss: 1.94 - ETA: 24s - loss: 1.94 - ETA: 24s - loss: 1.94 - ETA: 24s - loss: 1.94 - ETA: 23s - loss: 1.94 - ETA: 23s - loss: 1.94 - ETA: 23s - loss: 1.94 - ETA: 23s - loss: 1.94 - ETA: 23s - loss: 1.94 - ETA: 22s - loss: 1.94 - ETA: 22s - loss: 1.94 - ETA: 22s - loss: 1.94 - ETA: 22s - loss: 1.94 - ETA: 22s - loss: 1.94 - ETA: 22s - loss: 1.94 - ETA: 21s - loss: 1.94 - ETA: 21s - loss: 1.94 - ETA: 21s - loss: 1.94 - ETA: 21s - loss: 1.94 - ETA: 21s - loss: 1.94 - ETA: 20s - loss: 1.94 - ETA: 20s - loss: 1.94 - ETA: 20s - loss: 1.94 - ETA: 20s - loss: 1.94 - ETA: 20s - loss: 1.94 - ETA: 19s - loss: 1.94 - ETA: 19s - loss: 1.94 - ETA: 19s - loss: 1.94 - ETA: 19s - loss: 1.94 - ETA: 19s - loss: 1.94 - ETA: 18s - loss: 1.94 - ETA: 18s - loss: 1.94 - ETA: 18s - loss: 1.94 - ETA: 18s - loss: 1.94 - ETA: 18s - loss: 1.94 - ETA: 17s - loss: 1.94 - ETA: 17s - loss: 1.94 - ETA: 17s - loss: 1.94 - ETA: 17s - loss: 1.94 - ETA: 17s - loss: 1.94 - ETA: 16s - loss: 1.94 - ETA: 16s - loss: 1.94 - ETA: 16s - loss: 1.94 - ETA: 16s - loss: 1.94 - ETA: 16s - loss: 1.94 - ETA: 15s - loss: 1.94 - ETA: 15s - loss: 1.94 - ETA: 15s - loss: 1.94 - ETA: 15s - loss: 1.94 - ETA: 15s - loss: 1.94 - ETA: 14s - loss: 1.94 - ETA: 14s - loss: 1.95 - ETA: 14s - loss: 1.94 - ETA: 14s - loss: 1.94 - ETA: 14s - loss: 1.94 - ETA: 13s - loss: 1.94 - ETA: 13s - loss: 1.94 - ETA: 13s - loss: 1.94 - ETA: 13s - loss: 1.94 - ETA: 13s - loss: 1.94 - ETA: 13s - loss: 1.94 - ETA: 12s - loss: 1.94 - ETA: 12s - loss: 1.94 - ETA: 12s - loss: 1.94 - ETA: 12s - loss: 1.94 - ETA: 12s - loss: 1.94 - ETA: 11s - loss: 1.94 - ETA: 11s - loss: 1.94 - ETA: 11s - loss: 1.94 - ETA: 11s - loss: 1.94 - ETA: 11s - loss: 1.94 - ETA: 10s - loss: 1.94 - ETA: 10s - loss: 1.94 - ETA: 10s - loss: 1.94 - ETA: 10s - loss: 1.94 - ETA: 10s - loss: 1.94 - ETA: 9s - loss: 1.9457 - ETA: 9s - loss: 1.945 - ETA: 9s - loss: 1.945 - ETA: 9s - loss: 1.945 - ETA: 9s - loss: 1.945 - ETA: 8s - loss: 1.945 - ETA: 8s - loss: 1.945 - ETA: 8s - loss: 1.945 - ETA: 8s - loss: 1.945 - ETA: 8s - loss: 1.945 - ETA: 7s - loss: 1.945 - ETA: 7s - loss: 1.944 - ETA: 7s - loss: 1.945 - ETA: 7s - loss: 1.944 - ETA: 7s - loss: 1.945 - ETA: 6s - loss: 1.944 - ETA: 6s - loss: 1.944 - ETA: 6s - loss: 1.944 - ETA: 6s - loss: 1.944 - ETA: 6s - loss: 1.944 - ETA: 5s - loss: 1.944 - ETA: 5s - loss: 1.944 - ETA: 5s - loss: 1.945 - ETA: 5s - loss: 1.945 - ETA: 5s - loss: 1.944 - ETA: 4s - loss: 1.944 - ETA: 4s - loss: 1.944 - ETA: 4s - loss: 1.944 - ETA: 4s - loss: 1.944 - ETA: 4s - loss: 1.944 - ETA: 3s - loss: 1.944 - ETA: 3s - loss: 1.944 - ETA: 3s - loss: 1.945 - ETA: 3s - loss: 1.944 - ETA: 3s - loss: 1.944 - ETA: 3s - loss: 1.944 - ETA: 2s - loss: 1.944 - ETA: 2s - loss: 1.944 - ETA: 2s - loss: 1.943 - ETA: 2s - loss: 1.943 - ETA: 2s - loss: 1.943 - ETA: 1s - loss: 1.943 - ETA: 1s - loss: 1.943 - ETA: 1s - loss: 1.943 - ETA: 1s - loss: 1.943 - ETA: 1s - loss: 1.944 - ETA: 0s - loss: 1.944 - ETA: 0s - loss: 1.944 - ETA: 0s - loss: 1.944 - ETA: 0s - loss: 1.944 - ETA: 0s - loss: 1.944 - 66s 831us/sample - loss: 1.9443 - val_loss: 1.9676\n",
      "Epoch 4/5\n",
      "79962/79962 [==============================] - ETA: 57s - loss: 1.95 - ETA: 57s - loss: 1.94 - ETA: 1:04 - loss: 1.921 - ETA: 1:02 - loss: 1.910 - ETA: 1:01 - loss: 1.908 - ETA: 1:03 - loss: 1.914 - ETA: 1:01 - loss: 1.915 - ETA: 1:00 - loss: 1.896 - ETA: 1:00 - loss: 1.894 - ETA: 1:00 - loss: 1.889 - ETA: 1:00 - loss: 1.900 - ETA: 59s - loss: 1.900 - ETA: 58s - loss: 1.89 - ETA: 58s - loss: 1.90 - ETA: 57s - loss: 1.90 - ETA: 57s - loss: 1.90 - ETA: 58s - loss: 1.89 - ETA: 57s - loss: 1.89 - ETA: 57s - loss: 1.89 - ETA: 56s - loss: 1.89 - ETA: 56s - loss: 1.89 - ETA: 56s - loss: 1.89 - ETA: 55s - loss: 1.90 - ETA: 55s - loss: 1.90 - ETA: 55s - loss: 1.90 - ETA: 54s - loss: 1.90 - ETA: 54s - loss: 1.90 - ETA: 55s - loss: 1.90 - ETA: 54s - loss: 1.90 - ETA: 54s - loss: 1.90 - ETA: 54s - loss: 1.90 - ETA: 54s - loss: 1.90 - ETA: 54s - loss: 1.90 - ETA: 54s - loss: 1.89 - ETA: 53s - loss: 1.89 - ETA: 53s - loss: 1.89 - ETA: 53s - loss: 1.89 - ETA: 53s - loss: 1.89 - ETA: 52s - loss: 1.89 - ETA: 52s - loss: 1.89 - ETA: 52s - loss: 1.89 - ETA: 52s - loss: 1.89 - ETA: 52s - loss: 1.89 - ETA: 52s - loss: 1.89 - ETA: 52s - loss: 1.89 - ETA: 52s - loss: 1.89 - ETA: 51s - loss: 1.89 - ETA: 51s - loss: 1.89 - ETA: 51s - loss: 1.89 - ETA: 51s - loss: 1.89 - ETA: 51s - loss: 1.89 - ETA: 51s - loss: 1.89 - ETA: 50s - loss: 1.89 - ETA: 50s - loss: 1.89 - ETA: 50s - loss: 1.89 - ETA: 50s - loss: 1.89 - ETA: 49s - loss: 1.89 - ETA: 49s - loss: 1.90 - ETA: 49s - loss: 1.90 - ETA: 49s - loss: 1.90 - ETA: 48s - loss: 1.90 - ETA: 48s - loss: 1.89 - ETA: 48s - loss: 1.89 - ETA: 48s - loss: 1.90 - ETA: 47s - loss: 1.90 - ETA: 47s - loss: 1.90 - ETA: 47s - loss: 1.90 - ETA: 47s - loss: 1.90 - ETA: 46s - loss: 1.89 - ETA: 46s - loss: 1.89 - ETA: 46s - loss: 1.89 - ETA: 46s - loss: 1.89 - ETA: 46s - loss: 1.89 - ETA: 45s - loss: 1.89 - ETA: 45s - loss: 1.89 - ETA: 45s - loss: 1.89 - ETA: 45s - loss: 1.89 - ETA: 45s - loss: 1.89 - ETA: 44s - loss: 1.89 - ETA: 44s - loss: 1.89 - ETA: 44s - loss: 1.89 - ETA: 44s - loss: 1.89 - ETA: 43s - loss: 1.89 - ETA: 43s - loss: 1.89 - ETA: 43s - loss: 1.89 - ETA: 43s - loss: 1.89 - ETA: 43s - loss: 1.89 - ETA: 43s - loss: 1.89 - ETA: 43s - loss: 1.89 - ETA: 42s - loss: 1.89 - ETA: 42s - loss: 1.89 - ETA: 42s - loss: 1.89 - ETA: 42s - loss: 1.89 - ETA: 42s - loss: 1.89 - ETA: 41s - loss: 1.89 - ETA: 41s - loss: 1.89 - ETA: 41s - loss: 1.89 - ETA: 41s - loss: 1.89 - ETA: 41s - loss: 1.89 - ETA: 41s - loss: 1.89 - ETA: 40s - loss: 1.89 - ETA: 40s - loss: 1.89 - ETA: 40s - loss: 1.89 - ETA: 40s - loss: 1.89 - ETA: 40s - loss: 1.89 - ETA: 40s - loss: 1.89 - ETA: 39s - loss: 1.89 - ETA: 39s - loss: 1.89 - ETA: 39s - loss: 1.89 - ETA: 39s - loss: 1.89 - ETA: 39s - loss: 1.89 - ETA: 39s - loss: 1.89 - ETA: 38s - loss: 1.89 - ETA: 38s - loss: 1.89 - ETA: 38s - loss: 1.89 - ETA: 38s - loss: 1.89 - ETA: 38s - loss: 1.89 - ETA: 37s - loss: 1.89 - ETA: 37s - loss: 1.90 - ETA: 37s - loss: 1.90 - ETA: 37s - loss: 1.90 - ETA: 37s - loss: 1.90 - ETA: 36s - loss: 1.90 - ETA: 36s - loss: 1.90 - ETA: 36s - loss: 1.90 - ETA: 36s - loss: 1.90 - ETA: 36s - loss: 1.90 - ETA: 35s - loss: 1.90 - ETA: 35s - loss: 1.90 - ETA: 35s - loss: 1.90 - ETA: 35s - loss: 1.90 - ETA: 35s - loss: 1.90 - ETA: 35s - loss: 1.90 - ETA: 34s - loss: 1.90 - ETA: 34s - loss: 1.90 - ETA: 34s - loss: 1.90 - ETA: 34s - loss: 1.90 - ETA: 34s - loss: 1.90 - ETA: 33s - loss: 1.90 - ETA: 33s - loss: 1.90 - ETA: 33s - loss: 1.90 - ETA: 33s - loss: 1.90 - ETA: 33s - loss: 1.90 - ETA: 32s - loss: 1.90 - ETA: 32s - loss: 1.90 - ETA: 32s - loss: 1.90 - ETA: 32s - loss: 1.90 - ETA: 32s - loss: 1.90 - ETA: 31s - loss: 1.90 - ETA: 31s - loss: 1.90 - ETA: 31s - loss: 1.90 - ETA: 31s - loss: 1.90 - ETA: 31s - loss: 1.90 - ETA: 30s - loss: 1.90 - ETA: 30s - loss: 1.90 - ETA: 30s - loss: 1.90 - ETA: 30s - loss: 1.90 - ETA: 30s - loss: 1.90 - ETA: 30s - loss: 1.90 - ETA: 29s - loss: 1.90 - ETA: 29s - loss: 1.90 - ETA: 29s - loss: 1.90 - ETA: 29s - loss: 1.90 - ETA: 29s - loss: 1.90 - ETA: 28s - loss: 1.90 - ETA: 28s - loss: 1.90 - ETA: 28s - loss: 1.90 - ETA: 28s - loss: 1.90 - ETA: 28s - loss: 1.90 - ETA: 27s - loss: 1.90 - ETA: 27s - loss: 1.90 - ETA: 27s - loss: 1.90 - ETA: 27s - loss: 1.90 - ETA: 27s - loss: 1.90 - ETA: 26s - loss: 1.90 - ETA: 26s - loss: 1.90 - ETA: 26s - loss: 1.90 - ETA: 26s - loss: 1.90 - ETA: 26s - loss: 1.90 - ETA: 26s - loss: 1.90 - ETA: 25s - loss: 1.90 - ETA: 25s - loss: 1.90 - ETA: 25s - loss: 1.90 - ETA: 25s - loss: 1.90 - ETA: 25s - loss: 1.90 - ETA: 24s - loss: 1.90 - ETA: 24s - loss: 1.90 - ETA: 24s - loss: 1.90 - ETA: 24s - loss: 1.90 - ETA: 24s - loss: 1.90 - ETA: 23s - loss: 1.90 - ETA: 23s - loss: 1.90 - ETA: 23s - loss: 1.90 - ETA: 23s - loss: 1.90 - ETA: 23s - loss: 1.90 - ETA: 22s - loss: 1.90 - ETA: 22s - loss: 1.90 - ETA: 22s - loss: 1.90 - ETA: 22s - loss: 1.90 - ETA: 22s - loss: 1.90 - ETA: 21s - loss: 1.90 - ETA: 21s - loss: 1.90 - ETA: 21s - loss: 1.90 - ETA: 21s - loss: 1.90 - ETA: 21s - loss: 1.90 - ETA: 20s - loss: 1.90 - ETA: 20s - loss: 1.90 - ETA: 20s - loss: 1.90 - ETA: 20s - loss: 1.90 - ETA: 20s - loss: 1.90 - ETA: 19s - loss: 1.90 - ETA: 19s - loss: 1.90 - ETA: 19s - loss: 1.90 - ETA: 19s - loss: 1.90 - ETA: 19s - loss: 1.90 - ETA: 18s - loss: 1.90 - ETA: 18s - loss: 1.90 - ETA: 18s - loss: 1.90 - ETA: 18s - loss: 1.91 - ETA: 18s - loss: 1.91 - ETA: 17s - loss: 1.91 - ETA: 17s - loss: 1.91 - ETA: 17s - loss: 1.91 - ETA: 17s - loss: 1.91 - ETA: 17s - loss: 1.91 - ETA: 16s - loss: 1.91 - ETA: 16s - loss: 1.90 - ETA: 16s - loss: 1.91 - ETA: 16s - loss: 1.91 - ETA: 16s - loss: 1.91 - ETA: 15s - loss: 1.91 - ETA: 15s - loss: 1.91 - ETA: 15s - loss: 1.91 - ETA: 15s - loss: 1.91 - ETA: 15s - loss: 1.91 - ETA: 15s - loss: 1.91 - ETA: 14s - loss: 1.91 - ETA: 14s - loss: 1.91 - ETA: 14s - loss: 1.91 - ETA: 14s - loss: 1.91 - ETA: 14s - loss: 1.91 - ETA: 13s - loss: 1.91 - ETA: 13s - loss: 1.91 - ETA: 13s - loss: 1.90 - ETA: 13s - loss: 1.90 - ETA: 13s - loss: 1.90 - ETA: 12s - loss: 1.91 - ETA: 12s - loss: 1.91 - ETA: 12s - loss: 1.91 - ETA: 12s - loss: 1.91 - ETA: 12s - loss: 1.91 - ETA: 11s - loss: 1.91 - ETA: 11s - loss: 1.91 - ETA: 11s - loss: 1.91 - ETA: 11s - loss: 1.91 - ETA: 11s - loss: 1.91 - ETA: 10s - loss: 1.91 - ETA: 10s - loss: 1.91 - ETA: 10s - loss: 1.91 - ETA: 10s - loss: 1.91 - ETA: 10s - loss: 1.91 - ETA: 9s - loss: 1.9101 - ETA: 9s - loss: 1.910 - ETA: 9s - loss: 1.911 - ETA: 9s - loss: 1.911 - ETA: 9s - loss: 1.911 - ETA: 8s - loss: 1.911 - ETA: 8s - loss: 1.911 - ETA: 8s - loss: 1.911 - ETA: 8s - loss: 1.911 - ETA: 8s - loss: 1.911 - ETA: 7s - loss: 1.911 - ETA: 7s - loss: 1.911 - ETA: 7s - loss: 1.911 - ETA: 7s - loss: 1.910 - ETA: 7s - loss: 1.910 - ETA: 6s - loss: 1.910 - ETA: 6s - loss: 1.910 - ETA: 6s - loss: 1.910 - ETA: 6s - loss: 1.910 - ETA: 6s - loss: 1.909 - ETA: 5s - loss: 1.910 - ETA: 5s - loss: 1.910 - ETA: 5s - loss: 1.910 - ETA: 5s - loss: 1.910 - ETA: 5s - loss: 1.910 - ETA: 4s - loss: 1.910 - ETA: 4s - loss: 1.909 - ETA: 4s - loss: 1.909 - ETA: 4s - loss: 1.910 - ETA: 4s - loss: 1.910 - ETA: 4s - loss: 1.909 - ETA: 3s - loss: 1.909 - ETA: 3s - loss: 1.909 - ETA: 3s - loss: 1.909 - ETA: 3s - loss: 1.909 - ETA: 3s - loss: 1.909 - ETA: 2s - loss: 1.909 - ETA: 2s - loss: 1.909 - ETA: 2s - loss: 1.909 - ETA: 2s - loss: 1.909 - ETA: 2s - loss: 1.909 - ETA: 1s - loss: 1.909 - ETA: 1s - loss: 1.909 - ETA: 1s - loss: 1.908 - ETA: 1s - loss: 1.909 - ETA: 1s - loss: 1.909 - ETA: 0s - loss: 1.909 - ETA: 0s - loss: 1.908 - ETA: 0s - loss: 1.908 - ETA: 0s - loss: 1.908 - ETA: 0s - loss: 1.908 - 67s 833us/sample - loss: 1.9089 - val_loss: 1.9348\n",
      "Epoch 5/5\n",
      "79962/79962 [==============================] - ETA: 1:04 - loss: 1.865 - ETA: 1:03 - loss: 1.856 - ETA: 1:00 - loss: 1.822 - ETA: 1:02 - loss: 1.853 - ETA: 1:04 - loss: 1.871 - ETA: 1:03 - loss: 1.878 - ETA: 1:01 - loss: 1.897 - ETA: 1:01 - loss: 1.883 - ETA: 1:01 - loss: 1.898 - ETA: 1:01 - loss: 1.899 - ETA: 1:01 - loss: 1.902 - ETA: 1:01 - loss: 1.904 - ETA: 1:00 - loss: 1.895 - ETA: 1:00 - loss: 1.895 - ETA: 59s - loss: 1.893 - ETA: 59s - loss: 1.88 - ETA: 59s - loss: 1.88 - ETA: 59s - loss: 1.88 - ETA: 59s - loss: 1.88 - ETA: 58s - loss: 1.87 - ETA: 57s - loss: 1.87 - ETA: 57s - loss: 1.87 - ETA: 57s - loss: 1.87 - ETA: 56s - loss: 1.87 - ETA: 56s - loss: 1.87 - ETA: 56s - loss: 1.86 - ETA: 56s - loss: 1.86 - ETA: 55s - loss: 1.85 - ETA: 55s - loss: 1.86 - ETA: 55s - loss: 1.86 - ETA: 55s - loss: 1.86 - ETA: 55s - loss: 1.86 - ETA: 55s - loss: 1.86 - ETA: 55s - loss: 1.86 - ETA: 54s - loss: 1.86 - ETA: 54s - loss: 1.86 - ETA: 54s - loss: 1.86 - ETA: 54s - loss: 1.86 - ETA: 54s - loss: 1.86 - ETA: 53s - loss: 1.86 - ETA: 53s - loss: 1.86 - ETA: 53s - loss: 1.86 - ETA: 53s - loss: 1.86 - ETA: 53s - loss: 1.87 - ETA: 53s - loss: 1.87 - ETA: 52s - loss: 1.86 - ETA: 52s - loss: 1.87 - ETA: 52s - loss: 1.87 - ETA: 51s - loss: 1.87 - ETA: 51s - loss: 1.87 - ETA: 51s - loss: 1.87 - ETA: 51s - loss: 1.87 - ETA: 51s - loss: 1.87 - ETA: 50s - loss: 1.87 - ETA: 50s - loss: 1.87 - ETA: 50s - loss: 1.87 - ETA: 50s - loss: 1.87 - ETA: 50s - loss: 1.87 - ETA: 50s - loss: 1.87 - ETA: 49s - loss: 1.87 - ETA: 49s - loss: 1.87 - ETA: 49s - loss: 1.87 - ETA: 49s - loss: 1.86 - ETA: 49s - loss: 1.86 - ETA: 49s - loss: 1.86 - ETA: 48s - loss: 1.86 - ETA: 48s - loss: 1.86 - ETA: 48s - loss: 1.86 - ETA: 48s - loss: 1.86 - ETA: 48s - loss: 1.86 - ETA: 47s - loss: 1.86 - ETA: 47s - loss: 1.86 - ETA: 47s - loss: 1.86 - ETA: 47s - loss: 1.86 - ETA: 47s - loss: 1.86 - ETA: 47s - loss: 1.86 - ETA: 46s - loss: 1.86 - ETA: 46s - loss: 1.86 - ETA: 46s - loss: 1.86 - ETA: 46s - loss: 1.86 - ETA: 46s - loss: 1.86 - ETA: 45s - loss: 1.86 - ETA: 45s - loss: 1.86 - ETA: 45s - loss: 1.86 - ETA: 45s - loss: 1.86 - ETA: 45s - loss: 1.86 - ETA: 45s - loss: 1.86 - ETA: 44s - loss: 1.86 - ETA: 44s - loss: 1.86 - ETA: 44s - loss: 1.86 - ETA: 44s - loss: 1.86 - ETA: 44s - loss: 1.86 - ETA: 43s - loss: 1.86 - ETA: 43s - loss: 1.86 - ETA: 43s - loss: 1.86 - ETA: 43s - loss: 1.86 - ETA: 43s - loss: 1.86 - ETA: 42s - loss: 1.86 - ETA: 42s - loss: 1.86 - ETA: 42s - loss: 1.86 - ETA: 42s - loss: 1.86 - ETA: 41s - loss: 1.86 - ETA: 41s - loss: 1.86 - ETA: 41s - loss: 1.86 - ETA: 41s - loss: 1.86 - ETA: 41s - loss: 1.86 - ETA: 40s - loss: 1.86 - ETA: 40s - loss: 1.86 - ETA: 40s - loss: 1.86 - ETA: 40s - loss: 1.86 - ETA: 40s - loss: 1.86 - ETA: 39s - loss: 1.86 - ETA: 39s - loss: 1.86 - ETA: 39s - loss: 1.86 - ETA: 39s - loss: 1.86 - ETA: 39s - loss: 1.86 - ETA: 38s - loss: 1.86 - ETA: 38s - loss: 1.86 - ETA: 38s - loss: 1.86 - ETA: 38s - loss: 1.86 - ETA: 38s - loss: 1.86 - ETA: 37s - loss: 1.86 - ETA: 37s - loss: 1.86 - ETA: 37s - loss: 1.86 - ETA: 37s - loss: 1.86 - ETA: 37s - loss: 1.86 - ETA: 36s - loss: 1.86 - ETA: 36s - loss: 1.86 - ETA: 36s - loss: 1.86 - ETA: 36s - loss: 1.86 - ETA: 36s - loss: 1.86 - ETA: 36s - loss: 1.86 - ETA: 35s - loss: 1.86 - ETA: 35s - loss: 1.86 - ETA: 35s - loss: 1.86 - ETA: 35s - loss: 1.86 - ETA: 35s - loss: 1.86 - ETA: 34s - loss: 1.86 - ETA: 34s - loss: 1.86 - ETA: 34s - loss: 1.86 - ETA: 34s - loss: 1.86 - ETA: 34s - loss: 1.86 - ETA: 33s - loss: 1.86 - ETA: 33s - loss: 1.86 - ETA: 33s - loss: 1.86 - ETA: 33s - loss: 1.86 - ETA: 33s - loss: 1.86 - ETA: 32s - loss: 1.86 - ETA: 32s - loss: 1.86 - ETA: 32s - loss: 1.86 - ETA: 32s - loss: 1.86 - ETA: 32s - loss: 1.86 - ETA: 31s - loss: 1.86 - ETA: 31s - loss: 1.86 - ETA: 31s - loss: 1.86 - ETA: 31s - loss: 1.86 - ETA: 31s - loss: 1.86 - ETA: 30s - loss: 1.86 - ETA: 30s - loss: 1.86 - ETA: 30s - loss: 1.86 - ETA: 30s - loss: 1.86 - ETA: 30s - loss: 1.86 - ETA: 29s - loss: 1.86 - ETA: 29s - loss: 1.86 - ETA: 29s - loss: 1.86 - ETA: 29s - loss: 1.86 - ETA: 28s - loss: 1.86 - ETA: 28s - loss: 1.86 - ETA: 28s - loss: 1.86 - ETA: 28s - loss: 1.86 - ETA: 28s - loss: 1.86 - ETA: 27s - loss: 1.86 - ETA: 27s - loss: 1.87 - ETA: 27s - loss: 1.87 - ETA: 27s - loss: 1.87 - ETA: 27s - loss: 1.87 - ETA: 27s - loss: 1.87 - ETA: 26s - loss: 1.87 - ETA: 26s - loss: 1.87 - ETA: 26s - loss: 1.87 - ETA: 26s - loss: 1.87 - ETA: 26s - loss: 1.87 - ETA: 25s - loss: 1.87 - ETA: 25s - loss: 1.87 - ETA: 25s - loss: 1.87 - ETA: 25s - loss: 1.87 - ETA: 25s - loss: 1.87 - ETA: 24s - loss: 1.87 - ETA: 24s - loss: 1.87 - ETA: 24s - loss: 1.87 - ETA: 24s - loss: 1.87 - ETA: 24s - loss: 1.87 - ETA: 23s - loss: 1.87 - ETA: 23s - loss: 1.87 - ETA: 23s - loss: 1.87 - ETA: 23s - loss: 1.87 - ETA: 23s - loss: 1.87 - ETA: 22s - loss: 1.87 - ETA: 22s - loss: 1.87 - ETA: 22s - loss: 1.87 - ETA: 22s - loss: 1.87 - ETA: 22s - loss: 1.87 - ETA: 21s - loss: 1.87 - ETA: 21s - loss: 1.87 - ETA: 21s - loss: 1.87 - ETA: 21s - loss: 1.87 - ETA: 21s - loss: 1.87 - ETA: 20s - loss: 1.87 - ETA: 20s - loss: 1.87 - ETA: 20s - loss: 1.87 - ETA: 20s - loss: 1.87 - ETA: 20s - loss: 1.87 - ETA: 19s - loss: 1.87 - ETA: 19s - loss: 1.87 - ETA: 19s - loss: 1.87 - ETA: 19s - loss: 1.87 - ETA: 19s - loss: 1.87 - ETA: 18s - loss: 1.87 - ETA: 18s - loss: 1.87 - ETA: 18s - loss: 1.87 - ETA: 18s - loss: 1.87 - ETA: 18s - loss: 1.87 - ETA: 17s - loss: 1.87 - ETA: 17s - loss: 1.87 - ETA: 17s - loss: 1.87 - ETA: 17s - loss: 1.87 - ETA: 17s - loss: 1.87 - ETA: 16s - loss: 1.87 - ETA: 16s - loss: 1.87 - ETA: 16s - loss: 1.87 - ETA: 16s - loss: 1.87 - ETA: 16s - loss: 1.87 - ETA: 15s - loss: 1.87 - ETA: 15s - loss: 1.87 - ETA: 15s - loss: 1.87 - ETA: 15s - loss: 1.87 - ETA: 15s - loss: 1.87 - ETA: 14s - loss: 1.87 - ETA: 14s - loss: 1.87 - ETA: 14s - loss: 1.87 - ETA: 14s - loss: 1.87 - ETA: 14s - loss: 1.87 - ETA: 13s - loss: 1.87 - ETA: 13s - loss: 1.87 - ETA: 13s - loss: 1.87 - ETA: 13s - loss: 1.87 - ETA: 13s - loss: 1.87 - ETA: 12s - loss: 1.87 - ETA: 12s - loss: 1.87 - ETA: 12s - loss: 1.87 - ETA: 12s - loss: 1.87 - ETA: 12s - loss: 1.87 - ETA: 11s - loss: 1.87 - ETA: 11s - loss: 1.87 - ETA: 11s - loss: 1.87 - ETA: 11s - loss: 1.87 - ETA: 11s - loss: 1.87 - ETA: 10s - loss: 1.87 - ETA: 10s - loss: 1.87 - ETA: 10s - loss: 1.87 - ETA: 10s - loss: 1.87 - ETA: 10s - loss: 1.87 - ETA: 9s - loss: 1.8740 - ETA: 9s - loss: 1.874 - ETA: 9s - loss: 1.874 - ETA: 9s - loss: 1.874 - ETA: 9s - loss: 1.873 - ETA: 8s - loss: 1.873 - ETA: 8s - loss: 1.873 - ETA: 8s - loss: 1.873 - ETA: 8s - loss: 1.873 - ETA: 8s - loss: 1.873 - ETA: 7s - loss: 1.873 - ETA: 7s - loss: 1.873 - ETA: 7s - loss: 1.874 - ETA: 7s - loss: 1.874 - ETA: 7s - loss: 1.874 - ETA: 6s - loss: 1.874 - ETA: 6s - loss: 1.874 - ETA: 6s - loss: 1.874 - ETA: 6s - loss: 1.874 - ETA: 6s - loss: 1.874 - ETA: 5s - loss: 1.874 - ETA: 5s - loss: 1.874 - ETA: 5s - loss: 1.874 - ETA: 5s - loss: 1.874 - ETA: 5s - loss: 1.874 - ETA: 4s - loss: 1.874 - ETA: 4s - loss: 1.873 - ETA: 4s - loss: 1.873 - ETA: 4s - loss: 1.873 - ETA: 4s - loss: 1.873 - ETA: 3s - loss: 1.873 - ETA: 3s - loss: 1.873 - ETA: 3s - loss: 1.873 - ETA: 3s - loss: 1.873 - ETA: 3s - loss: 1.874 - ETA: 2s - loss: 1.874 - ETA: 2s - loss: 1.874 - ETA: 2s - loss: 1.874 - ETA: 2s - loss: 1.874 - ETA: 2s - loss: 1.874 - ETA: 1s - loss: 1.874 - ETA: 1s - loss: 1.874 - ETA: 1s - loss: 1.874 - ETA: 1s - loss: 1.874 - ETA: 1s - loss: 1.874 - ETA: 0s - loss: 1.874 - ETA: 0s - loss: 1.874 - ETA: 0s - loss: 1.874 - ETA: 0s - loss: 1.874 - ETA: 0s - loss: 1.875 - 68s 847us/sample - loss: 1.8749 - val_loss: 1.9071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19be6dc7c88>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x, y, batch_size=256, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sequence\n",
    "sentence = \"that, poor contempt, or claim'd thou sle\"\n",
    "\n",
    "# Create a 3-D zero vector to contain the encoding of sentence.\n",
    "X_test = np.zeros((1, maxlen, len(vocabulary)))\n",
    "\n",
    "# Iterate over each character and convert them to one-hot encoded vector.\n",
    "for s_idx, char in enumerate(sentence):\n",
    "    X_test[0, s_idx, char_to_idx[char]] = 1\n",
    "# Get the probability distribution using model predict\n",
    "preds = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Get the probability distribution for the first character after the sequence\n",
    "preds_next_char = preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "# Get the index of the most probable next character\n",
    "next_index = np.argmax(preds_next_char)\n",
    "\n",
    "# Map the index to the actual character and print it\n",
    "next_char = idx_to_char[next_index]\n",
    "\n",
    "# Print the next character\n",
    "print(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sentence, n):\n",
    "    \"\"\"\n",
    "    Function to generate text\n",
    "    Inputs: seed sentence and number of characters to be generated.\n",
    "    Output: returns nothing but prints the generated sequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the generated sequence with the seed sentence\n",
    "    generated = ''\n",
    "    generated += sentence\n",
    "    \n",
    "    # Iterate for each character to be generated\n",
    "    for i in range(n):\n",
    "      \n",
    "        # Create input vector from the input sentence\n",
    "        x_pred = np.zeros((1, maxlen, len(vocabulary)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_to_idx[char]] = 1.\n",
    "\n",
    "        # Get probability distribution for the next character\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "        # Get the index with maximum probability\n",
    "        next_index = np.argmax(preds)\n",
    "        next_char = idx_to_char[next_index]\n",
    "\n",
    "        # Append the new character to the input sentence for next iteration\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        # Append the new character to the text generated so far\n",
    "        generated += next_char\n",
    "    \n",
    "    # Print the generated text\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that, poor contempt, or claim'd thou slead the shall and the prought the sing the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the shall and the sear and the\n"
     ]
    }
   ],
   "source": [
    "# Input sequence and generate text\n",
    "sentence = \"that, poor contempt, or claim'd thou sle\"\n",
    "generate_text(sentence, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Increasing the sample size and the number of iterations(epochs) will lead to better predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Translation Model to translate English sentences to French\n",
    "-- Sequence to Sequence Models\n",
    "-  Aim to map a fixed length input with a fixed length output where the lengths of the input and output may differ\n",
    "    - Eg: Tanslation from one language to other, automated question-answering systems, named entity recognition, parts of speech tagging, text summarization, grammar correction etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\t\n"
     ]
    }
   ],
   "source": [
    "lines = []                             \n",
    "with open ('fra.txt', 'rt') as file: \n",
    "    for line in file:\n",
    "        line = line.partition('CC-BY')[0]\n",
    "        lines.append(line)           \n",
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.\\tVa !\\t'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175623"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = []\n",
    "french_sentences = []\n",
    "# Consider only the first 50 lines of the dataset\n",
    "for i in range(10000):\n",
    "    # Split each line into two at the tab character\n",
    "    eng_fra_line = str(lines[i]).split('\\t')\n",
    "    \n",
    "    # Separate out the English sentence \n",
    "    eng_line = eng_fra_line[0]\n",
    "    \n",
    "    # Append the start and end token to each French sentence\n",
    "    fra_line = '\\t' + eng_fra_line[1] + '\\n'\n",
    "    \n",
    "    # Append the English and French sentence to the list of sentences\n",
    "    english_sentences.append(eng_line)\n",
    "    french_sentences.append(fra_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.',\n",
       " 'Hi.',\n",
       " 'Hi.',\n",
       " 'Run!',\n",
       " 'Run!',\n",
       " 'Who?',\n",
       " 'Wow!',\n",
       " 'Fire!',\n",
       " 'Help!',\n",
       " 'Jump.']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty set to contain the English vocabulary \n",
    "english_vocab = set()\n",
    "\n",
    "# Iterate over each English sentence\n",
    "for eng_line in english_sentences:\n",
    "  \n",
    "    # Convert the English line to a set\n",
    "    eng_line_set = set(eng_line)\n",
    "    \n",
    "    # Update English vocabulary with new characters from this line.\n",
    "    english_vocab = english_vocab.union(eng_line_set)\n",
    "\n",
    "# Sort the vocabulary\n",
    "english_vocab = sorted(list(english_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty set to contain the French vocabulary \n",
    "french_vocab = set()\n",
    "\n",
    "# Iterate over each French sentence\n",
    "for fra_line in french_sentences:\n",
    "  \n",
    "    # Convert the French line to a set\n",
    "    fra_line_set = set(fra_line)\n",
    "    \n",
    "    # Update French vocabulary with new characters from this line.\n",
    "    french_vocab = french_vocab.union(fra_line_set)\n",
    "\n",
    "# Sort the vocabulary\n",
    "french_vocab = sorted(list(french_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to contain the character to integer mapping for English\n",
    "eng_char_to_idx = dict((char, idx) for idx, char in enumerate(english_vocab))\n",
    "\n",
    "# Dictionary to contain the integer to character mapping for English\n",
    "eng_idx_to_char = dict((idx, char) for idx, char in enumerate(english_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to contain the character to integer mapping for French\n",
    "fra_char_to_idx = dict((char, idx) for idx, char in enumerate(french_vocab))\n",
    "\n",
    "# Dictionary to contain the integer to character mapping for French\n",
    "fra_idx_to_char = dict((idx, char) for idx, char in enumerate(french_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Machine Translation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoder-Decoder architecture consists of two separate neural networks\n",
    "- Encoder\n",
    "    - The encoder accepts the input sentences and summarizes the information in its state vectors\n",
    "    - Encoders are implemented using LSTMs and here the states refer to the cell and hidden states from the LSTM layer\n",
    "    - During training, the encoder learns these states from data. Intuitively, we can think of the states as a summarization of all the useful information from the input\n",
    "    - The encoder output is ignored\n",
    "- Decoder\n",
    "    - The decoder is also implemented using LSTM's and the initial hidden and cell states are initialized to the encoder final states\n",
    "    - Intuitively, the decoder gets to know about all the useful information from the input from these states. the decoder uses this information to generate the output\n",
    "    - The final decoder states are ignored\n",
    "    - The output of the decoder is compared with the target sequence to calculate the error which is minimized during the training process by updating the weights of the encoder and decoder networks\n",
    "    - The input to the decoder at each time-step is the predicted output from the previous time-step as usual\n",
    "    - However, during training, the input to the decoder at each time-step is the actual output from the previous step instead of the predicted output\n",
    "    - This technique is known as 'Teacher-Forcing' which helps the model to learn faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we know how the encoder and decoder works, let's apply this to the case study of the machine translation \n",
    "- Encoder\n",
    "    - The encoder will accept the english sentences, the number of time-steps in the encoder will be the length of the english sentences\n",
    "    - As we have sentences of varying legths, the length of the longest english sentence can be taken as the step-size\n",
    "    - Shorter sentences can be padded with zeros at the end\n",
    "    - Encoder summarizes all the necessary information from the English sentences in its state vectors which are then passed to the decoder\n",
    "    - Encoder outputs are ignored\n",
    "- Decoder\n",
    "    - The initial states of the decoder are the final states from the encoder\n",
    "    - The encoder consolidates all the useful information from the english sentences in its state vectors which are needed in the decoder to generate the translated french sentence\n",
    "    - The decoder inputs during the training are the French sentences because of teacher-forcing\n",
    "    - Decoder outputs are the translated sentences\n",
    "    - Decoder states are ignored\n",
    "    - Similar to the encoder, as we have sentences of varying lengths, the number of time steps in the decoder can be set to the length of the longest french sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are two inputs to the network - English sentences for the encoder and French sentences for the decoder. The targets are the french sentences\n",
    "- All these vectors are 3-Dimensional - the first dimension being the number of sentences, the second being the number of time steps which is the length of the longest English or French sentence and the third being the length of the one-hot encoded vector for the characters which is the respective vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to find the length of the longest english and french sentences to define the number of time steps\n",
    "# Find the length of the longest English sentence\n",
    "max_len_eng_sent = max([len(sentence) for sentence in english_sentences])\n",
    "\n",
    "# Find the length of the longest French sentence\n",
    "max_len_fra_sent = max([len(sentence) for sentence in french_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input and target vectors \n",
    "# Create a 3-D zero vector for the input English data\n",
    "eng_input_data = np.zeros((len(english_sentences), max_len_eng_sent, len(english_vocab)), dtype='float32')\n",
    "\n",
    "# Create a 3-D zero vector for the input French data\n",
    "fra_input_data = np.zeros((len(french_sentences), max_len_fra_sent, len(french_vocab)), dtype='float32')\n",
    "\n",
    "# Create the target vector\n",
    "target_data = np.zeros((len(french_sentences), max_len_fra_sent, len(french_vocab)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can initialize these vectors by iterating over all the characters in each sentence and converting into a \n",
    "# one-hot encoded vector\n",
    "# Iterate over the 50 sentences\n",
    "for i in range(50):\n",
    "    # Iterate over each English character of each sentence\n",
    "    for k, ch in enumerate(english_sentences[i]):\n",
    "        # Convert the character to one-hot encoded vector\n",
    "        eng_input_data[i, k, eng_char_to_idx[ch]] = 1.\n",
    "    \n",
    "    # Iterate over each French character of each sentence\n",
    "    for k, ch in enumerate(french_sentences[i]):\n",
    "        # Convert the character to one-hot encoded vector\n",
    "        fra_input_data[i, k, fra_char_to_idx[ch]] = 1.\n",
    "\n",
    "        # Target data will be one timestep ahead and excludes start character\n",
    "        if k > 0:\n",
    "            target_data[i, k-1, fra_char_to_idx[ch]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-Decoder network using keras\n",
    "\n",
    "# Encoder\n",
    "\n",
    "encoder_input = Input(shape=(None, len(english_vocab)))\n",
    "encoder_LSTM = LSTM(256, return_state = True)\n",
    "\n",
    "# The first dimension of the input is None indicating that it can take varying number of input sequences at run time\n",
    "# Feed this input to the LSTM layer to produce the output and the state vectors\n",
    "# Save encoder output, hidden and cell state\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM(encoder_input)\n",
    "\n",
    "# Ignore the output and combine the hidden and cell states\n",
    "encoder_states = [encoder_h, encoder_c]\n",
    "\n",
    "# Decoder\n",
    "# Input layer is similar to the encoder\n",
    "decoder_input = Input(shape=(None, len(french_vocab)))\n",
    "\n",
    "# The initial state of the LSTM layer is the final state of the encoder\n",
    "decoder_LSTM = LSTM(256, return_sequences=True, return_state = True)\n",
    "\n",
    "# The output from this LSTM layer will be fed into a Dense softmax layer which will give us the final output\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "# the output states of the decoder are ignored, that is why we are not saving them\n",
    "\n",
    "# Create a dense layer with softmax activation. The dense layer predicts the next character and so the size of the dense\n",
    "# layer will be the same as the vocabulary\n",
    "decoder_dense = Dense(len(french_vocab), activation='softmax')\n",
    "\n",
    "# The output of the decoder LSTM layer is then fed to this Dense layer which generates the probability distribution of the \n",
    "# next character over the vocabulary\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "# The index with the maximum probability value is the index of the most probable next character.\n",
    "# The characters corresponding to this index can be found using the character to index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, None, 72)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, None, 92)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 256), (None, 336896      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 256),  357376      input_10[0][0]                   \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, None, 92)     23644       lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 717,916\n",
      "Trainable params: 717,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# combine the encoder and decoder using the model function from keras\n",
    "# Build model\n",
    "model = tf.keras.Model(inputs=[encoder_input, decoder_input], outputs=[decoder_out])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "# categorical class entropy is used when we have more than two class labels, here, the vocab size gives the no of labels\n",
    "# adam is advanced optimizer which converges faster\n",
    "\n",
    "# Print model summary to check the correctness of the encoder-decoder\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - ETA: 6:26 - loss: 0.0000e+0 - ETA: 3:28 - loss: 0.0000e+0 - ETA: 2:27 - loss: 0.0034    - ETA: 1:58 - loss: 0.002 - ETA: 1:39 - loss: 0.003 - ETA: 1:27 - loss: 0.003 - ETA: 1:18 - loss: 0.002 - ETA: 1:11 - loss: 0.002 - ETA: 1:06 - loss: 0.002 - ETA: 1:02 - loss: 0.003 - ETA: 58s - loss: 0.005 - ETA: 55s - loss: 0.00 - ETA: 53s - loss: 0.00 - ETA: 51s - loss: 0.00 - ETA: 48s - loss: 0.00 - ETA: 47s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0046 - ETA: 9s - loss: 0.004 - ETA: 9s - loss: 0.004 - ETA: 8s - loss: 0.004 - ETA: 8s - loss: 0.004 - ETA: 8s - loss: 0.004 - ETA: 7s - loss: 0.004 - ETA: 7s - loss: 0.004 - ETA: 7s - loss: 0.004 - ETA: 7s - loss: 0.004 - ETA: 6s - loss: 0.004 - ETA: 6s - loss: 0.004 - ETA: 6s - loss: 0.004 - ETA: 5s - loss: 0.004 - ETA: 5s - loss: 0.004 - ETA: 5s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.004 - 42s 5ms/sample - loss: 0.0046 - val_loss: 0.0000e+00\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - ETA: 59s - loss: 0.0000e+ - ETA: 55s - loss: 0.0000e+ - ETA: 51s - loss: 0.0000e+ - ETA: 47s - loss: 0.0000e+ - ETA: 45s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 41s - loss: 0.0000e+ - ETA: 40s - loss: 0.0000e+ - ETA: 39s - loss: 0.0000e+ - ETA: 38s - loss: 0.0013   - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0039 - ETA: 9s - loss: 0.003 - ETA: 9s - loss: 0.003 - ETA: 9s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 7s - loss: 0.004 - ETA: 7s - loss: 0.004 - ETA: 7s - loss: 0.004 - ETA: 6s - loss: 0.004 - ETA: 6s - loss: 0.004 - ETA: 6s - loss: 0.004 - ETA: 6s - loss: 0.004 - ETA: 5s - loss: 0.004 - ETA: 5s - loss: 0.004 - ETA: 5s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.004 - 41s 5ms/sample - loss: 0.0041 - val_loss: 0.0000e+00\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - ETA: 36s - loss: 0.03 - ETA: 36s - loss: 0.01 - ETA: 37s - loss: 0.01 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0041 - ETA: 9s - loss: 0.004 - ETA: 9s - loss: 0.004 - ETA: 8s - loss: 0.004 - ETA: 8s - loss: 0.004 - ETA: 8s - loss: 0.004 - ETA: 7s - loss: 0.004 - ETA: 7s - loss: 0.004 - ETA: 6s - loss: 0.004 - ETA: 6s - loss: 0.003 - ETA: 6s - loss: 0.004 - ETA: 5s - loss: 0.004 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 4s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 3s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 2s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 1s - loss: 0.004 - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 49s 6ms/sample - loss: 0.0039 - val_loss: 0.0000e+00\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - ETA: 45s - loss: 0.0000e+ - ETA: 45s - loss: 0.0024   - ETA: 45s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0040 - ETA: 9s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 50s 6ms/sample - loss: 0.0037 - val_loss: 0.0000e+00\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - ETA: 41s - loss: 0.0000e+ - ETA: 42s - loss: 0.0051   - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0033 - ETA: 9s - loss: 0.003 - ETA: 9s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 48s 6ms/sample - loss: 0.0036 - val_loss: 0.0000e+00\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0035 - ETA: 9s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 48s 6ms/sample - loss: 0.0033 - val_loss: 0.0000e+00\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.0000e+ - ETA: 44s - loss: 0.0051   - ETA: 44s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 46s - loss: 0.00 - ETA: 46s - loss: 0.00 - ETA: 47s - loss: 0.00 - ETA: 47s - loss: 0.00 - ETA: 47s - loss: 0.00 - ETA: 47s - loss: 0.00 - ETA: 47s - loss: 0.00 - ETA: 46s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0030 - ETA: 9s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 48s 6ms/sample - loss: 0.0032 - val_loss: 0.0000e+00\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - ETA: 42s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 42s - loss: 9.4510e- - ETA: 42s - loss: 7.8759e- - ETA: 42s - loss: 0.0014   - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 9.5415e- - ETA: 40s - loss: 8.6741e- - ETA: 40s - loss: 7.9512e- - ETA: 39s - loss: 7.3396e- - ETA: 39s - loss: 6.8154e- - ETA: 39s - loss: 6.3610e- - ETA: 39s - loss: 0.0015   - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0032 - ETA: 9s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 8s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 7s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 6s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 5s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 4s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 3s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 2s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 1s - loss: 0.003 - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 50s 6ms/sample - loss: 0.0030 - val_loss: 0.0000e+00\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - ETA: 47s - loss: 0.0000e+ - ETA: 44s - loss: 0.0000e+ - ETA: 44s - loss: 0.0000e+ - ETA: 43s - loss: 0.0025   - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0027 - ETA: 9s - loss: 0.002 - ETA: 9s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 50s 6ms/sample - loss: 0.0028 - val_loss: 0.0000e+00\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - ETA: 44s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0028 - ETA: 9s - loss: 0.002 - ETA: 9s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 49s 6ms/sample - loss: 0.0026 - val_loss: 0.0000e+00\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - ETA: 46s - loss: 0.0000e+ - ETA: 44s - loss: 0.0041   - ETA: 44s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0025 - ETA: 9s - loss: 0.002 - ETA: 9s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 49s 6ms/sample - loss: 0.0024 - val_loss: 0.0000e+00\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - ETA: 44s - loss: 0.0000e+ - ETA: 44s - loss: 0.0020   - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0019 - ETA: 9s - loss: 0.002 - ETA: 9s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 50s 6ms/sample - loss: 0.0023 - val_loss: 0.0000e+00\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.0000e+ - ETA: 43s - loss: 0.0016   - ETA: 44s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0023 - ETA: 9s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 51s 6ms/sample - loss: 0.0021 - val_loss: 0.0000e+00\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - ETA: 51s - loss: 0.0000e+ - ETA: 48s - loss: 0.0014   - ETA: 47s - loss: 9.0739e- - ETA: 47s - loss: 6.8054e- - ETA: 46s - loss: 0.0024   - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0018 - ETA: 9s - loss: 0.002 - ETA: 9s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 6s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 5s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 4s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 2s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 1s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 47s 6ms/sample - loss: 0.0021 - val_loss: 0.0000e+00\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - ETA: 42s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0019 - ETA: 9s - loss: 0.002 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 8s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 7s - loss: 0.002 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.002 - ETA: 3s - loss: 0.002 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 47s 6ms/sample - loss: 0.0019 - val_loss: 0.0000e+00\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - ETA: 44s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 43s - loss: 8.6948e- - ETA: 43s - loss: 0.0011   - ETA: 42s - loss: 8.9558e- - ETA: 42s - loss: 7.4632e- - ETA: 41s - loss: 0.0011   - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 8.9334e- - ETA: 40s - loss: 8.0401e- - ETA: 40s - loss: 7.3092e- - ETA: 39s - loss: 6.7001e- - ETA: 39s - loss: 6.1847e- - ETA: 39s - loss: 5.7429e- - ETA: 38s - loss: 5.3601e- - ETA: 38s - loss: 5.0250e- - ETA: 38s - loss: 4.7295e- - ETA: 38s - loss: 4.4667e- - ETA: 37s - loss: 0.0011   - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0018 - ETA: 9s - loss: 0.001 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 49s 6ms/sample - loss: 0.0018 - val_loss: 0.0000e+00\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - ETA: 55s - loss: 0.00 - ETA: 54s - loss: 0.00 - ETA: 53s - loss: 0.00 - ETA: 51s - loss: 0.00 - ETA: 52s - loss: 0.00 - ETA: 53s - loss: 0.00 - ETA: 52s - loss: 0.00 - ETA: 51s - loss: 0.00 - ETA: 51s - loss: 0.00 - ETA: 50s - loss: 0.00 - ETA: 50s - loss: 0.00 - ETA: 49s - loss: 0.00 - ETA: 49s - loss: 0.00 - ETA: 48s - loss: 0.00 - ETA: 47s - loss: 0.00 - ETA: 46s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0018 - ETA: 9s - loss: 0.001 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 51s 6ms/sample - loss: 0.0016 - val_loss: 0.0000e+00\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 9.7068e- - ETA: 39s - loss: 9.0134e- - ETA: 39s - loss: 0.0011   - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 9.5951e- - ETA: 38s - loss: 9.0620e- - ETA: 37s - loss: 9.8759e- - ETA: 37s - loss: 9.3821e- - ETA: 37s - loss: 8.9353e- - ETA: 37s - loss: 0.0011   - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0013 - ETA: 9s - loss: 0.001 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 49s 6ms/sample - loss: 0.0015 - val_loss: 0.0000e+00\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - ETA: 46s - loss: 0.0000e+ - ETA: 46s - loss: 0.0000e+ - ETA: 46s - loss: 0.0018   - ETA: 46s - loss: 0.00 - ETA: 46s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0014 - ETA: 9s - loss: 0.001 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 52s 6ms/sample - loss: 0.0014 - val_loss: 0.0000e+00\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 9.4210e- - ETA: 41s - loss: 7.8508e- - ETA: 41s - loss: 6.7293e- - ETA: 41s - loss: 0.0013   - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 9.9659e- - ETA: 39s - loss: 0.0011   - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 9.9022e- - ETA: 39s - loss: 9.2834e- - ETA: 39s - loss: 8.7373e- - ETA: 39s - loss: 8.2519e- - ETA: 38s - loss: 9.7057e- - ETA: 38s - loss: 9.2204e- - ETA: 38s - loss: 8.7813e- - ETA: 37s - loss: 0.0011   - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 9.8355e- - ETA: 35s - loss: 0.0011   - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0013 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 48s 6ms/sample - loss: 0.0014 - val_loss: 0.0000e+00\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - ETA: 41s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 42s - loss: 4.7935e- - ETA: 41s - loss: 3.5951e- - ETA: 40s - loss: 2.8761e- - ETA: 40s - loss: 2.3968e- - ETA: 40s - loss: 2.0544e- - ETA: 40s - loss: 1.7976e- - ETA: 39s - loss: 1.5978e- - ETA: 39s - loss: 1.4381e- - ETA: 39s - loss: 1.3073e- - ETA: 39s - loss: 1.1984e- - ETA: 38s - loss: 3.8226e- - ETA: 38s - loss: 3.5496e- - ETA: 37s - loss: 3.3129e- - ETA: 37s - loss: 5.6844e- - ETA: 37s - loss: 5.3500e- - ETA: 37s - loss: 5.8571e- - ETA: 36s - loss: 5.5488e- - ETA: 36s - loss: 5.2713e- - ETA: 36s - loss: 5.0203e- - ETA: 35s - loss: 4.7921e- - ETA: 35s - loss: 5.3860e- - ETA: 35s - loss: 5.1616e- - ETA: 34s - loss: 5.3158e- - ETA: 34s - loss: 6.3007e- - ETA: 34s - loss: 6.0674e- - ETA: 33s - loss: 7.0090e- - ETA: 33s - loss: 6.7673e- - ETA: 33s - loss: 8.3949e- - ETA: 32s - loss: 9.9443e- - ETA: 32s - loss: 9.6336e- - ETA: 32s - loss: 9.3416e- - ETA: 31s - loss: 9.0669e- - ETA: 31s - loss: 8.8078e- - ETA: 31s - loss: 9.9057e- - ETA: 30s - loss: 9.6380e- - ETA: 30s - loss: 9.3844e- - ETA: 30s - loss: 9.1437e- - ETA: 29s - loss: 0.0010   - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0012 - ETA: 9s - loss: 0.001 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 47s 6ms/sample - loss: 0.0013 - val_loss: 0.0000e+00\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 43s - loss: 0.0020   - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 9.6738e- - ETA: 41s - loss: 8.5990e- - ETA: 41s - loss: 7.7391e- - ETA: 40s - loss: 9.1362e- - ETA: 40s - loss: 8.3748e- - ETA: 40s - loss: 7.7306e- - ETA: 39s - loss: 9.6963e- - ETA: 39s - loss: 9.0499e- - ETA: 38s - loss: 0.0013   - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 9.9316e- - ETA: 36s - loss: 9.4801e- - ETA: 36s - loss: 0.0010   - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 9.8824e- - ETA: 28s - loss: 9.6628e- - ETA: 27s - loss: 9.4527e- - ETA: 27s - loss: 0.0011   - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 9.9019e- - ETA: 26s - loss: 9.7078e- - ETA: 25s - loss: 9.5211e- - ETA: 25s - loss: 9.3414e- - ETA: 24s - loss: 9.1684e- - ETA: 24s - loss: 9.8672e- - ETA: 24s - loss: 0.0010   - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0013 - ETA: 9s - loss: 0.001 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 47s 6ms/sample - loss: 0.0012 - val_loss: 0.0000e+00\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 41s - loss: 8.2446e- - ETA: 41s - loss: 6.1835e- - ETA: 41s - loss: 0.0011   - ETA: 41s - loss: 8.9053e- - ETA: 41s - loss: 0.0015   - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 9.4124e- - ETA: 38s - loss: 0.0012   - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 9.9312e- - ETA: 36s - loss: 0.0011   - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 9.7449e- - ETA: 35s - loss: 9.3388e- - ETA: 35s - loss: 8.9653e- - ETA: 35s - loss: 8.6205e- - ETA: 34s - loss: 8.3012e- - ETA: 34s - loss: 9.1801e- - ETA: 33s - loss: 8.8635e- - ETA: 33s - loss: 8.5681e- - ETA: 33s - loss: 8.2917e- - ETA: 32s - loss: 9.0633e- - ETA: 32s - loss: 8.7886e- - ETA: 32s - loss: 8.5301e- - ETA: 31s - loss: 8.2864e- - ETA: 31s - loss: 8.0562e- - ETA: 31s - loss: 8.6638e- - ETA: 30s - loss: 8.4358e- - ETA: 30s - loss: 8.9128e- - ETA: 30s - loss: 9.0454e- - ETA: 29s - loss: 8.8248e- - ETA: 29s - loss: 9.1905e- - ETA: 29s - loss: 8.9768e- - ETA: 28s - loss: 9.6993e- - ETA: 28s - loss: 9.4837e- - ETA: 27s - loss: 9.6783e- - ETA: 27s - loss: 0.0010   - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 9.8483e- - ETA: 25s - loss: 9.6660e- - ETA: 24s - loss: 9.4902e- - ETA: 24s - loss: 9.3208e- - ETA: 23s - loss: 9.1572e- - ETA: 23s - loss: 9.3652e- - ETA: 23s - loss: 9.6281e- - ETA: 22s - loss: 9.8909e- - ETA: 22s - loss: 0.0010   - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0011 - ETA: 9s - loss: 0.001 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 47s 6ms/sample - loss: 0.0011 - val_loss: 0.0000e+00\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - ETA: 40s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 41s - loss: 0.0000e+ - ETA: 41s - loss: 0.0000e+ - ETA: 40s - loss: 1.2280e- - ETA: 40s - loss: 8.6713e- - ETA: 40s - loss: 7.5874e- - ETA: 40s - loss: 6.7443e- - ETA: 39s - loss: 7.5164e- - ETA: 39s - loss: 0.0012   - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 9.9554e- - ETA: 32s - loss: 9.6443e- - ETA: 31s - loss: 9.3521e- - ETA: 31s - loss: 9.0770e- - ETA: 31s - loss: 8.8177e- - ETA: 30s - loss: 9.2737e- - ETA: 30s - loss: 0.0010   - ETA: 30s - loss: 9.8385e- - ETA: 29s - loss: 9.5863e- - ETA: 29s - loss: 9.3466e- - ETA: 29s - loss: 9.1186e- - ETA: 28s - loss: 9.7815e- - ETA: 28s - loss: 9.5541e- - ETA: 28s - loss: 9.3369e- - ETA: 27s - loss: 9.1294e- - ETA: 27s - loss: 9.2073e- - ETA: 27s - loss: 0.0011   - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 9.9054e- - ETA: 23s - loss: 0.0011   - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 9.9471e- - ETA: 11s - loss: 9.8401e- - ETA: 11s - loss: 9.7354e- - ETA: 10s - loss: 9.6329e- - ETA: 10s - loss: 0.0010   - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 9.9710e-0 - ETA: 9s - loss: 0.0010    - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 9.9861e-0 - ETA: 4s - loss: 9.8985e-0 - ETA: 3s - loss: 9.9118e-0 - ETA: 3s - loss: 9.8264e-0 - ETA: 2s - loss: 9.8916e-0 - ETA: 2s - loss: 9.8078e-0 - ETA: 2s - loss: 0.0010    - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 50s 6ms/sample - loss: 0.0010 - val_loss: 0.0000e+00\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - ETA: 49s - loss: 0.0000e+ - ETA: 46s - loss: 0.0000e+ - ETA: 45s - loss: 3.8119e- - ETA: 44s - loss: 0.0011   - ETA: 44s - loss: 0.00 - ETA: 45s - loss: 0.00 - ETA: 44s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 9.8295e- - ETA: 41s - loss: 9.9408e- - ETA: 41s - loss: 9.1124e- - ETA: 40s - loss: 8.4115e- - ETA: 40s - loss: 7.8107e- - ETA: 40s - loss: 0.0012   - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 36s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 35s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 34s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 33s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 30s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 29s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 28s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 27s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 26s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 25s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 24s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 23s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 22s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 20s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 19s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 18s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 17s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 16s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 14s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 13s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 12s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 11s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 10s - loss: 0.00 - ETA: 9s - loss: 0.0011 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 8s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 7s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 6s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 5s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 4s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 3s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 2s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 51s 6ms/sample - loss: 0.0010 - val_loss: 0.0000e+00\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - ETA: 45s - loss: 0.00 - ETA: 48s - loss: 8.8519e- - ETA: 46s - loss: 5.9013e- - ETA: 45s - loss: 4.4259e- - ETA: 44s - loss: 3.5408e- - ETA: 45s - loss: 2.9506e- - ETA: 45s - loss: 2.5291e- - ETA: 45s - loss: 2.2130e- - ETA: 46s - loss: 3.7432e- - ETA: 46s - loss: 6.7173e- - ETA: 45s - loss: 6.1067e- - ETA: 44s - loss: 5.5978e- - ETA: 44s - loss: 5.1672e- - ETA: 43s - loss: 5.7824e- - ETA: 43s - loss: 5.3969e- - ETA: 43s - loss: 5.0596e- - ETA: 42s - loss: 5.6898e- - ETA: 41s - loss: 5.3737e- - ETA: 41s - loss: 5.0909e- - ETA: 40s - loss: 4.8363e- - ETA: 39s - loss: 4.6060e- - ETA: 39s - loss: 4.3967e- - ETA: 38s - loss: 4.2055e- - ETA: 38s - loss: 4.0303e- - ETA: 37s - loss: 3.8691e- - ETA: 37s - loss: 5.1084e- - ETA: 36s - loss: 4.9192e- - ETA: 36s - loss: 4.7435e- - ETA: 35s - loss: 5.1038e- - ETA: 35s - loss: 4.9337e- - ETA: 34s - loss: 4.7746e- - ETA: 34s - loss: 4.6254e- - ETA: 34s - loss: 4.4852e- - ETA: 33s - loss: 4.5803e- - ETA: 33s - loss: 4.7150e- - ETA: 32s - loss: 5.0126e- - ETA: 32s - loss: 4.8771e- - ETA: 32s - loss: 4.7487e- - ETA: 32s - loss: 5.9037e- - ETA: 32s - loss: 6.7877e- - ETA: 31s - loss: 7.3272e- - ETA: 31s - loss: 7.1527e- - ETA: 31s - loss: 7.4540e- - ETA: 30s - loss: 8.1793e- - ETA: 30s - loss: 7.9976e- - ETA: 29s - loss: 7.8237e- - ETA: 29s - loss: 7.6573e- - ETA: 29s - loss: 7.7962e- - ETA: 28s - loss: 8.4961e- - ETA: 28s - loss: 8.6173e- - ETA: 28s - loss: 8.6379e- - ETA: 27s - loss: 8.4718e- - ETA: 27s - loss: 8.3119e- - ETA: 26s - loss: 8.6487e- - ETA: 26s - loss: 8.4914e- - ETA: 26s - loss: 8.3398e- - ETA: 25s - loss: 8.1935e- - ETA: 25s - loss: 8.0522e- - ETA: 24s - loss: 7.9158e- - ETA: 24s - loss: 8.1523e- - ETA: 24s - loss: 8.2975e- - ETA: 23s - loss: 8.1637e- - ETA: 23s - loss: 8.0341e- - ETA: 22s - loss: 8.1737e- - ETA: 22s - loss: 8.4265e- - ETA: 22s - loss: 8.2988e- - ETA: 21s - loss: 8.3694e- - ETA: 21s - loss: 8.2464e- - ETA: 21s - loss: 8.1269e- - ETA: 20s - loss: 8.0108e- - ETA: 20s - loss: 7.8979e- - ETA: 19s - loss: 8.0582e- - ETA: 19s - loss: 7.9478e- - ETA: 19s - loss: 7.8404e- - ETA: 18s - loss: 7.7359e- - ETA: 18s - loss: 7.6341e- - ETA: 17s - loss: 7.9609e- - ETA: 17s - loss: 7.8589e- - ETA: 17s - loss: 7.7594e- - ETA: 16s - loss: 8.2703e- - ETA: 16s - loss: 8.1682e- - ETA: 15s - loss: 8.0686e- - ETA: 15s - loss: 7.9714e- - ETA: 15s - loss: 7.8765e- - ETA: 14s - loss: 7.7838e- - ETA: 14s - loss: 8.2309e- - ETA: 14s - loss: 8.5568e- - ETA: 13s - loss: 8.7196e- - ETA: 13s - loss: 8.9610e- - ETA: 12s - loss: 8.8615e- - ETA: 12s - loss: 8.7641e- - ETA: 12s - loss: 8.6688e- - ETA: 11s - loss: 8.5756e- - ETA: 11s - loss: 8.4844e- - ETA: 11s - loss: 8.3951e- - ETA: 10s - loss: 8.6411e- - ETA: 10s - loss: 8.5520e- - ETA: 9s - loss: 8.4647e-04 - ETA: 9s - loss: 8.8395e-0 - ETA: 9s - loss: 8.7511e-0 - ETA: 8s - loss: 8.6645e-0 - ETA: 8s - loss: 8.5795e-0 - ETA: 8s - loss: 8.4962e-0 - ETA: 7s - loss: 8.6315e-0 - ETA: 7s - loss: 8.5493e-0 - ETA: 6s - loss: 8.5992e-0 - ETA: 6s - loss: 8.7583e-0 - ETA: 6s - loss: 8.6772e-0 - ETA: 5s - loss: 8.7544e-0 - ETA: 5s - loss: 8.9426e-0 - ETA: 5s - loss: 8.8620e-0 - ETA: 4s - loss: 8.7829e-0 - ETA: 4s - loss: 8.7052e-0 - ETA: 4s - loss: 9.5592e-0 - ETA: 3s - loss: 9.4761e-0 - ETA: 3s - loss: 9.4953e-0 - ETA: 2s - loss: 9.4142e-0 - ETA: 2s - loss: 9.3344e-0 - ETA: 2s - loss: 9.3946e-0 - ETA: 1s - loss: 9.3163e-0 - ETA: 1s - loss: 9.4724e-0 - ETA: 1s - loss: 9.6548e-0 - ETA: 0s - loss: 9.5763e-0 - ETA: 0s - loss: 9.6721e-0 - 49s 6ms/sample - loss: 9.5948e-04 - val_loss: 0.0000e+00\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - ETA: 42s - loss: 0.00 - ETA: 42s - loss: 7.0437e- - ETA: 42s - loss: 9.9243e- - ETA: 42s - loss: 9.3232e- - ETA: 41s - loss: 0.0011   - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 9.1673e- - ETA: 40s - loss: 0.0013   - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.00 - ETA: 37s - loss: 9.5264e- - ETA: 36s - loss: 8.9972e- - ETA: 36s - loss: 8.5236e- - ETA: 36s - loss: 8.0975e- - ETA: 36s - loss: 8.6375e- - ETA: 35s - loss: 8.6719e- - ETA: 35s - loss: 8.2948e- - ETA: 35s - loss: 7.9492e- - ETA: 34s - loss: 7.6313e- - ETA: 34s - loss: 8.1061e- - ETA: 34s - loss: 7.8058e- - ETA: 33s - loss: 7.5270e- - ETA: 33s - loss: 7.2675e- - ETA: 33s - loss: 7.0252e- - ETA: 32s - loss: 8.2630e- - ETA: 32s - loss: 8.0048e- - ETA: 31s - loss: 7.7622e- - ETA: 31s - loss: 7.5339e- - ETA: 31s - loss: 8.5974e- - ETA: 31s - loss: 8.3586e- - ETA: 30s - loss: 8.4212e- - ETA: 30s - loss: 8.1996e- - ETA: 30s - loss: 8.4501e- - ETA: 29s - loss: 8.2388e- - ETA: 29s - loss: 8.0379e- - ETA: 29s - loss: 7.8465e- - ETA: 28s - loss: 7.6640e- - ETA: 28s - loss: 7.4899e- - ETA: 28s - loss: 7.3234e- - ETA: 27s - loss: 7.1642e- - ETA: 27s - loss: 7.2058e- - ETA: 27s - loss: 7.0556e- - ETA: 26s - loss: 6.9117e- - ETA: 26s - loss: 6.7734e- - ETA: 26s - loss: 6.6406e- - ETA: 25s - loss: 6.5129e- - ETA: 25s - loss: 7.9308e- - ETA: 24s - loss: 7.7840e- - ETA: 24s - loss: 7.9359e- - ETA: 24s - loss: 8.4315e- - ETA: 23s - loss: 8.2836e- - ETA: 23s - loss: 8.1407e- - ETA: 23s - loss: 8.0028e- - ETA: 22s - loss: 7.8694e- - ETA: 22s - loss: 7.9726e- - ETA: 22s - loss: 7.8440e- - ETA: 21s - loss: 7.7195e- - ETA: 21s - loss: 7.5989e- - ETA: 20s - loss: 7.4820e- - ETA: 20s - loss: 7.3686e- - ETA: 20s - loss: 7.2586e- - ETA: 19s - loss: 7.1519e- - ETA: 19s - loss: 7.0483e- - ETA: 19s - loss: 6.9476e- - ETA: 18s - loss: 7.2259e- - ETA: 18s - loss: 7.1256e- - ETA: 18s - loss: 7.0280e- - ETA: 17s - loss: 7.2674e- - ETA: 17s - loss: 7.5645e- - ETA: 17s - loss: 8.0077e- - ETA: 16s - loss: 7.9037e- - ETA: 16s - loss: 7.9849e- - ETA: 16s - loss: 8.6426e- - ETA: 15s - loss: 8.8742e- - ETA: 15s - loss: 8.7647e- - ETA: 15s - loss: 8.6578e- - ETA: 14s - loss: 8.7274e- - ETA: 14s - loss: 8.6235e- - ETA: 13s - loss: 8.6121e- - ETA: 13s - loss: 8.5119e- - ETA: 13s - loss: 8.4141e- - ETA: 12s - loss: 8.8789e- - ETA: 12s - loss: 8.7792e- - ETA: 12s - loss: 8.6816e- - ETA: 11s - loss: 8.5862e- - ETA: 11s - loss: 8.8764e- - ETA: 11s - loss: 8.7810e- - ETA: 10s - loss: 8.6876e- - ETA: 10s - loss: 8.5961e- - ETA: 10s - loss: 9.0125e- - ETA: 9s - loss: 8.9196e-04 - ETA: 9s - loss: 9.5387e-0 - ETA: 9s - loss: 9.4424e-0 - ETA: 8s - loss: 9.3480e-0 - ETA: 8s - loss: 9.4329e-0 - ETA: 8s - loss: 9.3404e-0 - ETA: 7s - loss: 9.2497e-0 - ETA: 7s - loss: 9.1608e-0 - ETA: 6s - loss: 9.0735e-0 - ETA: 6s - loss: 8.9879e-0 - ETA: 6s - loss: 8.9039e-0 - ETA: 5s - loss: 8.8215e-0 - ETA: 5s - loss: 8.8260e-0 - ETA: 5s - loss: 8.7458e-0 - ETA: 4s - loss: 8.7750e-0 - ETA: 4s - loss: 8.6966e-0 - ETA: 4s - loss: 9.2096e-0 - ETA: 3s - loss: 9.1288e-0 - ETA: 3s - loss: 9.0494e-0 - ETA: 3s - loss: 8.9714e-0 - ETA: 2s - loss: 8.8947e-0 - ETA: 2s - loss: 8.8193e-0 - ETA: 2s - loss: 8.7452e-0 - ETA: 1s - loss: 8.6724e-0 - ETA: 1s - loss: 8.6007e-0 - ETA: 1s - loss: 8.5302e-0 - ETA: 0s - loss: 8.6053e-0 - ETA: 0s - loss: 8.5359e-0 - 47s 6ms/sample - loss: 8.4676e-04 - val_loss: 0.0000e+00\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - ETA: 41s - loss: 0.0000e+ - ETA: 41s - loss: 4.2053e- - ETA: 41s - loss: 0.0011   - ETA: 42s - loss: 7.9357e- - ETA: 41s - loss: 0.0012   - ETA: 41s - loss: 9.7493e- - ETA: 41s - loss: 8.3565e- - ETA: 40s - loss: 0.0011   - ETA: 40s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 39s - loss: 0.00 - ETA: 38s - loss: 0.00 - ETA: 38s - loss: 9.4416e- - ETA: 38s - loss: 0.0010   - ETA: 37s - loss: 9.3928e- - ETA: 37s - loss: 0.0011   - ETA: 37s - loss: 9.9395e- - ETA: 36s - loss: 9.3873e- - ETA: 36s - loss: 8.8932e- - ETA: 36s - loss: 9.3480e- - ETA: 35s - loss: 8.9029e- - ETA: 35s - loss: 8.4982e- - ETA: 35s - loss: 8.1287e- - ETA: 34s - loss: 7.7900e- - ETA: 34s - loss: 8.9465e- - ETA: 33s - loss: 9.5984e- - ETA: 33s - loss: 9.8637e- - ETA: 33s - loss: 0.0011   - ETA: 32s - loss: 0.00 - ETA: 32s - loss: 9.9376e- - ETA: 32s - loss: 0.0011   - ETA: 32s - loss: 0.00 - ETA: 31s - loss: 0.00 - ETA: 31s - loss: 9.7788e- - ETA: 30s - loss: 9.7423e- - ETA: 30s - loss: 9.4717e- - ETA: 30s - loss: 9.2157e- - ETA: 29s - loss: 9.2410e- - ETA: 29s - loss: 9.0040e- - ETA: 29s - loss: 8.7789e- - ETA: 28s - loss: 8.5648e- - ETA: 28s - loss: 8.3609e- - ETA: 28s - loss: 8.6017e- - ETA: 27s - loss: 8.4062e- - ETA: 27s - loss: 8.2194e- - ETA: 27s - loss: 9.1508e- - ETA: 26s - loss: 8.9561e- - ETA: 26s - loss: 9.1881e- - ETA: 26s - loss: 9.0006e- - ETA: 25s - loss: 9.5090e- - ETA: 25s - loss: 9.3226e- - ETA: 25s - loss: 9.1433e- - ETA: 24s - loss: 8.9708e- - ETA: 24s - loss: 9.2720e- - ETA: 24s - loss: 9.3576e- - ETA: 23s - loss: 9.1905e- - ETA: 23s - loss: 9.0292e- - ETA: 23s - loss: 9.4035e- - ETA: 22s - loss: 9.2441e- - ETA: 22s - loss: 9.0900e- - ETA: 22s - loss: 9.3369e- - ETA: 21s - loss: 9.5371e- - ETA: 21s - loss: 0.0010   - ETA: 21s - loss: 0.00 - ETA: 20s - loss: 9.9248e- - ETA: 20s - loss: 9.7744e- - ETA: 19s - loss: 9.6285e- - ETA: 19s - loss: 9.4869e- - ETA: 19s - loss: 9.4852e- - ETA: 18s - loss: 9.3497e- - ETA: 18s - loss: 9.2180e- - ETA: 18s - loss: 9.0900e- - ETA: 17s - loss: 8.9655e- - ETA: 17s - loss: 9.4896e- - ETA: 17s - loss: 9.3630e- - ETA: 16s - loss: 9.2398e- - ETA: 16s - loss: 9.1198e- - ETA: 16s - loss: 9.2075e- - ETA: 15s - loss: 9.0910e- - ETA: 15s - loss: 8.9773e- - ETA: 15s - loss: 9.3493e- - ETA: 14s - loss: 9.2353e- - ETA: 14s - loss: 9.1240e- - ETA: 14s - loss: 9.2554e- - ETA: 13s - loss: 9.1465e- - ETA: 13s - loss: 9.0401e- - ETA: 13s - loss: 8.9362e- - ETA: 12s - loss: 9.0463e- - ETA: 12s - loss: 9.3824e- - ETA: 12s - loss: 9.2781e- - ETA: 11s - loss: 9.1762e- - ETA: 11s - loss: 9.3047e- - ETA: 11s - loss: 9.5229e- - ETA: 10s - loss: 9.6408e- - ETA: 10s - loss: 9.6531e- - ETA: 10s - loss: 9.6722e- - ETA: 9s - loss: 9.5725e-04 - ETA: 9s - loss: 9.4748e-0 - ETA: 8s - loss: 9.3791e-0 - ETA: 8s - loss: 9.2853e-0 - ETA: 8s - loss: 9.1934e-0 - ETA: 7s - loss: 9.1033e-0 - ETA: 7s - loss: 9.0149e-0 - ETA: 7s - loss: 8.9282e-0 - ETA: 6s - loss: 8.8432e-0 - ETA: 6s - loss: 8.7597e-0 - ETA: 6s - loss: 8.6779e-0 - ETA: 5s - loss: 8.5975e-0 - ETA: 5s - loss: 8.6452e-0 - ETA: 5s - loss: 8.8287e-0 - ETA: 4s - loss: 8.7492e-0 - ETA: 4s - loss: 8.7919e-0 - ETA: 4s - loss: 8.8007e-0 - ETA: 3s - loss: 8.7235e-0 - ETA: 3s - loss: 8.8772e-0 - ETA: 3s - loss: 8.8007e-0 - ETA: 2s - loss: 8.7254e-0 - ETA: 2s - loss: 8.8396e-0 - ETA: 2s - loss: 8.7654e-0 - ETA: 1s - loss: 8.6923e-0 - ETA: 1s - loss: 8.6205e-0 - ETA: 1s - loss: 8.5498e-0 - ETA: 0s - loss: 8.4803e-0 - ETA: 0s - loss: 8.4119e-0 - 48s 6ms/sample - loss: 8.3446e-04 - val_loss: 0.0000e+00\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - ETA: 47s - loss: 0.0000e+ - ETA: 52s - loss: 0.0000e+ - ETA: 51s - loss: 4.4417e- - ETA: 50s - loss: 3.3312e- - ETA: 49s - loss: 2.6650e- - ETA: 49s - loss: 6.3163e- - ETA: 48s - loss: 5.4140e- - ETA: 47s - loss: 8.2336e- - ETA: 47s - loss: 8.6615e- - ETA: 46s - loss: 7.7953e- - ETA: 46s - loss: 7.0866e- - ETA: 45s - loss: 6.4961e- - ETA: 45s - loss: 5.9964e- - ETA: 45s - loss: 5.5681e- - ETA: 44s - loss: 5.1969e- - ETA: 43s - loss: 4.8721e- - ETA: 43s - loss: 4.5855e- - ETA: 42s - loss: 4.3307e- - ETA: 41s - loss: 4.1028e- - ETA: 41s - loss: 3.8977e- - ETA: 40s - loss: 3.7121e- - ETA: 39s - loss: 3.5433e- - ETA: 39s - loss: 3.3893e- - ETA: 38s - loss: 3.2480e- - ETA: 38s - loss: 3.1181e- - ETA: 37s - loss: 3.1999e- - ETA: 37s - loss: 3.0814e- - ETA: 36s - loss: 2.9713e- - ETA: 36s - loss: 2.8688e- - ETA: 35s - loss: 2.7732e- - ETA: 35s - loss: 4.2830e- - ETA: 34s - loss: 4.1491e- - ETA: 34s - loss: 4.4476e- - ETA: 34s - loss: 4.3168e- - ETA: 33s - loss: 4.1935e- - ETA: 33s - loss: 4.0770e- - ETA: 32s - loss: 4.3971e- - ETA: 32s - loss: 4.7092e- - ETA: 31s - loss: 4.5884e- - ETA: 31s - loss: 4.8410e- - ETA: 31s - loss: 4.9882e- - ETA: 30s - loss: 5.0770e- - ETA: 30s - loss: 4.9590e- - ETA: 29s - loss: 4.8463e- - ETA: 29s - loss: 5.7370e- - ETA: 28s - loss: 6.0872e- - ETA: 28s - loss: 5.9577e- - ETA: 28s - loss: 5.8336e- - ETA: 27s - loss: 7.1284e- - ETA: 27s - loss: 6.9858e- - ETA: 27s - loss: 6.8488e- - ETA: 26s - loss: 6.7171e- - ETA: 26s - loss: 6.5904e- - ETA: 25s - loss: 6.8086e- - ETA: 25s - loss: 6.6848e- - ETA: 25s - loss: 7.5101e- - ETA: 24s - loss: 7.3783e- - ETA: 24s - loss: 7.2511e- - ETA: 23s - loss: 7.6335e- - ETA: 23s - loss: 7.5062e- - ETA: 23s - loss: 7.3832e- - ETA: 22s - loss: 7.2641e- - ETA: 22s - loss: 7.1488e- - ETA: 22s - loss: 7.0371e- - ETA: 21s - loss: 6.9288e- - ETA: 21s - loss: 6.8238e- - ETA: 20s - loss: 6.7220e- - ETA: 20s - loss: 6.8262e- - ETA: 20s - loss: 6.7273e- - ETA: 19s - loss: 6.6312e- - ETA: 19s - loss: 6.5378e- - ETA: 19s - loss: 6.4470e- - ETA: 18s - loss: 6.3587e- - ETA: 18s - loss: 6.7789e- - ETA: 17s - loss: 6.6885e- - ETA: 17s - loss: 6.8701e- - ETA: 17s - loss: 6.7809e- - ETA: 16s - loss: 6.6940e- - ETA: 16s - loss: 6.6092e- - ETA: 16s - loss: 6.5266e- - ETA: 15s - loss: 6.4461e- - ETA: 15s - loss: 6.5076e- - ETA: 15s - loss: 6.4292e- - ETA: 14s - loss: 6.6521e- - ETA: 14s - loss: 6.5738e- - ETA: 14s - loss: 6.4974e- - ETA: 13s - loss: 6.4227e- - ETA: 13s - loss: 6.7140e- - ETA: 12s - loss: 6.6385e- - ETA: 12s - loss: 6.7074e- - ETA: 12s - loss: 7.2146e- - ETA: 11s - loss: 7.1362e- - ETA: 11s - loss: 7.3071e- - ETA: 11s - loss: 7.2293e- - ETA: 10s - loss: 7.1533e- - ETA: 10s - loss: 7.0787e- - ETA: 10s - loss: 7.0058e- - ETA: 9s - loss: 6.9343e-04 - ETA: 9s - loss: 6.8642e-0 - ETA: 9s - loss: 6.7956e-0 - ETA: 8s - loss: 6.7283e-0 - ETA: 8s - loss: 6.7657e-0 - ETA: 7s - loss: 6.8797e-0 - ETA: 7s - loss: 6.8135e-0 - ETA: 7s - loss: 6.7487e-0 - ETA: 6s - loss: 6.9917e-0 - ETA: 6s - loss: 6.9264e-0 - ETA: 6s - loss: 7.3446e-0 - ETA: 5s - loss: 7.2772e-0 - ETA: 5s - loss: 7.2110e-0 - ETA: 5s - loss: 7.1461e-0 - ETA: 4s - loss: 7.0823e-0 - ETA: 4s - loss: 7.0196e-0 - ETA: 3s - loss: 7.1446e-0 - ETA: 3s - loss: 7.2768e-0 - ETA: 3s - loss: 7.3885e-0 - ETA: 2s - loss: 7.5413e-0 - ETA: 2s - loss: 7.7034e-0 - ETA: 2s - loss: 7.8005e-0 - ETA: 1s - loss: 7.7355e-0 - ETA: 1s - loss: 7.6715e-0 - ETA: 1s - loss: 7.6087e-0 - ETA: 0s - loss: 8.0411e-0 - ETA: 0s - loss: 7.9763e-0 - 48s 6ms/sample - loss: 8.0765e-04 - val_loss: 0.0000e+00\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - ETA: 50s - loss: 0.0000e+ - ETA: 51s - loss: 0.0000e+ - ETA: 49s - loss: 0.0000e+ - ETA: 49s - loss: 0.0000e+ - ETA: 48s - loss: 0.0000e+ - ETA: 47s - loss: 0.0000e+ - ETA: 46s - loss: 1.8970e- - ETA: 45s - loss: 1.6599e- - ETA: 44s - loss: 1.4754e- - ETA: 44s - loss: 1.3279e- - ETA: 43s - loss: 1.2072e- - ETA: 43s - loss: 2.2867e- - ETA: 43s - loss: 3.4314e- - ETA: 42s - loss: 3.1863e- - ETA: 41s - loss: 2.9738e- - ETA: 41s - loss: 2.7880e- - ETA: 40s - loss: 2.6240e- - ETA: 39s - loss: 2.4782e- - ETA: 39s - loss: 2.3478e- - ETA: 38s - loss: 3.4761e- - ETA: 38s - loss: 4.0900e- - ETA: 38s - loss: 3.9041e- - ETA: 37s - loss: 3.7344e- - ETA: 37s - loss: 3.5788e- - ETA: 36s - loss: 3.4356e- - ETA: 36s - loss: 3.3035e- - ETA: 35s - loss: 3.1811e- - ETA: 35s - loss: 4.2877e- - ETA: 35s - loss: 5.3406e- - ETA: 34s - loss: 5.6021e- - ETA: 34s - loss: 5.4213e- - ETA: 33s - loss: 5.9035e- - ETA: 33s - loss: 5.7246e- - ETA: 33s - loss: 6.1046e- - ETA: 32s - loss: 5.9302e- - ETA: 32s - loss: 5.7655e- - ETA: 32s - loss: 5.6097e- - ETA: 31s - loss: 6.2073e- - ETA: 31s - loss: 6.7540e- - ETA: 30s - loss: 7.5954e- - ETA: 30s - loss: 7.4102e- - ETA: 30s - loss: 7.7753e- - ETA: 29s - loss: 7.5945e- - ETA: 29s - loss: 7.9388e- - ETA: 29s - loss: 8.0236e- - ETA: 28s - loss: 7.8492e- - ETA: 28s - loss: 7.6822e- - ETA: 27s - loss: 8.2824e- - ETA: 27s - loss: 8.1134e- - ETA: 27s - loss: 7.9511e- - ETA: 26s - loss: 7.7952e- - ETA: 26s - loss: 7.6453e- - ETA: 26s - loss: 7.9392e- - ETA: 25s - loss: 7.7921e- - ETA: 25s - loss: 7.6505e- - ETA: 24s - loss: 7.7233e- - ETA: 24s - loss: 7.5878e- - ETA: 24s - loss: 7.4570e- - ETA: 23s - loss: 7.3306e- - ETA: 23s - loss: 7.3492e- - ETA: 23s - loss: 7.2287e- - ETA: 22s - loss: 7.1121e- - ETA: 22s - loss: 7.1906e- - ETA: 21s - loss: 7.3552e- - ETA: 21s - loss: 7.3234e- - ETA: 21s - loss: 7.2125e- - ETA: 20s - loss: 7.1048e- - ETA: 20s - loss: 7.0003e- - ETA: 20s - loss: 6.8989e- - ETA: 19s - loss: 7.0901e- - ETA: 19s - loss: 7.1945e- - ETA: 19s - loss: 7.5006e- - ETA: 18s - loss: 7.3979e- - ETA: 18s - loss: 7.2979e- - ETA: 18s - loss: 7.2006e- - ETA: 17s - loss: 7.3285e- - ETA: 17s - loss: 7.2333e- - ETA: 16s - loss: 7.3532e- - ETA: 16s - loss: 7.6736e- - ETA: 16s - loss: 7.5777e- - ETA: 16s - loss: 7.7005e- - ETA: 15s - loss: 7.6066e- - ETA: 15s - loss: 7.5149e- - ETA: 15s - loss: 7.7669e- - ETA: 14s - loss: 7.6755e- - ETA: 14s - loss: 7.5862e- - ETA: 13s - loss: 7.4990e- - ETA: 13s - loss: 7.4138e- - ETA: 13s - loss: 7.3305e- - ETA: 12s - loss: 7.4276e- - ETA: 12s - loss: 7.3460e- - ETA: 12s - loss: 7.2661e- - ETA: 11s - loss: 7.1880e- - ETA: 11s - loss: 7.3452e- - ETA: 11s - loss: 7.2678e- - ETA: 10s - loss: 7.1921e- - ETA: 10s - loss: 7.1180e- - ETA: 10s - loss: 7.0454e- - ETA: 9s - loss: 7.2807e-04 - ETA: 9s - loss: 7.2079e-0 - ETA: 8s - loss: 7.3146e-0 - ETA: 8s - loss: 7.4716e-0 - ETA: 8s - loss: 7.3991e-0 - ETA: 7s - loss: 7.7583e-0 - ETA: 7s - loss: 7.7994e-0 - ETA: 7s - loss: 7.7258e-0 - ETA: 6s - loss: 7.6536e-0 - ETA: 6s - loss: 7.5828e-0 - ETA: 5s - loss: 7.7264e-0 - ETA: 5s - loss: 7.6562e-0 - ETA: 5s - loss: 7.5872e-0 - ETA: 4s - loss: 7.5195e-0 - ETA: 4s - loss: 7.5725e-0 - ETA: 4s - loss: 7.5061e-0 - ETA: 3s - loss: 7.4884e-0 - ETA: 3s - loss: 7.4239e-0 - ETA: 2s - loss: 7.3604e-0 - ETA: 2s - loss: 7.2980e-0 - ETA: 2s - loss: 7.6409e-0 - ETA: 1s - loss: 7.5772e-0 - ETA: 1s - loss: 7.5786e-0 - ETA: 1s - loss: 7.5165e-0 - ETA: 0s - loss: 7.4554e-0 - ETA: 0s - loss: 7.5724e-0 - 50s 6ms/sample - loss: 7.6279e-04 - val_loss: 0.0000e+00\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - ETA: 44s - loss: 0.0000e+ - ETA: 43s - loss: 6.7891e- - ETA: 42s - loss: 4.5261e- - ETA: 42s - loss: 0.0011   - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 43s - loss: 0.00 - ETA: 42s - loss: 0.00 - ETA: 41s - loss: 9.6944e- - ETA: 41s - loss: 0.0011   - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 41s - loss: 0.00 - ETA: 40s - loss: 9.5248e- - ETA: 40s - loss: 9.3374e- - ETA: 39s - loss: 8.7881e- - ETA: 39s - loss: 8.2999e- - ETA: 38s - loss: 7.8631e- - ETA: 38s - loss: 7.4699e- - ETA: 38s - loss: 7.7343e- - ETA: 37s - loss: 7.3828e- - ETA: 37s - loss: 7.0618e- - ETA: 37s - loss: 6.7675e- - ETA: 37s - loss: 6.4968e- - ETA: 36s - loss: 6.2470e- - ETA: 36s - loss: 6.0156e- - ETA: 36s - loss: 6.4458e- - ETA: 35s - loss: 6.7856e- - ETA: 35s - loss: 6.5594e- - ETA: 35s - loss: 6.3478e- - ETA: 34s - loss: 6.1494e- - ETA: 34s - loss: 5.9631e- - ETA: 33s - loss: 6.4564e- - ETA: 33s - loss: 6.2719e- - ETA: 33s - loss: 7.0566e- - ETA: 32s - loss: 7.0914e- - ETA: 32s - loss: 6.9048e- - ETA: 32s - loss: 6.7278e- - ETA: 31s - loss: 6.5596e- - ETA: 31s - loss: 6.7100e- - ETA: 30s - loss: 6.5502e- - ETA: 30s - loss: 6.3979e- - ETA: 30s - loss: 6.4665e- - ETA: 29s - loss: 6.3228e- - ETA: 29s - loss: 6.7369e- - ETA: 29s - loss: 6.5935e- - ETA: 28s - loss: 6.8982e- - ETA: 28s - loss: 6.7574e- - ETA: 27s - loss: 7.0205e- - ETA: 27s - loss: 7.1708e- - ETA: 27s - loss: 7.4330e- - ETA: 26s - loss: 7.6218e- - ETA: 26s - loss: 7.4807e- - ETA: 25s - loss: 7.3447e- - ETA: 25s - loss: 7.5926e- - ETA: 25s - loss: 7.8445e- - ETA: 24s - loss: 7.7093e- - ETA: 24s - loss: 7.5786e- - ETA: 24s - loss: 7.4523e- - ETA: 23s - loss: 7.3302e- - ETA: 23s - loss: 7.2119e- - ETA: 22s - loss: 7.0974e- - ETA: 22s - loss: 6.9865e- - ETA: 22s - loss: 6.8791e- - ETA: 21s - loss: 6.9589e- - ETA: 21s - loss: 7.1673e- - ETA: 20s - loss: 7.0619e- - ETA: 20s - loss: 7.1737e- - ETA: 20s - loss: 7.0712e- - ETA: 19s - loss: 7.1236e- - ETA: 19s - loss: 7.0247e- - ETA: 19s - loss: 6.9284e- - ETA: 18s - loss: 6.8348e- - ETA: 18s - loss: 6.7437e- - ETA: 17s - loss: 6.6549e- - ETA: 17s - loss: 7.0346e- - ETA: 17s - loss: 6.9444e- - ETA: 16s - loss: 6.8565e- - ETA: 16s - loss: 6.9386e- - ETA: 16s - loss: 6.8529e- - ETA: 15s - loss: 6.9704e- - ETA: 15s - loss: 6.8864e- - ETA: 14s - loss: 6.9671e- - ETA: 14s - loss: 6.8851e- - ETA: 14s - loss: 6.8051e- - ETA: 13s - loss: 6.7269e- - ETA: 13s - loss: 7.0900e- - ETA: 13s - loss: 7.0104e- - ETA: 12s - loss: 6.9325e- - ETA: 12s - loss: 6.8563e- - ETA: 12s - loss: 6.7818e- - ETA: 11s - loss: 6.7088e- - ETA: 11s - loss: 6.6375e- - ETA: 10s - loss: 6.5676e- - ETA: 10s - loss: 6.4992e- - ETA: 10s - loss: 6.4322e- - ETA: 9s - loss: 6.4861e-04 - ETA: 9s - loss: 6.4206e-0 - ETA: 9s - loss: 6.5122e-0 - ETA: 8s - loss: 6.4477e-0 - ETA: 8s - loss: 6.7861e-0 - ETA: 8s - loss: 6.7202e-0 - ETA: 7s - loss: 6.6556e-0 - ETA: 7s - loss: 6.5922e-0 - ETA: 6s - loss: 6.5300e-0 - ETA: 6s - loss: 6.5780e-0 - ETA: 6s - loss: 6.7381e-0 - ETA: 5s - loss: 6.6763e-0 - ETA: 5s - loss: 6.7425e-0 - ETA: 5s - loss: 6.6818e-0 - ETA: 4s - loss: 6.8109e-0 - ETA: 4s - loss: 6.7507e-0 - ETA: 4s - loss: 6.6914e-0 - ETA: 3s - loss: 6.6333e-0 - ETA: 3s - loss: 6.5761e-0 - ETA: 2s - loss: 6.8623e-0 - ETA: 2s - loss: 6.8042e-0 - ETA: 2s - loss: 6.8658e-0 - ETA: 1s - loss: 6.8086e-0 - ETA: 1s - loss: 6.7523e-0 - ETA: 1s - loss: 7.0120e-0 - ETA: 0s - loss: 6.9550e-0 - ETA: 0s - loss: 6.8989e-0 - 49s 6ms/sample - loss: 7.0131e-04 - val_loss: 0.0000e+00\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - ETA: 42s - loss: 0.00 - ETA: 43s - loss: 5.4810e- - ETA: 42s - loss: 3.6540e- - ETA: 42s - loss: 2.7405e- - ETA: 41s - loss: 4.2149e- - ETA: 41s - loss: 3.5124e- - ETA: 41s - loss: 3.0107e- - ETA: 41s - loss: 2.6343e- - ETA: 40s - loss: 2.3416e- - ETA: 40s - loss: 7.1753e- - ETA: 40s - loss: 6.5230e- - ETA: 39s - loss: 8.0009e- - ETA: 39s - loss: 8.2199e- - ETA: 39s - loss: 7.6328e- - ETA: 38s - loss: 8.6095e- - ETA: 38s - loss: 9.5917e- - ETA: 38s - loss: 9.0274e- - ETA: 37s - loss: 9.1102e- - ETA: 37s - loss: 8.6307e- - ETA: 37s - loss: 8.1992e- - ETA: 36s - loss: 8.6867e- - ETA: 36s - loss: 8.2919e- - ETA: 36s - loss: 7.9314e- - ETA: 35s - loss: 8.1907e- - ETA: 35s - loss: 7.8631e- - ETA: 35s - loss: 7.5607e- - ETA: 34s - loss: 7.2806e- - ETA: 34s - loss: 7.0206e- - ETA: 34s - loss: 6.7785e- - ETA: 33s - loss: 6.5526e- - ETA: 33s - loss: 6.3412e- - ETA: 33s - loss: 6.1430e- - ETA: 32s - loss: 6.4361e- - ETA: 32s - loss: 6.6896e- - ETA: 32s - loss: 6.4985e- - ETA: 31s - loss: 6.3180e- - ETA: 31s - loss: 6.1472e- - ETA: 31s - loss: 5.9854e- - ETA: 30s - loss: 5.8320e- - ETA: 30s - loss: 5.6862e- - ETA: 29s - loss: 5.5475e- - ETA: 29s - loss: 5.4154e- - ETA: 29s - loss: 5.5312e- - ETA: 28s - loss: 5.6804e- - ETA: 28s - loss: 5.7939e- - ETA: 28s - loss: 5.9865e- - ETA: 27s - loss: 5.8591e- - ETA: 27s - loss: 5.7370e- - ETA: 27s - loss: 5.6200e- - ETA: 26s - loss: 5.5076e- - ETA: 26s - loss: 5.3996e- - ETA: 26s - loss: 5.2957e- - ETA: 25s - loss: 5.4833e- - ETA: 25s - loss: 5.3818e- - ETA: 25s - loss: 5.2839e- - ETA: 24s - loss: 5.1896e- - ETA: 24s - loss: 5.0985e- - ETA: 24s - loss: 5.0106e- - ETA: 23s - loss: 4.9257e- - ETA: 23s - loss: 4.8436e- - ETA: 22s - loss: 4.7642e- - ETA: 22s - loss: 4.8876e- - ETA: 22s - loss: 4.8100e- - ETA: 21s - loss: 4.7348e- - ETA: 21s - loss: 5.1748e- - ETA: 21s - loss: 5.3048e- - ETA: 20s - loss: 5.6034e- - ETA: 20s - loss: 5.5210e- - ETA: 20s - loss: 5.4410e- - ETA: 20s - loss: 5.3633e- - ETA: 19s - loss: 5.2877e- - ETA: 19s - loss: 5.3094e- - ETA: 19s - loss: 5.2366e- - ETA: 18s - loss: 5.1659e- - ETA: 18s - loss: 5.4251e- - ETA: 18s - loss: 5.7116e- - ETA: 17s - loss: 5.8065e- - ETA: 17s - loss: 6.1052e- - ETA: 17s - loss: 6.0279e- - ETA: 16s - loss: 5.9525e- - ETA: 16s - loss: 5.8790e- - ETA: 16s - loss: 5.9716e- - ETA: 15s - loss: 5.8996e- - ETA: 15s - loss: 5.8294e- - ETA: 15s - loss: 5.7608e- - ETA: 14s - loss: 5.6938e- - ETA: 14s - loss: 5.6284e- - ETA: 13s - loss: 5.7888e- - ETA: 13s - loss: 5.7238e- - ETA: 13s - loss: 5.6602e- - ETA: 13s - loss: 5.7961e- - ETA: 12s - loss: 5.7905e- - ETA: 12s - loss: 6.1849e- - ETA: 12s - loss: 6.1191e- - ETA: 11s - loss: 6.1368e- - ETA: 11s - loss: 6.0728e- - ETA: 10s - loss: 6.4441e- - ETA: 10s - loss: 6.5691e- - ETA: 10s - loss: 6.5027e- - ETA: 9s - loss: 6.4377e-04 - ETA: 9s - loss: 6.3739e-0 - ETA: 8s - loss: 6.3115e-0 - ETA: 8s - loss: 6.2502e-0 - ETA: 8s - loss: 6.1901e-0 - ETA: 7s - loss: 6.2245e-0 - ETA: 7s - loss: 6.1658e-0 - ETA: 6s - loss: 6.1081e-0 - ETA: 6s - loss: 6.0516e-0 - ETA: 6s - loss: 5.9961e-0 - ETA: 5s - loss: 5.9416e-0 - ETA: 5s - loss: 6.0257e-0 - ETA: 5s - loss: 5.9719e-0 - ETA: 4s - loss: 6.2443e-0 - ETA: 4s - loss: 6.1895e-0 - ETA: 3s - loss: 6.2541e-0 - ETA: 3s - loss: 6.2002e-0 - ETA: 3s - loss: 6.4466e-0 - ETA: 2s - loss: 6.4575e-0 - ETA: 2s - loss: 6.4033e-0 - ETA: 1s - loss: 6.5628e-0 - ETA: 1s - loss: 6.5086e-0 - ETA: 1s - loss: 6.6812e-0 - ETA: 0s - loss: 6.6269e-0 - ETA: 0s - loss: 6.6753e-0 - 51s 6ms/sample - loss: 6.6219e-04 - val_loss: 0.0000e+00\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - ETA: 46s - loss: 0.0000e+ - ETA: 45s - loss: 3.0263e- - ETA: 44s - loss: 2.0175e- - ETA: 44s - loss: 1.5131e- - ETA: 43s - loss: 3.4905e- - ETA: 42s - loss: 6.4902e- - ETA: 42s - loss: 8.3023e- - ETA: 41s - loss: 7.2645e- - ETA: 42s - loss: 6.4574e- - ETA: 42s - loss: 5.8116e- - ETA: 41s - loss: 5.2833e- - ETA: 41s - loss: 4.8430e- - ETA: 41s - loss: 4.4705e- - ETA: 40s - loss: 4.1512e- - ETA: 40s - loss: 5.2542e- - ETA: 39s - loss: 7.2209e- - ETA: 39s - loss: 7.2215e- - ETA: 38s - loss: 6.8203e- - ETA: 38s - loss: 6.4613e- - ETA: 38s - loss: 6.1383e- - ETA: 37s - loss: 5.8460e- - ETA: 37s - loss: 5.5802e- - ETA: 36s - loss: 5.3376e- - ETA: 36s - loss: 5.1152e- - ETA: 35s - loss: 4.9106e- - ETA: 35s - loss: 4.7217e- - ETA: 35s - loss: 5.3327e- - ETA: 35s - loss: 5.1423e- - ETA: 34s - loss: 4.9649e- - ETA: 34s - loss: 4.7995e- - ETA: 33s - loss: 5.2089e- - ETA: 33s - loss: 5.0461e- - ETA: 33s - loss: 4.8932e- - ETA: 32s - loss: 4.7493e- - ETA: 32s - loss: 4.6136e- - ETA: 31s - loss: 4.7426e- - ETA: 31s - loss: 4.6144e- - ETA: 31s - loss: 4.6919e- - ETA: 30s - loss: 4.8369e- - ETA: 30s - loss: 4.7160e- - ETA: 30s - loss: 4.9124e- - ETA: 29s - loss: 4.7954e- - ETA: 29s - loss: 4.6839e- - ETA: 29s - loss: 4.5774e- - ETA: 28s - loss: 4.6907e- - ETA: 28s - loss: 4.5887e- - ETA: 28s - loss: 4.4911e- - ETA: 27s - loss: 4.3975e- - ETA: 27s - loss: 4.3743e- - ETA: 26s - loss: 4.2868e- - ETA: 26s - loss: 4.2027e- - ETA: 26s - loss: 4.1219e- - ETA: 26s - loss: 4.0441e- - ETA: 25s - loss: 3.9692e- - ETA: 25s - loss: 3.8971e- - ETA: 25s - loss: 3.8275e- - ETA: 25s - loss: 4.1552e- - ETA: 24s - loss: 4.0836e- - ETA: 24s - loss: 4.0144e- - ETA: 24s - loss: 3.9475e- - ETA: 23s - loss: 4.1974e- - ETA: 23s - loss: 4.1297e- - ETA: 23s - loss: 4.5029e- - ETA: 22s - loss: 4.4325e- - ETA: 22s - loss: 4.8446e- - ETA: 21s - loss: 4.7712e- - ETA: 21s - loss: 4.7000e- - ETA: 21s - loss: 4.6309e- - ETA: 20s - loss: 4.5638e- - ETA: 20s - loss: 4.7583e- - ETA: 19s - loss: 4.6913e- - ETA: 19s - loss: 5.1829e- - ETA: 19s - loss: 5.1119e- - ETA: 18s - loss: 5.0428e- - ETA: 18s - loss: 4.9756e- - ETA: 18s - loss: 5.0814e- - ETA: 17s - loss: 5.0154e- - ETA: 17s - loss: 4.9511e- - ETA: 17s - loss: 4.8884e- - ETA: 16s - loss: 5.1764e- - ETA: 16s - loss: 5.2594e- - ETA: 16s - loss: 5.3806e- - ETA: 15s - loss: 5.3157e- - ETA: 15s - loss: 5.2525e- - ETA: 14s - loss: 5.6081e- - ETA: 14s - loss: 5.7305e- - ETA: 14s - loss: 5.8782e- - ETA: 13s - loss: 5.8114e- - ETA: 13s - loss: 5.7461e- - ETA: 13s - loss: 5.6822e- - ETA: 12s - loss: 6.0119e- - ETA: 12s - loss: 5.9465e- - ETA: 11s - loss: 5.8826e- - ETA: 11s - loss: 5.8200e- - ETA: 11s - loss: 5.7587e- - ETA: 10s - loss: 5.6987e- - ETA: 10s - loss: 5.6400e- - ETA: 10s - loss: 5.5824e- - ETA: 9s - loss: 5.6720e-04 - ETA: 9s - loss: 5.6153e-0 - ETA: 8s - loss: 5.9310e-0 - ETA: 8s - loss: 6.0803e-0 - ETA: 8s - loss: 6.0212e-0 - ETA: 7s - loss: 6.0390e-0 - ETA: 7s - loss: 5.9815e-0 - ETA: 7s - loss: 5.9251e-0 - ETA: 6s - loss: 5.9671e-0 - ETA: 6s - loss: 6.0817e-0 - ETA: 5s - loss: 6.0996e-0 - ETA: 5s - loss: 6.3038e-0 - ETA: 5s - loss: 6.2470e-0 - ETA: 4s - loss: 6.1912e-0 - ETA: 4s - loss: 6.1364e-0 - ETA: 4s - loss: 6.3948e-0 - ETA: 3s - loss: 6.3392e-0 - ETA: 3s - loss: 6.2846e-0 - ETA: 3s - loss: 6.2309e-0 - ETA: 2s - loss: 6.1780e-0 - ETA: 2s - loss: 6.1261e-0 - ETA: 1s - loss: 6.1267e-0 - ETA: 1s - loss: 6.0760e-0 - ETA: 1s - loss: 6.0262e-0 - ETA: 0s - loss: 6.0393e-0 - ETA: 0s - loss: 6.1719e-0 - 54s 7ms/sample - loss: 6.1226e-04 - val_loss: 0.0000e+00\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - ETA: 45s - loss: 0.0000e+ - ETA: 47s - loss: 0.0000e+ - ETA: 46s - loss: 0.0000e+ - ETA: 45s - loss: 0.0000e+ - ETA: 45s - loss: 0.0000e+ - ETA: 45s - loss: 0.0000e+ - ETA: 44s - loss: 0.0000e+ - ETA: 44s - loss: 3.4413e- - ETA: 44s - loss: 3.0589e- - ETA: 43s - loss: 2.7530e- - ETA: 43s - loss: 1.8233e- - ETA: 42s - loss: 1.6713e- - ETA: 42s - loss: 2.0886e- - ETA: 41s - loss: 1.9394e- - ETA: 41s - loss: 1.8101e- - ETA: 41s - loss: 1.6970e- - ETA: 40s - loss: 2.5026e- - ETA: 40s - loss: 2.3636e- - ETA: 39s - loss: 3.0207e- - ETA: 39s - loss: 2.8697e- - ETA: 39s - loss: 3.3664e- - ETA: 39s - loss: 3.2134e- - ETA: 38s - loss: 3.0737e- - ETA: 38s - loss: 2.9456e- - ETA: 37s - loss: 3.6742e- - ETA: 37s - loss: 3.5329e- - ETA: 37s - loss: 3.7665e- - ETA: 36s - loss: 4.6008e- - ETA: 36s - loss: 4.4422e- - ETA: 36s - loss: 4.2941e- - ETA: 35s - loss: 4.9056e- - ETA: 35s - loss: 5.4502e- - ETA: 35s - loss: 5.2851e- - ETA: 34s - loss: 5.1296e- - ETA: 34s - loss: 4.9831e- - ETA: 33s - loss: 5.0099e- - ETA: 33s - loss: 4.8745e- - ETA: 33s - loss: 4.8354e- - ETA: 32s - loss: 5.0823e- - ETA: 32s - loss: 4.9552e- - ETA: 32s - loss: 4.8344e- - ETA: 31s - loss: 4.9508e- - ETA: 31s - loss: 4.8356e- - ETA: 30s - loss: 4.9325e- - ETA: 30s - loss: 5.1825e- - ETA: 30s - loss: 5.0698e- - ETA: 29s - loss: 4.9620e- - ETA: 29s - loss: 4.8586e- - ETA: 29s - loss: 4.7594e- - ETA: 28s - loss: 4.6642e- - ETA: 28s - loss: 5.0184e- - ETA: 27s - loss: 5.4876e- - ETA: 27s - loss: 5.7166e- - ETA: 27s - loss: 5.6108e- - ETA: 26s - loss: 5.5088e- - ETA: 26s - loss: 5.8192e- - ETA: 26s - loss: 5.7171e- - ETA: 25s - loss: 5.6185e- - ETA: 25s - loss: 5.5233e- - ETA: 24s - loss: 5.4313e- - ETA: 24s - loss: 5.3422e- - ETA: 24s - loss: 5.2560e- - ETA: 23s - loss: 5.4176e- - ETA: 23s - loss: 5.4003e- - ETA: 23s - loss: 5.5511e- - ETA: 22s - loss: 5.5903e- - ETA: 22s - loss: 5.5069e- - ETA: 22s - loss: 5.4259e- - ETA: 21s - loss: 5.3473e- - ETA: 21s - loss: 5.3947e- - ETA: 21s - loss: 5.3187e- - ETA: 20s - loss: 5.2449e- - ETA: 20s - loss: 5.2965e- - ETA: 20s - loss: 5.5668e- - ETA: 19s - loss: 5.4926e- - ETA: 19s - loss: 5.4203e- - ETA: 19s - loss: 5.3499e- - ETA: 18s - loss: 5.2813e- - ETA: 18s - loss: 5.2145e- - ETA: 18s - loss: 5.4636e- - ETA: 17s - loss: 5.7626e- - ETA: 17s - loss: 5.6923e- - ETA: 17s - loss: 5.7784e- - ETA: 16s - loss: 5.7096e- - ETA: 16s - loss: 5.6425e- - ETA: 15s - loss: 5.5769e- - ETA: 15s - loss: 5.5128e- - ETA: 15s - loss: 5.4501e- - ETA: 14s - loss: 5.3889e- - ETA: 14s - loss: 5.5256e- - ETA: 13s - loss: 5.4648e- - ETA: 13s - loss: 5.4054e- - ETA: 13s - loss: 5.6044e- - ETA: 12s - loss: 5.5448e- - ETA: 12s - loss: 5.6314e- - ETA: 12s - loss: 5.7559e- - ETA: 11s - loss: 6.1435e- - ETA: 11s - loss: 6.3956e- - ETA: 10s - loss: 6.3310e- - ETA: 10s - loss: 6.2677e- - ETA: 10s - loss: 6.2057e- - ETA: 9s - loss: 6.1448e-04 - ETA: 9s - loss: 6.0852e-0 - ETA: 8s - loss: 6.0267e-0 - ETA: 8s - loss: 5.9693e-0 - ETA: 8s - loss: 5.9129e-0 - ETA: 7s - loss: 5.8577e-0 - ETA: 7s - loss: 5.8034e-0 - ETA: 6s - loss: 6.1171e-0 - ETA: 6s - loss: 6.3636e-0 - ETA: 5s - loss: 6.3063e-0 - ETA: 5s - loss: 6.2500e-0 - ETA: 5s - loss: 6.1947e-0 - ETA: 4s - loss: 6.2688e-0 - ETA: 4s - loss: 6.3451e-0 - ETA: 3s - loss: 6.4603e-0 - ETA: 3s - loss: 6.4051e-0 - ETA: 3s - loss: 6.3508e-0 - ETA: 2s - loss: 6.2975e-0 - ETA: 2s - loss: 6.3919e-0 - ETA: 1s - loss: 6.3391e-0 - ETA: 1s - loss: 6.2871e-0 - ETA: 0s - loss: 6.2360e-0 - ETA: 0s - loss: 6.1857e-0 - 59s 7ms/sample - loss: 6.1362e-04 - val_loss: 0.0000e+00\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - ETA: 55s - loss: 0.00 - ETA: 55s - loss: 7.5467e- - ETA: 55s - loss: 0.0013   - ETA: 55s - loss: 0.00 - ETA: 53s - loss: 9.0857e- - ETA: 53s - loss: 7.5714e- - ETA: 53s - loss: 6.4898e- - ETA: 53s - loss: 7.6341e- - ETA: 52s - loss: 6.7858e- - ETA: 52s - loss: 6.1073e- - ETA: 51s - loss: 5.5521e- - ETA: 50s - loss: 5.0894e- - ETA: 50s - loss: 4.6979e- - ETA: 49s - loss: 4.3623e- - ETA: 49s - loss: 4.0715e- - ETA: 49s - loss: 4.8092e- - ETA: 49s - loss: 4.5263e- - ETA: 48s - loss: 6.2149e- - ETA: 48s - loss: 5.8878e- - ETA: 47s - loss: 5.5934e- - ETA: 47s - loss: 5.3270e- - ETA: 46s - loss: 5.0849e- - ETA: 46s - loss: 5.6143e- - ETA: 46s - loss: 6.6664e- - ETA: 46s - loss: 6.3997e- - ETA: 45s - loss: 7.0989e- - ETA: 45s - loss: 6.8360e- - ETA: 45s - loss: 6.5918e- - ETA: 44s - loss: 6.3645e- - ETA: 44s - loss: 6.1524e- - ETA: 44s - loss: 5.9539e- - ETA: 43s - loss: 5.7678e- - ETA: 43s - loss: 5.5931e- - ETA: 42s - loss: 5.7754e- - ETA: 42s - loss: 5.6104e- - ETA: 42s - loss: 5.4546e- - ETA: 41s - loss: 5.3072e- - ETA: 41s - loss: 5.1675e- - ETA: 41s - loss: 5.0350e- - ETA: 40s - loss: 4.9091e- - ETA: 40s - loss: 4.7894e- - ETA: 39s - loss: 5.0900e- - ETA: 39s - loss: 4.9716e- - ETA: 38s - loss: 4.8586e- - ETA: 38s - loss: 4.7507e- - ETA: 37s - loss: 4.9363e- - ETA: 36s - loss: 4.8313e- - ETA: 36s - loss: 4.7306e- - ETA: 35s - loss: 4.6341e- - ETA: 35s - loss: 4.5414e- - ETA: 35s - loss: 4.6599e- - ETA: 34s - loss: 4.5703e- - ETA: 34s - loss: 4.6495e- - ETA: 33s - loss: 4.5634e- - ETA: 33s - loss: 4.4804e- - ETA: 32s - loss: 4.4004e- - ETA: 32s - loss: 4.3232e- - ETA: 31s - loss: 4.2487e- - ETA: 31s - loss: 4.1767e- - ETA: 30s - loss: 4.1071e- - ETA: 30s - loss: 4.0397e- - ETA: 29s - loss: 3.9746e- - ETA: 29s - loss: 3.9115e- - ETA: 28s - loss: 3.8504e- - ETA: 28s - loss: 4.1444e- - ETA: 28s - loss: 4.0816e- - ETA: 27s - loss: 4.0207e- - ETA: 27s - loss: 4.2668e- - ETA: 26s - loss: 4.4719e- - ETA: 26s - loss: 4.5106e- - ETA: 25s - loss: 4.5535e- - ETA: 25s - loss: 4.8178e- - ETA: 24s - loss: 4.7518e- - ETA: 24s - loss: 4.7586e- - ETA: 23s - loss: 4.6952e- - ETA: 23s - loss: 4.6334e- - ETA: 22s - loss: 4.8901e- - ETA: 22s - loss: 4.8274e- - ETA: 21s - loss: 4.7663e- - ETA: 21s - loss: 4.9327e- - ETA: 20s - loss: 5.0744e- - ETA: 20s - loss: 5.6515e- - ETA: 20s - loss: 5.5834e- - ETA: 19s - loss: 5.5573e- - ETA: 19s - loss: 5.4919e- - ETA: 19s - loss: 5.4280e- - ETA: 18s - loss: 5.3656e- - ETA: 18s - loss: 5.3047e- - ETA: 17s - loss: 5.3307e- - ETA: 17s - loss: 5.6577e- - ETA: 16s - loss: 5.5956e- - ETA: 16s - loss: 5.8017e- - ETA: 15s - loss: 5.9056e- - ETA: 15s - loss: 5.8427e- - ETA: 14s - loss: 5.7812e- - ETA: 14s - loss: 5.7210e- - ETA: 14s - loss: 5.7812e- - ETA: 13s - loss: 5.7222e- - ETA: 13s - loss: 5.6644e- - ETA: 12s - loss: 5.6077e- - ETA: 12s - loss: 5.5522e- - ETA: 11s - loss: 5.6153e- - ETA: 11s - loss: 5.5608e- - ETA: 10s - loss: 6.1994e- - ETA: 10s - loss: 6.1404e- - ETA: 9s - loss: 6.0825e-04 - ETA: 9s - loss: 6.2388e-0 - ETA: 8s - loss: 6.1811e-0 - ETA: 8s - loss: 6.1243e-0 - ETA: 7s - loss: 6.0687e-0 - ETA: 7s - loss: 6.0140e-0 - ETA: 6s - loss: 5.9603e-0 - ETA: 6s - loss: 5.9076e-0 - ETA: 5s - loss: 5.8557e-0 - ETA: 5s - loss: 5.8598e-0 - ETA: 4s - loss: 5.9112e-0 - ETA: 4s - loss: 5.8607e-0 - ETA: 3s - loss: 5.8110e-0 - ETA: 3s - loss: 5.7622e-0 - ETA: 2s - loss: 5.7142e-0 - ETA: 2s - loss: 5.6670e-0 - ETA: 1s - loss: 5.7297e-0 - ETA: 1s - loss: 5.6832e-0 - ETA: 0s - loss: 5.6373e-0 - 69s 9ms/sample - loss: 5.6624e-04 - val_loss: 0.0000e+00\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - ETA: 49s - loss: 0.0000e+ - ETA: 53s - loss: 0.0000e+ - ETA: 53s - loss: 5.8244e- - ETA: 52s - loss: 4.3683e- - ETA: 51s - loss: 3.4946e- - ETA: 50s - loss: 2.9122e- - ETA: 49s - loss: 2.4962e- - ETA: 49s - loss: 2.1841e- - ETA: 48s - loss: 1.9415e- - ETA: 47s - loss: 1.7473e- - ETA: 47s - loss: 1.5885e- - ETA: 46s - loss: 1.4561e- - ETA: 46s - loss: 1.3441e- - ETA: 46s - loss: 2.1352e- - ETA: 46s - loss: 2.1847e- - ETA: 46s - loss: 2.0482e- - ETA: 45s - loss: 1.9277e- - ETA: 45s - loss: 1.8206e- - ETA: 45s - loss: 1.7248e- - ETA: 44s - loss: 1.9919e- - ETA: 44s - loss: 2.3342e- - ETA: 44s - loss: 2.2281e- - ETA: 44s - loss: 2.1312e- - ETA: 44s - loss: 2.0424e- - ETA: 44s - loss: 1.9607e- - ETA: 44s - loss: 2.0710e- - ETA: 44s - loss: 3.0339e- - ETA: 43s - loss: 2.9255e- - ETA: 43s - loss: 2.8246e- - ETA: 43s - loss: 2.7305e- - ETA: 43s - loss: 2.6424e- - ETA: 42s - loss: 2.8513e- - ETA: 42s - loss: 3.1295e- - ETA: 42s - loss: 3.0375e- - ETA: 41s - loss: 3.3854e- - ETA: 41s - loss: 3.4406e- - ETA: 40s - loss: 3.5680e- - ETA: 40s - loss: 4.1742e- - ETA: 39s - loss: 4.0672e- - ETA: 39s - loss: 3.9655e- - ETA: 38s - loss: 3.8688e- - ETA: 38s - loss: 3.7767e- - ETA: 37s - loss: 3.6889e- - ETA: 37s - loss: 3.6050e- - ETA: 36s - loss: 3.5249e- - ETA: 36s - loss: 3.7538e- - ETA: 35s - loss: 3.6739e- - ETA: 35s - loss: 4.5049e- - ETA: 34s - loss: 4.4130e- - ETA: 34s - loss: 5.0081e- - ETA: 33s - loss: 5.1419e- - ETA: 33s - loss: 5.0430e- - ETA: 33s - loss: 4.9478e- - ETA: 32s - loss: 4.8562e- - ETA: 32s - loss: 4.9259e- - ETA: 31s - loss: 4.8379e- - ETA: 31s - loss: 4.7531e- - ETA: 30s - loss: 4.7605e- - ETA: 30s - loss: 4.6798e- - ETA: 29s - loss: 4.7542e- - ETA: 29s - loss: 4.6763e- - ETA: 28s - loss: 4.8773e- - ETA: 28s - loss: 4.7999e- - ETA: 27s - loss: 4.7249e- - ETA: 27s - loss: 4.6522e- - ETA: 26s - loss: 4.5817e- - ETA: 26s - loss: 4.5134e- - ETA: 25s - loss: 4.7394e- - ETA: 25s - loss: 4.6707e- - ETA: 25s - loss: 4.7409e- - ETA: 24s - loss: 4.6741e- - ETA: 24s - loss: 4.6092e- - ETA: 23s - loss: 5.2208e- - ETA: 23s - loss: 5.3231e- - ETA: 22s - loss: 5.2522e- - ETA: 22s - loss: 5.1831e- - ETA: 22s - loss: 5.1157e- - ETA: 21s - loss: 5.0502e- - ETA: 21s - loss: 5.2572e- - ETA: 20s - loss: 5.1914e- - ETA: 20s - loss: 5.5380e- - ETA: 19s - loss: 5.4705e- - ETA: 19s - loss: 5.5485e- - ETA: 18s - loss: 5.7461e- - ETA: 18s - loss: 5.6785e- - ETA: 17s - loss: 5.6125e- - ETA: 17s - loss: 5.9147e- - ETA: 16s - loss: 5.9674e- - ETA: 16s - loss: 5.9004e- - ETA: 15s - loss: 5.8348e- - ETA: 15s - loss: 5.7707e- - ETA: 14s - loss: 5.7080e- - ETA: 14s - loss: 5.7652e- - ETA: 13s - loss: 5.7038e- - ETA: 13s - loss: 5.6438e- - ETA: 13s - loss: 5.5850e- - ETA: 12s - loss: 5.5274e- - ETA: 12s - loss: 5.4710e- - ETA: 11s - loss: 5.5747e- - ETA: 11s - loss: 5.5190e- - ETA: 10s - loss: 5.4643e- - ETA: 10s - loss: 5.4108e- - ETA: 9s - loss: 5.3582e-04 - ETA: 9s - loss: 5.3067e-0 - ETA: 8s - loss: 5.2562e-0 - ETA: 8s - loss: 5.5962e-0 - ETA: 8s - loss: 5.5439e-0 - ETA: 7s - loss: 5.4925e-0 - ETA: 7s - loss: 5.5751e-0 - ETA: 6s - loss: 5.8557e-0 - ETA: 6s - loss: 5.8030e-0 - ETA: 5s - loss: 5.8212e-0 - ETA: 5s - loss: 5.7697e-0 - ETA: 4s - loss: 5.7907e-0 - ETA: 4s - loss: 5.7403e-0 - ETA: 4s - loss: 5.6908e-0 - ETA: 3s - loss: 5.6422e-0 - ETA: 3s - loss: 5.8519e-0 - ETA: 2s - loss: 5.8027e-0 - ETA: 2s - loss: 5.7543e-0 - ETA: 1s - loss: 5.7068e-0 - ETA: 1s - loss: 5.6600e-0 - ETA: 0s - loss: 6.0522e-0 - ETA: 0s - loss: 6.0034e-0 - 59s 7ms/sample - loss: 5.9554e-04 - val_loss: 0.0000e+00\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - ETA: 44s - loss: 0.0000e+ - ETA: 46s - loss: 0.0000e+ - ETA: 45s - loss: 0.0000e+ - ETA: 45s - loss: 2.2798e- - ETA: 45s - loss: 1.8239e- - ETA: 45s - loss: 1.5199e- - ETA: 45s - loss: 2.6840e- - ETA: 45s - loss: 3.5981e- - ETA: 44s - loss: 4.3807e- - ETA: 43s - loss: 3.9426e- - ETA: 42s - loss: 3.5842e- - ETA: 42s - loss: 4.2954e- - ETA: 42s - loss: 4.2570e- - ETA: 42s - loss: 4.8880e- - ETA: 42s - loss: 4.5621e- - ETA: 42s - loss: 4.7428e- - ETA: 41s - loss: 4.4638e- - ETA: 41s - loss: 4.2158e- - ETA: 41s - loss: 3.9939e- - ETA: 41s - loss: 4.0775e- - ETA: 41s - loss: 3.8834e- - ETA: 40s - loss: 3.7069e- - ETA: 40s - loss: 3.5457e- - ETA: 40s - loss: 3.3980e- - ETA: 39s - loss: 3.8703e- - ETA: 39s - loss: 3.7214e- - ETA: 39s - loss: 3.8822e- - ETA: 38s - loss: 3.8547e- - ETA: 39s - loss: 3.7218e- - ETA: 38s - loss: 4.1124e- - ETA: 38s - loss: 3.9798e- - ETA: 38s - loss: 3.8554e- - ETA: 38s - loss: 3.7386e- - ETA: 38s - loss: 3.6286e- - ETA: 37s - loss: 4.1092e- - ETA: 37s - loss: 3.9950e- - ETA: 37s - loss: 3.8871e- - ETA: 36s - loss: 3.7848e- - ETA: 36s - loss: 3.8680e- - ETA: 36s - loss: 3.7713e- - ETA: 35s - loss: 3.6794e- - ETA: 35s - loss: 3.5918e- - ETA: 34s - loss: 3.5082e- - ETA: 34s - loss: 4.0808e- - ETA: 33s - loss: 3.9902e- - ETA: 33s - loss: 3.9034e- - ETA: 33s - loss: 3.8204e- - ETA: 32s - loss: 3.7408e- - ETA: 32s - loss: 3.6644e- - ETA: 31s - loss: 3.5911e- - ETA: 31s - loss: 3.5207e- - ETA: 31s - loss: 3.4530e- - ETA: 31s - loss: 3.3879e- - ETA: 30s - loss: 3.3251e- - ETA: 30s - loss: 3.2647e- - ETA: 29s - loss: 3.3637e- - ETA: 29s - loss: 3.3047e- - ETA: 29s - loss: 3.6321e- - ETA: 28s - loss: 3.5705e- - ETA: 28s - loss: 3.5110e- - ETA: 27s - loss: 3.5890e- - ETA: 27s - loss: 3.5311e- - ETA: 26s - loss: 3.4751e- - ETA: 26s - loss: 3.4208e- - ETA: 26s - loss: 3.7551e- - ETA: 25s - loss: 3.6982e- - ETA: 25s - loss: 3.8291e- - ETA: 24s - loss: 3.8788e- - ETA: 24s - loss: 4.0959e- - ETA: 23s - loss: 4.0374e- - ETA: 23s - loss: 3.9805e- - ETA: 23s - loss: 4.5159e- - ETA: 22s - loss: 4.5408e- - ETA: 22s - loss: 4.4795e- - ETA: 21s - loss: 4.4198e- - ETA: 21s - loss: 4.3616e- - ETA: 20s - loss: 4.3050e- - ETA: 20s - loss: 4.3457e- - ETA: 20s - loss: 4.2907e- - ETA: 19s - loss: 4.3085e- - ETA: 19s - loss: 4.2553e- - ETA: 19s - loss: 4.2034e- - ETA: 18s - loss: 4.1527e- - ETA: 18s - loss: 4.1033e- - ETA: 17s - loss: 4.0550e- - ETA: 17s - loss: 4.0079e- - ETA: 16s - loss: 4.1922e- - ETA: 16s - loss: 4.1446e- - ETA: 16s - loss: 4.0980e- - ETA: 15s - loss: 4.0525e- - ETA: 15s - loss: 4.3959e- - ETA: 14s - loss: 4.3481e- - ETA: 14s - loss: 4.4380e- - ETA: 13s - loss: 4.6323e- - ETA: 13s - loss: 4.7985e- - ETA: 12s - loss: 4.7485e- - ETA: 12s - loss: 4.6996e- - ETA: 12s - loss: 4.7578e- - ETA: 11s - loss: 4.7098e- - ETA: 11s - loss: 4.8913e- - ETA: 10s - loss: 4.8429e- - ETA: 10s - loss: 4.7954e- - ETA: 9s - loss: 4.7489e-04 - ETA: 9s - loss: 4.7032e-0 - ETA: 8s - loss: 4.9362e-0 - ETA: 8s - loss: 5.1228e-0 - ETA: 8s - loss: 5.2432e-0 - ETA: 7s - loss: 5.3987e-0 - ETA: 7s - loss: 5.3492e-0 - ETA: 6s - loss: 5.3005e-0 - ETA: 6s - loss: 5.3750e-0 - ETA: 5s - loss: 5.4582e-0 - ETA: 5s - loss: 5.5166e-0 - ETA: 4s - loss: 5.4682e-0 - ETA: 4s - loss: 5.4207e-0 - ETA: 4s - loss: 5.3739e-0 - ETA: 3s - loss: 5.3280e-0 - ETA: 3s - loss: 5.2828e-0 - ETA: 2s - loss: 5.2385e-0 - ETA: 2s - loss: 5.1948e-0 - ETA: 1s - loss: 5.1519e-0 - ETA: 1s - loss: 5.2255e-0 - ETA: 0s - loss: 5.1830e-0 - ETA: 0s - loss: 5.1412e-0 - 61s 8ms/sample - loss: 5.1001e-04 - val_loss: 0.0000e+00\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - ETA: 57s - loss: 6.0442e- - ETA: 55s - loss: 3.0221e- - ETA: 53s - loss: 4.6890e- - ETA: 52s - loss: 3.5167e- - ETA: 51s - loss: 2.8134e- - ETA: 50s - loss: 2.3445e- - ETA: 50s - loss: 2.0096e- - ETA: 50s - loss: 1.7584e- - ETA: 49s - loss: 1.5630e- - ETA: 49s - loss: 1.4067e- - ETA: 48s - loss: 1.2788e- - ETA: 47s - loss: 1.1722e- - ETA: 53s - loss: 1.0821e- - ETA: 53s - loss: 1.0048e- - ETA: 52s - loss: 1.5438e- - ETA: 51s - loss: 1.4473e- - ETA: 50s - loss: 1.4712e- - ETA: 53s - loss: 1.7706e- - ETA: 52s - loss: 1.6774e- - ETA: 52s - loss: 1.5935e- - ETA: 52s - loss: 1.5177e- - ETA: 51s - loss: 1.4487e- - ETA: 50s - loss: 1.3857e- - ETA: 50s - loss: 1.9151e- - ETA: 49s - loss: 2.1292e- - ETA: 48s - loss: 2.0473e- - ETA: 48s - loss: 1.9715e- - ETA: 47s - loss: 3.5003e- - ETA: 46s - loss: 3.3796e- - ETA: 45s - loss: 3.2670e- - ETA: 45s - loss: 3.1616e- - ETA: 44s - loss: 3.2436e- - ETA: 44s - loss: 3.5927e- - ETA: 43s - loss: 4.2172e- - ETA: 42s - loss: 4.0967e- - ETA: 42s - loss: 3.9829e- - ETA: 41s - loss: 3.8752e- - ETA: 41s - loss: 3.7733e- - ETA: 40s - loss: 3.6765e- - ETA: 39s - loss: 4.3333e- - ETA: 39s - loss: 4.2276e- - ETA: 38s - loss: 4.1269e- - ETA: 38s - loss: 4.0310e- - ETA: 37s - loss: 3.9394e- - ETA: 37s - loss: 3.8518e- - ETA: 37s - loss: 4.1197e- - ETA: 36s - loss: 4.0320e- - ETA: 36s - loss: 3.9480e- - ETA: 36s - loss: 3.8674e- - ETA: 35s - loss: 3.7901e- - ETA: 35s - loss: 3.7889e- - ETA: 34s - loss: 4.0855e- - ETA: 34s - loss: 4.0084e- - ETA: 33s - loss: 3.9342e- - ETA: 33s - loss: 3.8627e- - ETA: 32s - loss: 3.7937e- - ETA: 32s - loss: 3.7272e- - ETA: 32s - loss: 3.6629e- - ETA: 31s - loss: 3.6008e- - ETA: 31s - loss: 3.5408e- - ETA: 30s - loss: 3.5712e- - ETA: 30s - loss: 3.7125e- - ETA: 29s - loss: 4.1733e- - ETA: 29s - loss: 4.1080e- - ETA: 28s - loss: 4.3590e- - ETA: 28s - loss: 4.2929e- - ETA: 27s - loss: 4.2288e- - ETA: 27s - loss: 4.1666e- - ETA: 26s - loss: 4.1063e- - ETA: 26s - loss: 4.0476e- - ETA: 25s - loss: 3.9906e- - ETA: 25s - loss: 3.9352e- - ETA: 25s - loss: 3.8813e- - ETA: 24s - loss: 3.8288e- - ETA: 24s - loss: 3.9956e- - ETA: 23s - loss: 3.9430e- - ETA: 23s - loss: 3.8918e- - ETA: 22s - loss: 3.8419e- - ETA: 22s - loss: 3.7933e- - ETA: 21s - loss: 3.7458e- - ETA: 21s - loss: 3.6996e- - ETA: 20s - loss: 3.6545e- - ETA: 20s - loss: 4.1701e- - ETA: 19s - loss: 4.1204e- - ETA: 19s - loss: 4.0719e- - ETA: 18s - loss: 4.1334e- - ETA: 18s - loss: 4.0859e- - ETA: 17s - loss: 4.1223e- - ETA: 17s - loss: 4.0760e- - ETA: 17s - loss: 4.2519e- - ETA: 16s - loss: 4.4782e- - ETA: 16s - loss: 4.4296e- - ETA: 15s - loss: 4.5950e- - ETA: 15s - loss: 4.7866e- - ETA: 14s - loss: 4.7362e- - ETA: 14s - loss: 4.7658e- - ETA: 13s - loss: 4.7167e- - ETA: 13s - loss: 4.6686e- - ETA: 12s - loss: 4.7948e- - ETA: 12s - loss: 4.7469e- - ETA: 11s - loss: 4.6999e- - ETA: 11s - loss: 4.7041e- - ETA: 10s - loss: 4.6585e- - ETA: 10s - loss: 4.9046e- - ETA: 9s - loss: 4.9809e-04 - ETA: 9s - loss: 4.9339e-0 - ETA: 8s - loss: 4.8878e-0 - ETA: 8s - loss: 4.8425e-0 - ETA: 7s - loss: 4.7981e-0 - ETA: 7s - loss: 4.8635e-0 - ETA: 6s - loss: 4.8197e-0 - ETA: 6s - loss: 4.7767e-0 - ETA: 5s - loss: 4.7344e-0 - ETA: 5s - loss: 4.6929e-0 - ETA: 4s - loss: 4.6521e-0 - ETA: 4s - loss: 4.7462e-0 - ETA: 3s - loss: 4.9226e-0 - ETA: 3s - loss: 4.8808e-0 - ETA: 2s - loss: 4.8398e-0 - ETA: 2s - loss: 4.7995e-0 - ETA: 1s - loss: 4.8291e-0 - ETA: 1s - loss: 4.7895e-0 - ETA: 0s - loss: 4.7506e-0 - ETA: 0s - loss: 4.7123e-0 - 63s 8ms/sample - loss: 4.6746e-04 - val_loss: 0.0000e+00\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - ETA: 48s - loss: 0.0000e+ - ETA: 54s - loss: 0.0000e+ - ETA: 54s - loss: 4.6308e- - ETA: 52s - loss: 3.4731e- - ETA: 50s - loss: 2.7785e- - ETA: 49s - loss: 3.7739e- - ETA: 48s - loss: 3.2348e- - ETA: 48s - loss: 2.8304e- - ETA: 47s - loss: 2.5160e- - ETA: 47s - loss: 2.2644e- - ETA: 46s - loss: 2.0585e- - ETA: 45s - loss: 1.8870e- - ETA: 45s - loss: 1.7418e- - ETA: 44s - loss: 1.6174e- - ETA: 44s - loss: 1.5096e- - ETA: 44s - loss: 2.0083e- - ETA: 43s - loss: 1.8901e- - ETA: 44s - loss: 2.3106e- - ETA: 44s - loss: 2.7443e- - ETA: 44s - loss: 3.1961e- - ETA: 44s - loss: 3.6756e- - ETA: 43s - loss: 4.3864e- - ETA: 42s - loss: 4.1957e- - ETA: 42s - loss: 4.0209e- - ETA: 41s - loss: 4.2837e- - ETA: 41s - loss: 4.1189e- - ETA: 40s - loss: 3.9664e- - ETA: 40s - loss: 4.3500e- - ETA: 39s - loss: 4.2000e- - ETA: 39s - loss: 4.0600e- - ETA: 38s - loss: 3.9290e- - ETA: 37s - loss: 3.9505e- - ETA: 37s - loss: 3.8924e- - ETA: 37s - loss: 4.7426e- - ETA: 36s - loss: 4.7361e- - ETA: 36s - loss: 4.6045e- - ETA: 35s - loss: 5.2323e- - ETA: 35s - loss: 5.0946e- - ETA: 34s - loss: 4.9640e- - ETA: 34s - loss: 4.8399e- - ETA: 33s - loss: 4.7218e- - ETA: 33s - loss: 4.6094e- - ETA: 32s - loss: 4.5022e- - ETA: 32s - loss: 4.3999e- - ETA: 31s - loss: 4.3021e- - ETA: 31s - loss: 4.4401e- - ETA: 31s - loss: 4.3456e- - ETA: 30s - loss: 4.4674e- - ETA: 30s - loss: 4.3762e- - ETA: 29s - loss: 4.2887e- - ETA: 29s - loss: 4.2046e- - ETA: 29s - loss: 4.2343e- - ETA: 28s - loss: 4.1544e- - ETA: 28s - loss: 4.0775e- - ETA: 27s - loss: 4.0033e- - ETA: 27s - loss: 3.9318e- - ETA: 26s - loss: 3.8629e- - ETA: 26s - loss: 3.7963e- - ETA: 25s - loss: 3.7319e- - ETA: 25s - loss: 4.1758e- - ETA: 25s - loss: 4.1073e- - ETA: 24s - loss: 4.2212e- - ETA: 24s - loss: 4.1542e- - ETA: 23s - loss: 4.0893e- - ETA: 23s - loss: 4.0264e- - ETA: 22s - loss: 4.0043e- - ETA: 22s - loss: 4.0834e- - ETA: 22s - loss: 4.0234e- - ETA: 21s - loss: 3.9651e- - ETA: 21s - loss: 4.0234e- - ETA: 20s - loss: 4.2474e- - ETA: 20s - loss: 4.4106e- - ETA: 20s - loss: 4.3502e- - ETA: 19s - loss: 4.4531e- - ETA: 19s - loss: 4.8013e- - ETA: 18s - loss: 4.7381e- - ETA: 18s - loss: 4.6766e- - ETA: 18s - loss: 4.6166e- - ETA: 17s - loss: 4.5582e- - ETA: 17s - loss: 4.5839e- - ETA: 16s - loss: 4.5273e- - ETA: 16s - loss: 4.6205e- - ETA: 16s - loss: 4.5648e- - ETA: 15s - loss: 4.5105e- - ETA: 15s - loss: 4.4574e- - ETA: 14s - loss: 4.4056e- - ETA: 14s - loss: 4.4573e- - ETA: 14s - loss: 4.4067e- - ETA: 13s - loss: 4.3571e- - ETA: 13s - loss: 4.3087e- - ETA: 12s - loss: 4.2614e- - ETA: 12s - loss: 4.4106e- - ETA: 12s - loss: 4.3632e- - ETA: 11s - loss: 4.3168e- - ETA: 11s - loss: 4.3653e- - ETA: 11s - loss: 4.3198e- - ETA: 10s - loss: 4.2753e- - ETA: 10s - loss: 4.2317e- - ETA: 9s - loss: 4.1889e-04 - ETA: 9s - loss: 4.2999e-0 - ETA: 9s - loss: 4.2573e-0 - ETA: 8s - loss: 4.3625e-0 - ETA: 8s - loss: 4.3201e-0 - ETA: 7s - loss: 4.2786e-0 - ETA: 7s - loss: 4.2378e-0 - ETA: 7s - loss: 4.5399e-0 - ETA: 6s - loss: 4.4975e-0 - ETA: 6s - loss: 4.4559e-0 - ETA: 6s - loss: 4.4150e-0 - ETA: 5s - loss: 4.3749e-0 - ETA: 5s - loss: 4.3354e-0 - ETA: 4s - loss: 4.6550e-0 - ETA: 4s - loss: 4.6138e-0 - ETA: 4s - loss: 4.7284e-0 - ETA: 3s - loss: 4.8375e-0 - ETA: 3s - loss: 4.7958e-0 - ETA: 3s - loss: 4.7548e-0 - ETA: 2s - loss: 4.8683e-0 - ETA: 2s - loss: 4.8273e-0 - ETA: 1s - loss: 4.7871e-0 - ETA: 1s - loss: 4.7475e-0 - ETA: 1s - loss: 4.7086e-0 - ETA: 0s - loss: 4.9335e-0 - ETA: 0s - loss: 4.8937e-0 - 50s 6ms/sample - loss: 4.8545e-04 - val_loss: 0.0000e+00\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - ETA: 48s - loss: 0.00 - ETA: 47s - loss: 6.8418e- - ETA: 47s - loss: 4.5612e- - ETA: 46s - loss: 3.4209e- - ETA: 45s - loss: 2.7367e- - ETA: 45s - loss: 2.8585e- - ETA: 45s - loss: 2.4502e- - ETA: 45s - loss: 2.1439e- - ETA: 45s - loss: 1.9057e- - ETA: 44s - loss: 1.7151e- - ETA: 43s - loss: 1.5592e- - ETA: 42s - loss: 1.4293e- - ETA: 42s - loss: 1.3193e- - ETA: 42s - loss: 1.6652e- - ETA: 41s - loss: 1.5542e- - ETA: 41s - loss: 1.4570e- - ETA: 40s - loss: 2.8535e- - ETA: 40s - loss: 3.2794e- - ETA: 39s - loss: 3.1068e- - ETA: 39s - loss: 3.3927e- - ETA: 39s - loss: 3.2311e- - ETA: 38s - loss: 3.0843e- - ETA: 38s - loss: 3.9493e- - ETA: 38s - loss: 4.7377e- - ETA: 37s - loss: 4.5482e- - ETA: 37s - loss: 5.1414e- - ETA: 36s - loss: 4.9510e- - ETA: 36s - loss: 4.7742e- - ETA: 35s - loss: 4.7474e- - ETA: 35s - loss: 4.5892e- - ETA: 35s - loss: 4.4412e- - ETA: 34s - loss: 4.3024e- - ETA: 34s - loss: 4.1720e- - ETA: 33s - loss: 4.0493e- - ETA: 33s - loss: 4.1261e- - ETA: 32s - loss: 4.1484e- - ETA: 32s - loss: 4.0363e- - ETA: 32s - loss: 3.9301e- - ETA: 31s - loss: 3.8293e- - ETA: 31s - loss: 3.7336e- - ETA: 31s - loss: 3.6425e- - ETA: 30s - loss: 3.5558e- - ETA: 30s - loss: 3.4731e- - ETA: 29s - loss: 3.3941e- - ETA: 29s - loss: 3.3187e- - ETA: 29s - loss: 3.5515e- - ETA: 28s - loss: 3.7752e- - ETA: 28s - loss: 3.6965e- - ETA: 27s - loss: 3.7875e- - ETA: 27s - loss: 3.7118e- - ETA: 27s - loss: 3.6390e- - ETA: 26s - loss: 3.5690e- - ETA: 26s - loss: 3.7702e- - ETA: 25s - loss: 3.9203e- - ETA: 25s - loss: 3.8490e- - ETA: 25s - loss: 3.9993e- - ETA: 24s - loss: 3.9292e- - ETA: 24s - loss: 3.8614e- - ETA: 24s - loss: 3.9713e- - ETA: 23s - loss: 4.2390e- - ETA: 23s - loss: 4.1695e- - ETA: 23s - loss: 4.1023e- - ETA: 22s - loss: 4.0372e- - ETA: 22s - loss: 3.9741e- - ETA: 21s - loss: 3.9129e- - ETA: 21s - loss: 3.8536e- - ETA: 21s - loss: 4.0472e- - ETA: 20s - loss: 3.9877e- - ETA: 20s - loss: 3.9299e- - ETA: 20s - loss: 3.8737e- - ETA: 19s - loss: 3.8192e- - ETA: 19s - loss: 3.7661e- - ETA: 18s - loss: 3.8886e- - ETA: 18s - loss: 3.8361e- - ETA: 18s - loss: 3.7850e- - ETA: 17s - loss: 3.8533e- - ETA: 17s - loss: 3.8033e- - ETA: 17s - loss: 3.7545e- - ETA: 16s - loss: 3.7070e- - ETA: 16s - loss: 3.6607e- - ETA: 16s - loss: 3.6155e- - ETA: 15s - loss: 3.6147e- - ETA: 15s - loss: 3.5712e- - ETA: 14s - loss: 3.7983e- - ETA: 14s - loss: 3.7536e- - ETA: 14s - loss: 3.7100e- - ETA: 13s - loss: 3.7276e- - ETA: 13s - loss: 3.6852e- - ETA: 13s - loss: 4.0361e- - ETA: 12s - loss: 4.0706e- - ETA: 12s - loss: 4.0259e- - ETA: 12s - loss: 4.2141e- - ETA: 11s - loss: 4.1688e- - ETA: 11s - loss: 4.3936e- - ETA: 10s - loss: 4.3474e- - ETA: 10s - loss: 4.3021e- - ETA: 10s - loss: 4.2577e- - ETA: 9s - loss: 4.4845e-04 - ETA: 9s - loss: 4.4392e-0 - ETA: 9s - loss: 4.6385e-0 - ETA: 8s - loss: 4.6745e-0 - ETA: 8s - loss: 4.6287e-0 - ETA: 8s - loss: 4.5838e-0 - ETA: 7s - loss: 4.6377e-0 - ETA: 7s - loss: 4.5935e-0 - ETA: 6s - loss: 4.5502e-0 - ETA: 6s - loss: 4.6148e-0 - ETA: 6s - loss: 4.8207e-0 - ETA: 5s - loss: 4.7765e-0 - ETA: 5s - loss: 4.7330e-0 - ETA: 5s - loss: 4.7965e-0 - ETA: 4s - loss: 4.7537e-0 - ETA: 4s - loss: 4.7116e-0 - ETA: 4s - loss: 4.6703e-0 - ETA: 3s - loss: 4.6297e-0 - ETA: 3s - loss: 4.7194e-0 - ETA: 2s - loss: 4.6790e-0 - ETA: 2s - loss: 4.6394e-0 - ETA: 2s - loss: 4.6004e-0 - ETA: 1s - loss: 4.5621e-0 - ETA: 1s - loss: 4.5244e-0 - ETA: 1s - loss: 4.4873e-0 - ETA: 0s - loss: 4.4508e-0 - ETA: 0s - loss: 4.5384e-0 - 50s 6ms/sample - loss: 4.5021e-04 - val_loss: 0.0000e+00\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - ETA: 47s - loss: 0.0000e+ - ETA: 46s - loss: 0.0000e+ - ETA: 46s - loss: 1.0245e- - ETA: 45s - loss: 7.6840e- - ETA: 45s - loss: 6.1472e- - ETA: 44s - loss: 5.1227e- - ETA: 44s - loss: 4.3909e- - ETA: 44s - loss: 3.8420e- - ETA: 43s - loss: 3.4151e- - ETA: 43s - loss: 1.4864e- - ETA: 42s - loss: 1.9729e- - ETA: 42s - loss: 3.0280e- - ETA: 42s - loss: 3.3374e- - ETA: 41s - loss: 3.0991e- - ETA: 41s - loss: 3.0649e- - ETA: 41s - loss: 4.0148e- - ETA: 41s - loss: 3.7787e- - ETA: 40s - loss: 3.5687e- - ETA: 40s - loss: 3.3809e- - ETA: 39s - loss: 4.3457e- - ETA: 39s - loss: 4.3405e- - ETA: 39s - loss: 4.4842e- - ETA: 38s - loss: 4.2893e- - ETA: 38s - loss: 4.4277e- - ETA: 37s - loss: 4.2506e- - ETA: 37s - loss: 4.3831e- - ETA: 37s - loss: 5.3164e- - ETA: 36s - loss: 5.1266e- - ETA: 36s - loss: 5.2862e- - ETA: 35s - loss: 5.1100e- - ETA: 35s - loss: 5.2698e- - ETA: 35s - loss: 5.1051e- - ETA: 35s - loss: 4.9504e- - ETA: 34s - loss: 4.8048e- - ETA: 34s - loss: 4.6675e- - ETA: 34s - loss: 4.8157e- - ETA: 34s - loss: 4.6855e- - ETA: 33s - loss: 4.5622e- - ETA: 33s - loss: 4.4452e- - ETA: 33s - loss: 4.9490e- - ETA: 33s - loss: 4.8283e- - ETA: 33s - loss: 4.7133e- - ETA: 32s - loss: 4.8296e- - ETA: 32s - loss: 4.7198e- - ETA: 32s - loss: 5.0472e- - ETA: 31s - loss: 4.9375e- - ETA: 31s - loss: 4.8324e- - ETA: 31s - loss: 4.7318e- - ETA: 31s - loss: 4.6352e- - ETA: 31s - loss: 4.5425e- - ETA: 30s - loss: 4.6574e- - ETA: 30s - loss: 4.5679e- - ETA: 29s - loss: 4.4817e- - ETA: 29s - loss: 4.3987e- - ETA: 28s - loss: 4.5037e- - ETA: 28s - loss: 4.7231e- - ETA: 28s - loss: 4.8656e- - ETA: 27s - loss: 4.8398e- - ETA: 27s - loss: 4.8730e- - ETA: 26s - loss: 4.7918e- - ETA: 26s - loss: 4.7132e- - ETA: 26s - loss: 4.6372e- - ETA: 25s - loss: 4.5636e- - ETA: 25s - loss: 4.8369e- - ETA: 24s - loss: 4.7625e- - ETA: 24s - loss: 5.0491e- - ETA: 23s - loss: 5.1877e- - ETA: 23s - loss: 5.1114e- - ETA: 23s - loss: 5.0373e- - ETA: 22s - loss: 4.9654e- - ETA: 22s - loss: 5.0155e- - ETA: 21s - loss: 4.9459e- - ETA: 21s - loss: 5.1386e- - ETA: 20s - loss: 5.0691e- - ETA: 20s - loss: 5.0015e- - ETA: 20s - loss: 4.9357e- - ETA: 19s - loss: 4.8716e- - ETA: 19s - loss: 4.8092e- - ETA: 18s - loss: 4.7483e- - ETA: 18s - loss: 4.8244e- - ETA: 17s - loss: 4.7649e- - ETA: 17s - loss: 4.7068e- - ETA: 17s - loss: 4.6501e- - ETA: 16s - loss: 4.5947e- - ETA: 16s - loss: 4.5406e- - ETA: 15s - loss: 4.4878e- - ETA: 15s - loss: 4.6428e- - ETA: 14s - loss: 4.5900e- - ETA: 14s - loss: 4.5384e- - ETA: 14s - loss: 4.4880e- - ETA: 13s - loss: 4.4387e- - ETA: 13s - loss: 4.6167e- - ETA: 12s - loss: 4.5670e- - ETA: 12s - loss: 4.5184e- - ETA: 11s - loss: 4.4709e- - ETA: 11s - loss: 4.4243e- - ETA: 11s - loss: 4.3787e- - ETA: 10s - loss: 4.3340e- - ETA: 10s - loss: 4.2902e- - ETA: 9s - loss: 4.2473e-04 - ETA: 9s - loss: 4.2368e-0 - ETA: 9s - loss: 4.2389e-0 - ETA: 8s - loss: 4.1977e-0 - ETA: 8s - loss: 4.2062e-0 - ETA: 7s - loss: 4.2933e-0 - ETA: 7s - loss: 4.2528e-0 - ETA: 7s - loss: 4.2131e-0 - ETA: 6s - loss: 4.1741e-0 - ETA: 6s - loss: 4.2428e-0 - ETA: 5s - loss: 4.2394e-0 - ETA: 5s - loss: 4.3230e-0 - ETA: 5s - loss: 4.2844e-0 - ETA: 4s - loss: 4.2464e-0 - ETA: 4s - loss: 4.2504e-0 - ETA: 3s - loss: 4.2135e-0 - ETA: 3s - loss: 4.1771e-0 - ETA: 3s - loss: 4.1414e-0 - ETA: 2s - loss: 4.1063e-0 - ETA: 2s - loss: 4.0718e-0 - ETA: 1s - loss: 4.1105e-0 - ETA: 1s - loss: 4.4907e-0 - ETA: 1s - loss: 4.4539e-0 - ETA: 0s - loss: 4.4177e-0 - ETA: 0s - loss: 4.3820e-0 - 52s 7ms/sample - loss: 4.3470e-04 - val_loss: 0.0000e+00\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - ETA: 44s - loss: 0.0000e+ - ETA: 44s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 42s - loss: 1.4777e- - ETA: 41s - loss: 2.4705e- - ETA: 41s - loss: 2.1617e- - ETA: 41s - loss: 1.9215e- - ETA: 40s - loss: 2.7640e- - ETA: 40s - loss: 3.0527e- - ETA: 40s - loss: 2.7983e- - ETA: 39s - loss: 3.1534e- - ETA: 39s - loss: 2.9282e- - ETA: 38s - loss: 2.7329e- - ETA: 38s - loss: 3.4822e- - ETA: 38s - loss: 3.2774e- - ETA: 37s - loss: 3.2643e- - ETA: 37s - loss: 3.0925e- - ETA: 37s - loss: 2.9379e- - ETA: 36s - loss: 2.7980e- - ETA: 36s - loss: 2.6708e- - ETA: 36s - loss: 3.0431e- - ETA: 35s - loss: 2.9163e- - ETA: 35s - loss: 3.0706e- - ETA: 35s - loss: 2.9525e- - ETA: 34s - loss: 2.8431e- - ETA: 34s - loss: 3.5747e- - ETA: 34s - loss: 4.1461e- - ETA: 33s - loss: 4.5416e- - ETA: 33s - loss: 4.7155e- - ETA: 33s - loss: 4.5682e- - ETA: 32s - loss: 4.7700e- - ETA: 32s - loss: 4.6297e- - ETA: 31s - loss: 4.4974e- - ETA: 31s - loss: 4.8215e- - ETA: 31s - loss: 4.6911e- - ETA: 31s - loss: 4.8857e- - ETA: 30s - loss: 4.8952e- - ETA: 30s - loss: 5.0016e- - ETA: 30s - loss: 5.0058e- - ETA: 29s - loss: 4.8866e- - ETA: 29s - loss: 4.7730e- - ETA: 29s - loss: 4.6645e- - ETA: 28s - loss: 4.5608e- - ETA: 28s - loss: 4.4617e- - ETA: 28s - loss: 4.5852e- - ETA: 27s - loss: 4.5917e- - ETA: 27s - loss: 4.4980e- - ETA: 27s - loss: 4.7307e- - ETA: 26s - loss: 4.6379e- - ETA: 26s - loss: 4.5487e- - ETA: 26s - loss: 4.4629e- - ETA: 26s - loss: 4.3803e- - ETA: 25s - loss: 4.3633e- - ETA: 25s - loss: 4.5604e- - ETA: 25s - loss: 4.6869e- - ETA: 25s - loss: 4.8428e- - ETA: 24s - loss: 4.7607e- - ETA: 24s - loss: 4.6814e- - ETA: 24s - loss: 4.7045e- - ETA: 23s - loss: 4.6287e- - ETA: 23s - loss: 4.5552e- - ETA: 23s - loss: 4.4840e- - ETA: 22s - loss: 4.7436e- - ETA: 22s - loss: 4.6717e- - ETA: 21s - loss: 4.9272e- - ETA: 21s - loss: 4.8548e- - ETA: 21s - loss: 4.7844e- - ETA: 20s - loss: 4.9281e- - ETA: 20s - loss: 4.8587e- - ETA: 20s - loss: 5.2089e- - ETA: 19s - loss: 5.3137e- - ETA: 19s - loss: 5.2419e- - ETA: 18s - loss: 5.3593e- - ETA: 18s - loss: 5.3921e- - ETA: 18s - loss: 5.3221e- - ETA: 17s - loss: 5.3611e- - ETA: 17s - loss: 5.2932e- - ETA: 17s - loss: 5.2271e- - ETA: 16s - loss: 5.1625e- - ETA: 16s - loss: 5.0996e- - ETA: 16s - loss: 5.0381e- - ETA: 15s - loss: 4.9782e- - ETA: 15s - loss: 4.9196e- - ETA: 14s - loss: 4.8624e- - ETA: 14s - loss: 4.9594e- - ETA: 14s - loss: 4.9031e- - ETA: 13s - loss: 4.8480e- - ETA: 13s - loss: 4.7941e- - ETA: 12s - loss: 4.7414e- - ETA: 12s - loss: 4.6899e- - ETA: 12s - loss: 4.6395e- - ETA: 11s - loss: 4.5901e- - ETA: 11s - loss: 4.5418e- - ETA: 10s - loss: 4.6243e- - ETA: 10s - loss: 4.5766e- - ETA: 10s - loss: 4.5299e- - ETA: 9s - loss: 4.4841e-04 - ETA: 9s - loss: 4.4393e-0 - ETA: 9s - loss: 4.3953e-0 - ETA: 8s - loss: 4.3522e-0 - ETA: 8s - loss: 4.3100e-0 - ETA: 7s - loss: 4.2685e-0 - ETA: 7s - loss: 4.2279e-0 - ETA: 7s - loss: 4.1880e-0 - ETA: 6s - loss: 4.1489e-0 - ETA: 6s - loss: 4.2599e-0 - ETA: 6s - loss: 4.2208e-0 - ETA: 5s - loss: 4.2275e-0 - ETA: 5s - loss: 4.2172e-0 - ETA: 4s - loss: 4.1795e-0 - ETA: 4s - loss: 4.1425e-0 - ETA: 4s - loss: 4.1062e-0 - ETA: 3s - loss: 4.1713e-0 - ETA: 3s - loss: 4.1354e-0 - ETA: 2s - loss: 4.1000e-0 - ETA: 2s - loss: 4.0653e-0 - ETA: 2s - loss: 4.0311e-0 - ETA: 1s - loss: 3.9975e-0 - ETA: 1s - loss: 3.9645e-0 - ETA: 1s - loss: 4.0427e-0 - ETA: 0s - loss: 4.0098e-0 - ETA: 0s - loss: 3.9775e-0 - 50s 6ms/sample - loss: 3.9857e-04 - val_loss: 0.0000e+00\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - ETA: 44s - loss: 0.0000e+ - ETA: 41s - loss: 2.3221e- - ETA: 41s - loss: 1.5481e- - ETA: 41s - loss: 2.8361e- - ETA: 41s - loss: 4.4310e- - ETA: 41s - loss: 3.6925e- - ETA: 41s - loss: 3.1650e- - ETA: 41s - loss: 2.7694e- - ETA: 40s - loss: 2.4617e- - ETA: 40s - loss: 2.5073e- - ETA: 40s - loss: 2.2793e- - ETA: 40s - loss: 2.0894e- - ETA: 40s - loss: 1.9287e- - ETA: 40s - loss: 2.6777e- - ETA: 40s - loss: 2.4992e- - ETA: 39s - loss: 2.9040e- - ETA: 39s - loss: 3.1385e- - ETA: 39s - loss: 2.9641e- - ETA: 38s - loss: 2.8081e- - ETA: 38s - loss: 2.6677e- - ETA: 38s - loss: 3.3028e- - ETA: 37s - loss: 3.1527e- - ETA: 37s - loss: 3.3828e- - ETA: 37s - loss: 3.2419e- - ETA: 36s - loss: 3.1122e- - ETA: 36s - loss: 2.9925e- - ETA: 36s - loss: 2.8817e- - ETA: 35s - loss: 2.7788e- - ETA: 35s - loss: 3.8775e- - ETA: 35s - loss: 3.7482e- - ETA: 34s - loss: 3.6273e- - ETA: 34s - loss: 3.9972e- - ETA: 33s - loss: 3.8760e- - ETA: 33s - loss: 3.9793e- - ETA: 33s - loss: 3.8656e- - ETA: 32s - loss: 3.7583e- - ETA: 32s - loss: 3.6567e- - ETA: 31s - loss: 3.6127e- - ETA: 31s - loss: 3.7404e- - ETA: 31s - loss: 4.0415e- - ETA: 30s - loss: 4.1030e- - ETA: 30s - loss: 4.2164e- - ETA: 29s - loss: 4.4071e- - ETA: 29s - loss: 4.3069e- - ETA: 29s - loss: 4.2112e- - ETA: 28s - loss: 4.1197e- - ETA: 28s - loss: 4.0320e- - ETA: 28s - loss: 3.9480e- - ETA: 28s - loss: 3.8674e- - ETA: 27s - loss: 3.7901e- - ETA: 27s - loss: 3.7158e- - ETA: 27s - loss: 3.6443e- - ETA: 26s - loss: 3.5755e- - ETA: 26s - loss: 3.5093e- - ETA: 26s - loss: 3.4455e- - ETA: 25s - loss: 3.3840e- - ETA: 25s - loss: 3.4330e- - ETA: 24s - loss: 3.5137e- - ETA: 24s - loss: 3.4541e- - ETA: 24s - loss: 3.3965e- - ETA: 23s - loss: 3.6183e- - ETA: 23s - loss: 3.5599e- - ETA: 22s - loss: 3.6590e- - ETA: 22s - loss: 3.6797e- - ETA: 22s - loss: 3.7229e- - ETA: 21s - loss: 3.6665e- - ETA: 21s - loss: 3.6117e- - ETA: 21s - loss: 3.7031e- - ETA: 20s - loss: 3.7794e- - ETA: 20s - loss: 3.7254e- - ETA: 19s - loss: 3.8835e- - ETA: 19s - loss: 3.8296e- - ETA: 19s - loss: 3.7771e- - ETA: 18s - loss: 3.7261e- - ETA: 18s - loss: 3.8541e- - ETA: 17s - loss: 3.8034e- - ETA: 17s - loss: 3.7540e- - ETA: 17s - loss: 3.7058e- - ETA: 16s - loss: 3.6589e- - ETA: 16s - loss: 3.6132e- - ETA: 16s - loss: 3.5686e- - ETA: 15s - loss: 3.6329e- - ETA: 15s - loss: 3.5891e- - ETA: 14s - loss: 3.5464e- - ETA: 14s - loss: 3.6891e- - ETA: 14s - loss: 3.6462e- - ETA: 13s - loss: 3.6043e- - ETA: 13s - loss: 3.5634e- - ETA: 13s - loss: 3.5233e- - ETA: 12s - loss: 3.4842e- - ETA: 12s - loss: 3.4459e- - ETA: 12s - loss: 3.5421e- - ETA: 11s - loss: 3.5040e- - ETA: 11s - loss: 3.4667e- - ETA: 10s - loss: 3.4302e- - ETA: 10s - loss: 3.3945e- - ETA: 10s - loss: 3.3595e- - ETA: 9s - loss: 3.3252e-04 - ETA: 9s - loss: 3.3265e-0 - ETA: 9s - loss: 3.2932e-0 - ETA: 8s - loss: 3.2606e-0 - ETA: 8s - loss: 3.2286e-0 - ETA: 7s - loss: 3.3707e-0 - ETA: 7s - loss: 3.4705e-0 - ETA: 7s - loss: 3.6275e-0 - ETA: 6s - loss: 3.7669e-0 - ETA: 6s - loss: 3.8799e-0 - ETA: 6s - loss: 4.0020e-0 - ETA: 5s - loss: 3.9653e-0 - ETA: 5s - loss: 3.9293e-0 - ETA: 5s - loss: 3.9163e-0 - ETA: 4s - loss: 3.9851e-0 - ETA: 4s - loss: 3.9498e-0 - ETA: 3s - loss: 4.0111e-0 - ETA: 3s - loss: 3.9762e-0 - ETA: 3s - loss: 3.9420e-0 - ETA: 2s - loss: 3.9606e-0 - ETA: 2s - loss: 3.9270e-0 - ETA: 2s - loss: 3.8940e-0 - ETA: 1s - loss: 3.8616e-0 - ETA: 1s - loss: 3.8297e-0 - ETA: 1s - loss: 4.0601e-0 - ETA: 0s - loss: 4.0271e-0 - ETA: 0s - loss: 4.0829e-0 - 48s 6ms/sample - loss: 4.0503e-04 - val_loss: 0.0000e+00\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - ETA: 41s - loss: 0.0000e+ - ETA: 42s - loss: 2.6846e- - ETA: 42s - loss: 1.7897e- - ETA: 42s - loss: 1.3423e- - ETA: 41s - loss: 1.0738e- - ETA: 40s - loss: 8.9487e- - ETA: 40s - loss: 2.5556e- - ETA: 40s - loss: 2.2362e- - ETA: 39s - loss: 1.9877e- - ETA: 39s - loss: 1.7889e- - ETA: 39s - loss: 1.6263e- - ETA: 39s - loss: 1.4908e- - ETA: 38s - loss: 1.3761e- - ETA: 38s - loss: 1.2778e- - ETA: 37s - loss: 1.1926e- - ETA: 37s - loss: 1.1181e- - ETA: 37s - loss: 2.0526e- - ETA: 37s - loss: 1.9386e- - ETA: 36s - loss: 1.8365e- - ETA: 36s - loss: 1.7447e- - ETA: 35s - loss: 1.6616e- - ETA: 35s - loss: 1.5861e- - ETA: 35s - loss: 2.3069e- - ETA: 34s - loss: 2.2108e- - ETA: 34s - loss: 2.1223e- - ETA: 34s - loss: 2.4316e- - ETA: 33s - loss: 2.7029e- - ETA: 33s - loss: 3.0950e- - ETA: 33s - loss: 2.9882e- - ETA: 32s - loss: 2.8886e- - ETA: 32s - loss: 2.8775e- - ETA: 32s - loss: 2.8439e- - ETA: 31s - loss: 2.7577e- - ETA: 31s - loss: 2.9231e- - ETA: 31s - loss: 2.8396e- - ETA: 30s - loss: 2.7607e- - ETA: 30s - loss: 2.6861e- - ETA: 30s - loss: 2.6154e- - ETA: 29s - loss: 3.1114e- - ETA: 29s - loss: 3.1708e- - ETA: 29s - loss: 3.1562e- - ETA: 28s - loss: 3.4081e- - ETA: 28s - loss: 3.6191e- - ETA: 28s - loss: 3.5369e- - ETA: 27s - loss: 3.4789e- - ETA: 27s - loss: 3.4033e- - ETA: 27s - loss: 3.3309e- - ETA: 26s - loss: 3.2615e- - ETA: 26s - loss: 3.1949e- - ETA: 26s - loss: 3.1310e- - ETA: 26s - loss: 3.0696e- - ETA: 25s - loss: 3.2833e- - ETA: 25s - loss: 3.2213e- - ETA: 24s - loss: 3.1617e- - ETA: 24s - loss: 3.1042e- - ETA: 24s - loss: 3.0487e- - ETA: 23s - loss: 2.9953e- - ETA: 23s - loss: 3.2118e- - ETA: 23s - loss: 3.1574e- - ETA: 22s - loss: 3.1179e- - ETA: 22s - loss: 3.1557e- - ETA: 22s - loss: 3.5656e- - ETA: 21s - loss: 3.5090e- - ETA: 21s - loss: 3.4542e- - ETA: 21s - loss: 3.4011e- - ETA: 20s - loss: 3.3495e- - ETA: 20s - loss: 3.4216e- - ETA: 19s - loss: 3.3713e- - ETA: 19s - loss: 3.5695e- - ETA: 19s - loss: 3.5185e- - ETA: 18s - loss: 3.4690e- - ETA: 18s - loss: 3.4208e- - ETA: 18s - loss: 3.3739e- - ETA: 17s - loss: 3.3283e- - ETA: 17s - loss: 3.2839e- - ETA: 17s - loss: 3.2407e- - ETA: 16s - loss: 3.1986e- - ETA: 16s - loss: 3.1576e- - ETA: 16s - loss: 3.2552e- - ETA: 15s - loss: 3.4075e- - ETA: 15s - loss: 3.3654e- - ETA: 15s - loss: 3.4908e- - ETA: 14s - loss: 3.4488e- - ETA: 14s - loss: 3.4077e- - ETA: 14s - loss: 3.4460e- - ETA: 13s - loss: 3.4059e- - ETA: 13s - loss: 3.3667e- - ETA: 13s - loss: 3.3285e- - ETA: 12s - loss: 3.2911e- - ETA: 12s - loss: 3.2545e- - ETA: 11s - loss: 3.2188e- - ETA: 11s - loss: 3.1838e- - ETA: 11s - loss: 3.1495e- - ETA: 10s - loss: 3.3302e- - ETA: 10s - loss: 3.2951e- - ETA: 10s - loss: 3.2608e- - ETA: 9s - loss: 3.4303e-04 - ETA: 9s - loss: 3.3953e-0 - ETA: 9s - loss: 3.3610e-0 - ETA: 8s - loss: 3.3274e-0 - ETA: 8s - loss: 3.2945e-0 - ETA: 8s - loss: 3.4208e-0 - ETA: 7s - loss: 3.3876e-0 - ETA: 7s - loss: 3.4538e-0 - ETA: 7s - loss: 3.4685e-0 - ETA: 6s - loss: 3.4358e-0 - ETA: 6s - loss: 3.6957e-0 - ETA: 6s - loss: 3.6615e-0 - ETA: 5s - loss: 3.7493e-0 - ETA: 5s - loss: 3.7152e-0 - ETA: 4s - loss: 3.6817e-0 - ETA: 4s - loss: 3.6489e-0 - ETA: 4s - loss: 3.6166e-0 - ETA: 3s - loss: 3.5849e-0 - ETA: 3s - loss: 3.5537e-0 - ETA: 3s - loss: 3.6557e-0 - ETA: 2s - loss: 3.7043e-0 - ETA: 2s - loss: 3.6729e-0 - ETA: 2s - loss: 3.8075e-0 - ETA: 1s - loss: 3.8413e-0 - ETA: 1s - loss: 3.8095e-0 - ETA: 1s - loss: 3.9790e-0 - ETA: 0s - loss: 3.9944e-0 - ETA: 0s - loss: 3.9621e-0 - 47s 6ms/sample - loss: 3.9304e-04 - val_loss: 0.0000e+00\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.0000e+ - ETA: 44s - loss: 0.0000e+ - ETA: 45s - loss: 0.0000e+ - ETA: 45s - loss: 0.0000e+ - ETA: 46s - loss: 0.0000e+ - ETA: 48s - loss: 0.0000e+ - ETA: 47s - loss: 0.0000e+ - ETA: 46s - loss: 0.0000e+ - ETA: 46s - loss: 0.0000e+ - ETA: 45s - loss: 0.0000e+ - ETA: 44s - loss: 0.0000e+ - ETA: 44s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 42s - loss: 7.4946e- - ETA: 41s - loss: 7.0262e- - ETA: 41s - loss: 1.1066e- - ETA: 40s - loss: 1.4331e- - ETA: 40s - loss: 2.2216e- - ETA: 39s - loss: 2.6226e- - ETA: 39s - loss: 2.4977e- - ETA: 39s - loss: 2.3842e- - ETA: 38s - loss: 2.2805e- - ETA: 38s - loss: 2.1855e- - ETA: 37s - loss: 2.0981e- - ETA: 37s - loss: 2.0174e- - ETA: 36s - loss: 2.0883e- - ETA: 36s - loss: 2.0137e- - ETA: 35s - loss: 1.9443e- - ETA: 35s - loss: 1.8795e- - ETA: 34s - loss: 1.8189e- - ETA: 34s - loss: 2.5043e- - ETA: 33s - loss: 2.4284e- - ETA: 33s - loss: 2.3570e- - ETA: 33s - loss: 2.2897e- - ETA: 32s - loss: 2.2261e- - ETA: 32s - loss: 2.1659e- - ETA: 31s - loss: 2.1089e- - ETA: 31s - loss: 2.1192e- - ETA: 31s - loss: 2.1521e- - ETA: 30s - loss: 2.0996e- - ETA: 30s - loss: 2.0496e- - ETA: 29s - loss: 2.0019e- - ETA: 29s - loss: 1.9564e- - ETA: 29s - loss: 1.9129e- - ETA: 28s - loss: 1.8714e- - ETA: 28s - loss: 2.1195e- - ETA: 27s - loss: 2.0754e- - ETA: 27s - loss: 2.3010e- - ETA: 27s - loss: 2.2550e- - ETA: 26s - loss: 2.2108e- - ETA: 26s - loss: 2.1682e- - ETA: 26s - loss: 2.1273e- - ETA: 25s - loss: 2.0879e- - ETA: 25s - loss: 2.0500e- - ETA: 24s - loss: 2.0134e- - ETA: 24s - loss: 1.9781e- - ETA: 24s - loss: 1.9439e- - ETA: 23s - loss: 1.9110e- - ETA: 23s - loss: 1.8791e- - ETA: 23s - loss: 1.8483e- - ETA: 22s - loss: 1.8185e- - ETA: 22s - loss: 1.9753e- - ETA: 21s - loss: 1.9444e- - ETA: 21s - loss: 2.0543e- - ETA: 21s - loss: 2.0231e- - ETA: 20s - loss: 1.9929e- - ETA: 20s - loss: 2.0874e- - ETA: 20s - loss: 2.3793e- - ETA: 19s - loss: 2.4754e- - ETA: 19s - loss: 2.4728e- - ETA: 18s - loss: 2.4384e- - ETA: 18s - loss: 2.5761e- - ETA: 18s - loss: 2.7374e- - ETA: 17s - loss: 2.7009e- - ETA: 17s - loss: 2.6653e- - ETA: 17s - loss: 2.6307e- - ETA: 16s - loss: 2.5970e- - ETA: 16s - loss: 2.9228e- - ETA: 16s - loss: 2.8863e- - ETA: 15s - loss: 3.2178e- - ETA: 15s - loss: 3.1786e- - ETA: 15s - loss: 3.1403e- - ETA: 14s - loss: 3.1029e- - ETA: 14s - loss: 3.1446e- - ETA: 14s - loss: 3.2919e- - ETA: 13s - loss: 3.3615e- - ETA: 13s - loss: 3.3233e- - ETA: 12s - loss: 3.4144e- - ETA: 12s - loss: 3.3765e- - ETA: 12s - loss: 3.3394e- - ETA: 11s - loss: 3.3031e- - ETA: 11s - loss: 3.3541e- - ETA: 11s - loss: 3.6102e- - ETA: 10s - loss: 3.5722e- - ETA: 10s - loss: 3.5350e- - ETA: 10s - loss: 3.4986e- - ETA: 9s - loss: 3.5649e-04 - ETA: 9s - loss: 3.5289e-0 - ETA: 8s - loss: 3.4936e-0 - ETA: 8s - loss: 3.4590e-0 - ETA: 8s - loss: 3.4251e-0 - ETA: 7s - loss: 3.3919e-0 - ETA: 7s - loss: 3.5217e-0 - ETA: 7s - loss: 3.4881e-0 - ETA: 6s - loss: 3.4552e-0 - ETA: 6s - loss: 3.4229e-0 - ETA: 6s - loss: 3.5064e-0 - ETA: 5s - loss: 3.4742e-0 - ETA: 5s - loss: 3.4426e-0 - ETA: 5s - loss: 3.5268e-0 - ETA: 4s - loss: 3.4953e-0 - ETA: 4s - loss: 3.5269e-0 - ETA: 3s - loss: 3.4959e-0 - ETA: 3s - loss: 3.4655e-0 - ETA: 3s - loss: 3.4356e-0 - ETA: 2s - loss: 3.5741e-0 - ETA: 2s - loss: 3.7159e-0 - ETA: 2s - loss: 3.6847e-0 - ETA: 1s - loss: 3.6540e-0 - ETA: 1s - loss: 3.6939e-0 - ETA: 1s - loss: 3.9140e-0 - ETA: 0s - loss: 3.9366e-0 - ETA: 0s - loss: 4.0118e-0 - 50s 6ms/sample - loss: 3.9797e-04 - val_loss: 0.0000e+00\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - ETA: 50s - loss: 7.2290e- - ETA: 46s - loss: 3.6145e- - ETA: 45s - loss: 4.6566e- - ETA: 47s - loss: 3.4924e- - ETA: 46s - loss: 2.7939e- - ETA: 45s - loss: 2.8939e- - ETA: 44s - loss: 3.0747e- - ETA: 44s - loss: 2.6903e- - ETA: 43s - loss: 3.1823e- - ETA: 42s - loss: 2.8640e- - ETA: 42s - loss: 2.6037e- - ETA: 41s - loss: 3.0249e- - ETA: 41s - loss: 3.7452e- - ETA: 41s - loss: 3.6768e- - ETA: 40s - loss: 3.4317e- - ETA: 40s - loss: 3.8826e- - ETA: 40s - loss: 4.0763e- - ETA: 39s - loss: 3.8498e- - ETA: 38s - loss: 3.6472e- - ETA: 38s - loss: 3.4648e- - ETA: 38s - loss: 3.2998e- - ETA: 37s - loss: 3.9291e- - ETA: 37s - loss: 3.7583e- - ETA: 36s - loss: 3.6017e- - ETA: 36s - loss: 3.4576e- - ETA: 36s - loss: 3.5486e- - ETA: 35s - loss: 3.4172e- - ETA: 35s - loss: 3.6821e- - ETA: 35s - loss: 3.7527e- - ETA: 34s - loss: 3.6276e- - ETA: 34s - loss: 3.5106e- - ETA: 34s - loss: 3.4716e- - ETA: 33s - loss: 3.3664e- - ETA: 33s - loss: 3.2674e- - ETA: 32s - loss: 3.1741e- - ETA: 32s - loss: 3.2726e- - ETA: 32s - loss: 3.1842e- - ETA: 31s - loss: 3.1004e- - ETA: 31s - loss: 3.3119e- - ETA: 31s - loss: 3.2291e- - ETA: 30s - loss: 3.2452e- - ETA: 30s - loss: 3.1679e- - ETA: 29s - loss: 3.0942e- - ETA: 29s - loss: 3.0239e- - ETA: 29s - loss: 2.9567e- - ETA: 29s - loss: 2.8924e- - ETA: 28s - loss: 2.8309e- - ETA: 28s - loss: 2.7719e- - ETA: 28s - loss: 2.7154e- - ETA: 27s - loss: 2.9211e- - ETA: 27s - loss: 3.0244e- - ETA: 26s - loss: 2.9663e- - ETA: 26s - loss: 3.4011e- - ETA: 26s - loss: 3.3381e- - ETA: 25s - loss: 3.4375e- - ETA: 25s - loss: 3.3761e- - ETA: 24s - loss: 3.5484e- - ETA: 24s - loss: 3.5222e- - ETA: 24s - loss: 3.4625e- - ETA: 23s - loss: 3.4048e- - ETA: 23s - loss: 3.3490e- - ETA: 22s - loss: 3.2949e- - ETA: 22s - loss: 3.6502e- - ETA: 22s - loss: 3.5931e- - ETA: 21s - loss: 3.6267e- - ETA: 21s - loss: 3.5718e- - ETA: 21s - loss: 3.5185e- - ETA: 20s - loss: 3.4667e- - ETA: 20s - loss: 3.4165e- - ETA: 19s - loss: 3.3677e- - ETA: 19s - loss: 3.4856e- - ETA: 19s - loss: 3.5657e- - ETA: 18s - loss: 3.5169e- - ETA: 18s - loss: 3.8822e- - ETA: 18s - loss: 3.8304e- - ETA: 17s - loss: 3.7800e- - ETA: 17s - loss: 3.7474e- - ETA: 17s - loss: 3.7773e- - ETA: 16s - loss: 3.7295e- - ETA: 16s - loss: 3.6829e- - ETA: 15s - loss: 3.8931e- - ETA: 15s - loss: 3.8457e- - ETA: 15s - loss: 3.8937e- - ETA: 14s - loss: 3.8830e- - ETA: 14s - loss: 3.8373e- - ETA: 14s - loss: 3.7927e- - ETA: 13s - loss: 3.7491e- - ETA: 13s - loss: 3.7065e- - ETA: 13s - loss: 3.6649e- - ETA: 12s - loss: 3.7670e- - ETA: 12s - loss: 3.7823e- - ETA: 12s - loss: 3.7411e- - ETA: 11s - loss: 3.7009e- - ETA: 11s - loss: 3.6615e- - ETA: 10s - loss: 3.6230e- - ETA: 10s - loss: 3.5853e- - ETA: 10s - loss: 3.5483e- - ETA: 9s - loss: 3.5121e-04 - ETA: 9s - loss: 3.5261e-0 - ETA: 9s - loss: 3.4908e-0 - ETA: 8s - loss: 3.4563e-0 - ETA: 8s - loss: 3.4224e-0 - ETA: 8s - loss: 3.3891e-0 - ETA: 7s - loss: 3.3566e-0 - ETA: 7s - loss: 3.3246e-0 - ETA: 7s - loss: 3.2932e-0 - ETA: 6s - loss: 3.2624e-0 - ETA: 6s - loss: 3.4630e-0 - ETA: 5s - loss: 3.4313e-0 - ETA: 5s - loss: 3.4001e-0 - ETA: 5s - loss: 3.3695e-0 - ETA: 4s - loss: 3.3394e-0 - ETA: 4s - loss: 3.4111e-0 - ETA: 4s - loss: 3.3811e-0 - ETA: 3s - loss: 3.3517e-0 - ETA: 3s - loss: 3.3229e-0 - ETA: 2s - loss: 3.2945e-0 - ETA: 2s - loss: 3.3724e-0 - ETA: 2s - loss: 3.3441e-0 - ETA: 1s - loss: 3.3162e-0 - ETA: 1s - loss: 3.2888e-0 - ETA: 1s - loss: 3.2618e-0 - ETA: 0s - loss: 3.3167e-0 - ETA: 0s - loss: 3.3858e-0 - 49s 6ms/sample - loss: 3.3587e-04 - val_loss: 0.0000e+00\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 42s - loss: 1.2399e- - ETA: 42s - loss: 9.2991e- - ETA: 41s - loss: 7.4393e- - ETA: 41s - loss: 1.4331e- - ETA: 41s - loss: 1.3673e- - ETA: 40s - loss: 1.3382e- - ETA: 40s - loss: 1.1896e- - ETA: 40s - loss: 1.0706e- - ETA: 39s - loss: 9.7327e- - ETA: 39s - loss: 1.2691e- - ETA: 39s - loss: 1.6428e- - ETA: 38s - loss: 2.2186e- - ETA: 38s - loss: 2.0707e- - ETA: 38s - loss: 1.9413e- - ETA: 37s - loss: 1.8271e- - ETA: 37s - loss: 1.7256e- - ETA: 37s - loss: 1.6348e- - ETA: 36s - loss: 1.5530e- - ETA: 36s - loss: 1.4791e- - ETA: 36s - loss: 1.4118e- - ETA: 35s - loss: 1.3504e- - ETA: 35s - loss: 2.1375e- - ETA: 35s - loss: 2.0520e- - ETA: 35s - loss: 1.9731e- - ETA: 34s - loss: 1.9000e- - ETA: 34s - loss: 1.8322e- - ETA: 34s - loss: 2.0245e- - ETA: 34s - loss: 1.9570e- - ETA: 34s - loss: 1.8939e- - ETA: 34s - loss: 1.8347e- - ETA: 33s - loss: 1.7791e- - ETA: 33s - loss: 1.7268e- - ETA: 33s - loss: 1.6774e- - ETA: 32s - loss: 1.6308e- - ETA: 32s - loss: 1.5868e- - ETA: 32s - loss: 1.5450e- - ETA: 31s - loss: 1.5054e- - ETA: 31s - loss: 1.4678e- - ETA: 31s - loss: 1.4320e- - ETA: 30s - loss: 1.6963e- - ETA: 30s - loss: 1.6569e- - ETA: 29s - loss: 1.6192e- - ETA: 29s - loss: 1.5832e- - ETA: 29s - loss: 1.9043e- - ETA: 28s - loss: 1.8638e- - ETA: 28s - loss: 2.2045e- - ETA: 27s - loss: 2.1990e- - ETA: 27s - loss: 2.1550e- - ETA: 27s - loss: 2.1128e- - ETA: 26s - loss: 2.0721e- - ETA: 26s - loss: 2.0330e- - ETA: 26s - loss: 1.9954e- - ETA: 25s - loss: 2.0044e- - ETA: 25s - loss: 2.3116e- - ETA: 24s - loss: 2.3228e- - ETA: 24s - loss: 2.2827e- - ETA: 24s - loss: 2.5364e- - ETA: 23s - loss: 2.4941e- - ETA: 23s - loss: 2.5684e- - ETA: 23s - loss: 2.5270e- - ETA: 22s - loss: 2.5685e- - ETA: 22s - loss: 2.5283e- - ETA: 21s - loss: 2.4895e- - ETA: 21s - loss: 2.7323e- - ETA: 21s - loss: 2.9398e- - ETA: 20s - loss: 2.8965e- - ETA: 20s - loss: 2.8546e- - ETA: 19s - loss: 2.8138e- - ETA: 19s - loss: 2.7742e- - ETA: 19s - loss: 2.8998e- - ETA: 18s - loss: 2.8601e- - ETA: 18s - loss: 2.8214e- - ETA: 18s - loss: 2.7838e- - ETA: 17s - loss: 2.7472e- - ETA: 17s - loss: 2.7115e- - ETA: 16s - loss: 2.8683e- - ETA: 16s - loss: 2.8320e- - ETA: 16s - loss: 2.7966e- - ETA: 15s - loss: 3.0312e- - ETA: 15s - loss: 3.4548e- - ETA: 15s - loss: 3.4132e- - ETA: 14s - loss: 3.3726e- - ETA: 14s - loss: 3.3329e- - ETA: 14s - loss: 3.2941e- - ETA: 13s - loss: 3.2563e- - ETA: 13s - loss: 3.2193e- - ETA: 13s - loss: 3.1831e- - ETA: 12s - loss: 3.2017e- - ETA: 12s - loss: 3.1887e- - ETA: 12s - loss: 3.1540e- - ETA: 12s - loss: 3.1201e- - ETA: 11s - loss: 3.0869e- - ETA: 11s - loss: 3.0544e- - ETA: 11s - loss: 3.2189e- - ETA: 10s - loss: 3.3692e- - ETA: 10s - loss: 3.3348e- - ETA: 10s - loss: 3.3012e- - ETA: 9s - loss: 3.2682e-04 - ETA: 9s - loss: 3.2984e-0 - ETA: 9s - loss: 3.3340e-0 - ETA: 8s - loss: 3.3016e-0 - ETA: 8s - loss: 3.2699e-0 - ETA: 8s - loss: 3.2388e-0 - ETA: 7s - loss: 3.2082e-0 - ETA: 7s - loss: 3.3276e-0 - ETA: 6s - loss: 3.2967e-0 - ETA: 6s - loss: 3.2665e-0 - ETA: 6s - loss: 3.3078e-0 - ETA: 5s - loss: 3.4435e-0 - ETA: 5s - loss: 3.4128e-0 - ETA: 4s - loss: 3.4585e-0 - ETA: 4s - loss: 3.4281e-0 - ETA: 4s - loss: 3.3983e-0 - ETA: 3s - loss: 3.4392e-0 - ETA: 3s - loss: 3.4098e-0 - ETA: 2s - loss: 3.3809e-0 - ETA: 2s - loss: 3.4467e-0 - ETA: 2s - loss: 3.4694e-0 - ETA: 1s - loss: 3.4407e-0 - ETA: 1s - loss: 3.4125e-0 - ETA: 0s - loss: 3.5353e-0 - ETA: 0s - loss: 3.5068e-0 - 57s 7ms/sample - loss: 3.6309e-04 - val_loss: 0.0000e+00\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - ETA: 51s - loss: 0.0000e+ - ETA: 51s - loss: 2.5464e- - ETA: 50s - loss: 1.6976e- - ETA: 49s - loss: 3.0381e- - ETA: 48s - loss: 4.1246e- - ETA: 48s - loss: 3.4372e- - ETA: 50s - loss: 2.9461e- - ETA: 51s - loss: 2.5779e- - ETA: 51s - loss: 5.0973e- - ETA: 52s - loss: 4.5876e- - ETA: 51s - loss: 4.1705e- - ETA: 51s - loss: 3.8230e- - ETA: 50s - loss: 3.5289e- - ETA: 49s - loss: 3.2769e- - ETA: 49s - loss: 3.5410e- - ETA: 48s - loss: 4.0943e- - ETA: 48s - loss: 3.8535e- - ETA: 48s - loss: 3.7036e- - ETA: 47s - loss: 3.5087e- - ETA: 47s - loss: 3.3332e- - ETA: 46s - loss: 3.1745e- - ETA: 46s - loss: 3.0302e- - ETA: 45s - loss: 3.5266e- - ETA: 45s - loss: 3.3797e- - ETA: 44s - loss: 3.2445e- - ETA: 43s - loss: 3.1611e- - ETA: 43s - loss: 3.0440e- - ETA: 42s - loss: 2.9353e- - ETA: 42s - loss: 3.0747e- - ETA: 41s - loss: 2.9722e- - ETA: 41s - loss: 2.8763e- - ETA: 40s - loss: 2.9984e- - ETA: 39s - loss: 3.1402e- - ETA: 39s - loss: 3.2654e- - ETA: 38s - loss: 3.1721e- - ETA: 37s - loss: 3.5583e- - ETA: 37s - loss: 3.4621e- - ETA: 37s - loss: 3.3710e- - ETA: 37s - loss: 3.2846e- - ETA: 36s - loss: 3.2024e- - ETA: 36s - loss: 3.1243e- - ETA: 36s - loss: 3.2502e- - ETA: 35s - loss: 3.1746e- - ETA: 35s - loss: 3.1025e- - ETA: 35s - loss: 3.1444e- - ETA: 34s - loss: 3.2126e- - ETA: 34s - loss: 3.3026e- - ETA: 33s - loss: 3.2338e- - ETA: 33s - loss: 3.1678e- - ETA: 33s - loss: 3.1045e- - ETA: 32s - loss: 3.1017e- - ETA: 32s - loss: 3.3217e- - ETA: 32s - loss: 3.2591e- - ETA: 31s - loss: 3.1987e- - ETA: 31s - loss: 3.1405e- - ETA: 31s - loss: 3.0845e- - ETA: 30s - loss: 3.2327e- - ETA: 30s - loss: 3.2850e- - ETA: 29s - loss: 3.2294e- - ETA: 29s - loss: 3.2874e- - ETA: 28s - loss: 3.2335e- - ETA: 28s - loss: 3.4445e- - ETA: 27s - loss: 3.3898e- - ETA: 27s - loss: 3.3369e- - ETA: 26s - loss: 3.4320e- - ETA: 26s - loss: 3.3800e- - ETA: 25s - loss: 3.3296e- - ETA: 25s - loss: 3.3790e- - ETA: 24s - loss: 3.3300e- - ETA: 24s - loss: 3.3686e- - ETA: 24s - loss: 3.3211e- - ETA: 23s - loss: 3.2750e- - ETA: 23s - loss: 3.2301e- - ETA: 22s - loss: 3.1865e- - ETA: 22s - loss: 3.2601e- - ETA: 21s - loss: 3.2172e- - ETA: 21s - loss: 3.1754e- - ETA: 20s - loss: 3.2470e- - ETA: 20s - loss: 3.2059e- - ETA: 19s - loss: 3.1658e- - ETA: 19s - loss: 3.1267e- - ETA: 18s - loss: 3.0886e- - ETA: 18s - loss: 3.1739e- - ETA: 17s - loss: 3.1361e- - ETA: 17s - loss: 3.1958e- - ETA: 17s - loss: 3.2224e- - ETA: 16s - loss: 3.1853e- - ETA: 16s - loss: 3.1491e- - ETA: 15s - loss: 3.1138e- - ETA: 15s - loss: 3.0792e- - ETA: 14s - loss: 3.2340e- - ETA: 14s - loss: 3.1988e- - ETA: 13s - loss: 3.1644e- - ETA: 13s - loss: 3.2015e- - ETA: 12s - loss: 3.1678e- - ETA: 12s - loss: 3.1348e- - ETA: 12s - loss: 3.2214e- - ETA: 11s - loss: 3.1886e- - ETA: 11s - loss: 3.2089e- - ETA: 10s - loss: 3.1769e- - ETA: 10s - loss: 3.2735e- - ETA: 9s - loss: 3.2414e-04 - ETA: 9s - loss: 3.2099e-0 - ETA: 9s - loss: 3.4283e-0 - ETA: 8s - loss: 3.3957e-0 - ETA: 8s - loss: 3.4357e-0 - ETA: 7s - loss: 3.4942e-0 - ETA: 7s - loss: 3.4619e-0 - ETA: 6s - loss: 3.4380e-0 - ETA: 6s - loss: 3.4708e-0 - ETA: 6s - loss: 3.4395e-0 - ETA: 5s - loss: 3.4088e-0 - ETA: 5s - loss: 3.3786e-0 - ETA: 4s - loss: 3.4631e-0 - ETA: 4s - loss: 3.4329e-0 - ETA: 3s - loss: 3.4033e-0 - ETA: 3s - loss: 3.3743e-0 - ETA: 2s - loss: 3.3457e-0 - ETA: 2s - loss: 3.3175e-0 - ETA: 2s - loss: 3.3811e-0 - ETA: 1s - loss: 3.3531e-0 - ETA: 1s - loss: 3.3257e-0 - ETA: 0s - loss: 3.2986e-0 - ETA: 0s - loss: 3.4048e-0 - 57s 7ms/sample - loss: 3.3776e-04 - val_loss: 0.0000e+00\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - ETA: 49s - loss: 8.3060e- - ETA: 51s - loss: 8.2558e- - ETA: 49s - loss: 5.5039e- - ETA: 48s - loss: 7.1462e- - ETA: 49s - loss: 5.7169e- - ETA: 49s - loss: 4.7641e- - ETA: 49s - loss: 4.0835e- - ETA: 49s - loss: 3.5731e- - ETA: 49s - loss: 3.1761e- - ETA: 48s - loss: 3.6770e- - ETA: 47s - loss: 3.9093e- - ETA: 47s - loss: 4.0300e- - ETA: 47s - loss: 3.7200e- - ETA: 46s - loss: 3.4542e- - ETA: 46s - loss: 4.0743e- - ETA: 46s - loss: 4.5605e- - ETA: 45s - loss: 4.2923e- - ETA: 44s - loss: 4.0538e- - ETA: 45s - loss: 3.8404e- - ETA: 44s - loss: 3.6484e- - ETA: 44s - loss: 3.5809e- - ETA: 43s - loss: 3.4181e- - ETA: 42s - loss: 3.2695e- - ETA: 42s - loss: 4.4814e- - ETA: 41s - loss: 4.7197e- - ETA: 41s - loss: 4.5381e- - ETA: 40s - loss: 4.6270e- - ETA: 40s - loss: 4.4618e- - ETA: 40s - loss: 4.3079e- - ETA: 39s - loss: 4.1643e- - ETA: 39s - loss: 4.0300e- - ETA: 38s - loss: 4.1997e- - ETA: 38s - loss: 4.1638e- - ETA: 38s - loss: 4.0414e- - ETA: 37s - loss: 3.9259e- - ETA: 37s - loss: 3.8168e- - ETA: 36s - loss: 4.1518e- - ETA: 36s - loss: 4.1409e- - ETA: 35s - loss: 4.0348e- - ETA: 35s - loss: 3.9339e- - ETA: 34s - loss: 3.8379e- - ETA: 34s - loss: 3.7466e- - ETA: 33s - loss: 3.6594e- - ETA: 33s - loss: 3.5763e- - ETA: 32s - loss: 3.4968e- - ETA: 32s - loss: 3.7899e- - ETA: 31s - loss: 3.7092e- - ETA: 31s - loss: 3.7086e- - ETA: 30s - loss: 3.6329e- - ETA: 30s - loss: 3.5602e- - ETA: 29s - loss: 4.0625e- - ETA: 29s - loss: 3.9844e- - ETA: 28s - loss: 3.9092e- - ETA: 28s - loss: 3.8369e- - ETA: 28s - loss: 3.7671e- - ETA: 27s - loss: 3.6998e- - ETA: 27s - loss: 3.9117e- - ETA: 26s - loss: 3.8442e- - ETA: 26s - loss: 3.7791e- - ETA: 25s - loss: 3.7280e- - ETA: 25s - loss: 3.6669e- - ETA: 24s - loss: 3.6308e- - ETA: 24s - loss: 3.5732e- - ETA: 24s - loss: 3.5767e- - ETA: 23s - loss: 3.5217e- - ETA: 23s - loss: 3.4684e- - ETA: 22s - loss: 3.4166e- - ETA: 22s - loss: 3.5144e- - ETA: 21s - loss: 3.5871e- - ETA: 21s - loss: 3.5359e- - ETA: 21s - loss: 3.4861e- - ETA: 20s - loss: 3.6913e- - ETA: 20s - loss: 3.7728e- - ETA: 19s - loss: 3.7218e- - ETA: 19s - loss: 3.6722e- - ETA: 19s - loss: 3.7702e- - ETA: 18s - loss: 3.7212e- - ETA: 18s - loss: 3.6735e- - ETA: 17s - loss: 3.7054e- - ETA: 17s - loss: 3.6591e- - ETA: 17s - loss: 3.6139e- - ETA: 16s - loss: 3.5699e- - ETA: 16s - loss: 3.5269e- - ETA: 15s - loss: 3.6880e- - ETA: 15s - loss: 3.6446e- - ETA: 15s - loss: 3.6816e- - ETA: 14s - loss: 3.6393e- - ETA: 14s - loss: 3.5980e- - ETA: 13s - loss: 3.5575e- - ETA: 13s - loss: 3.9259e- - ETA: 13s - loss: 3.8828e- - ETA: 12s - loss: 3.8406e- - ETA: 12s - loss: 3.9776e- - ETA: 11s - loss: 3.9353e- - ETA: 11s - loss: 3.8938e- - ETA: 11s - loss: 3.8533e- - ETA: 10s - loss: 3.8135e- - ETA: 10s - loss: 3.7746e- - ETA: 9s - loss: 3.7365e-04 - ETA: 9s - loss: 3.6991e-0 - ETA: 9s - loss: 3.6625e-0 - ETA: 8s - loss: 3.6266e-0 - ETA: 8s - loss: 3.5914e-0 - ETA: 7s - loss: 3.5569e-0 - ETA: 7s - loss: 3.5230e-0 - ETA: 7s - loss: 3.5382e-0 - ETA: 6s - loss: 3.5890e-0 - ETA: 6s - loss: 3.5557e-0 - ETA: 6s - loss: 3.5231e-0 - ETA: 5s - loss: 3.4911e-0 - ETA: 5s - loss: 3.4639e-0 - ETA: 4s - loss: 3.4506e-0 - ETA: 4s - loss: 3.4201e-0 - ETA: 4s - loss: 3.3901e-0 - ETA: 3s - loss: 3.3606e-0 - ETA: 3s - loss: 3.3316e-0 - ETA: 3s - loss: 3.3032e-0 - ETA: 2s - loss: 3.2752e-0 - ETA: 2s - loss: 3.2476e-0 - ETA: 1s - loss: 3.2206e-0 - ETA: 1s - loss: 3.2911e-0 - ETA: 1s - loss: 3.2641e-0 - ETA: 0s - loss: 3.3209e-0 - ETA: 0s - loss: 3.5412e-0 - 50s 6ms/sample - loss: 3.5623e-04 - val_loss: 0.0000e+00\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - ETA: 43s - loss: 0.0000e+ - ETA: 43s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 42s - loss: 0.0000e+ - ETA: 41s - loss: 0.0000e+ - ETA: 41s - loss: 0.0000e+ - ETA: 40s - loss: 0.0000e+ - ETA: 40s - loss: 0.0000e+ - ETA: 40s - loss: 3.8226e- - ETA: 40s - loss: 1.1478e- - ETA: 40s - loss: 1.0435e- - ETA: 39s - loss: 1.2951e- - ETA: 40s - loss: 1.1955e- - ETA: 40s - loss: 1.1101e- - ETA: 39s - loss: 1.0361e- - ETA: 39s - loss: 1.3163e- - ETA: 38s - loss: 1.2388e- - ETA: 38s - loss: 1.1700e- - ETA: 38s - loss: 1.3937e- - ETA: 37s - loss: 2.1957e- - ETA: 37s - loss: 2.0911e- - ETA: 36s - loss: 2.4497e- - ETA: 36s - loss: 2.3432e- - ETA: 36s - loss: 2.2455e- - ETA: 35s - loss: 2.1557e- - ETA: 35s - loss: 2.3615e- - ETA: 35s - loss: 2.2740e- - ETA: 34s - loss: 2.3433e- - ETA: 34s - loss: 2.2624e- - ETA: 33s - loss: 2.1870e- - ETA: 33s - loss: 2.1165e- - ETA: 33s - loss: 2.1456e- - ETA: 32s - loss: 2.0806e- - ETA: 32s - loss: 2.0194e- - ETA: 32s - loss: 1.9735e- - ETA: 32s - loss: 1.9186e- - ETA: 32s - loss: 2.1379e- - ETA: 31s - loss: 2.3389e- - ETA: 31s - loss: 2.2789e- - ETA: 31s - loss: 2.2219e- - ETA: 31s - loss: 2.1678e- - ETA: 31s - loss: 2.1161e- - ETA: 31s - loss: 2.0669e- - ETA: 30s - loss: 2.0820e- - ETA: 30s - loss: 2.0357e- - ETA: 30s - loss: 1.9914e- - ETA: 29s - loss: 1.9491e- - ETA: 29s - loss: 1.9085e- - ETA: 29s - loss: 1.9452e- - ETA: 29s - loss: 2.0864e- - ETA: 29s - loss: 2.2889e- - ETA: 29s - loss: 2.2449e- - ETA: 29s - loss: 2.2779e- - ETA: 28s - loss: 2.2357e- - ETA: 28s - loss: 2.1951e- - ETA: 28s - loss: 2.2345e- - ETA: 27s - loss: 2.1953e- - ETA: 27s - loss: 2.4516e- - ETA: 27s - loss: 2.5362e- - ETA: 26s - loss: 2.8882e- - ETA: 26s - loss: 2.8408e- - ETA: 25s - loss: 2.8780e- - ETA: 25s - loss: 2.9928e- - ETA: 25s - loss: 2.9461e- - ETA: 24s - loss: 2.9007e- - ETA: 24s - loss: 3.0052e- - ETA: 23s - loss: 2.9603e- - ETA: 23s - loss: 3.0142e- - ETA: 23s - loss: 2.9706e- - ETA: 22s - loss: 3.0302e- - ETA: 22s - loss: 3.0835e- - ETA: 21s - loss: 3.0407e- - ETA: 21s - loss: 2.9990e- - ETA: 21s - loss: 2.9585e- - ETA: 20s - loss: 2.9190e- - ETA: 20s - loss: 2.8806e- - ETA: 19s - loss: 2.9448e- - ETA: 19s - loss: 2.9071e- - ETA: 18s - loss: 3.1568e- - ETA: 18s - loss: 3.1173e- - ETA: 17s - loss: 3.0788e- - ETA: 17s - loss: 3.0413e- - ETA: 17s - loss: 3.1530e- - ETA: 16s - loss: 3.1155e- - ETA: 16s - loss: 3.1969e- - ETA: 15s - loss: 3.2283e- - ETA: 15s - loss: 3.1912e- - ETA: 15s - loss: 3.3656e- - ETA: 14s - loss: 3.4449e- - ETA: 14s - loss: 3.5244e- - ETA: 13s - loss: 3.4857e- - ETA: 13s - loss: 3.4478e- - ETA: 12s - loss: 3.4505e- - ETA: 12s - loss: 3.4138e- - ETA: 12s - loss: 3.3779e- - ETA: 11s - loss: 3.3427e- - ETA: 11s - loss: 3.3082e- - ETA: 10s - loss: 3.2875e- - ETA: 10s - loss: 3.2543e- - ETA: 10s - loss: 3.3046e- - ETA: 9s - loss: 3.2718e-04 - ETA: 9s - loss: 3.5232e-0 - ETA: 8s - loss: 3.4890e-0 - ETA: 8s - loss: 3.4554e-0 - ETA: 8s - loss: 3.4225e-0 - ETA: 7s - loss: 3.3902e-0 - ETA: 7s - loss: 3.5051e-0 - ETA: 6s - loss: 3.4726e-0 - ETA: 6s - loss: 3.4408e-0 - ETA: 5s - loss: 3.4095e-0 - ETA: 5s - loss: 3.5215e-0 - ETA: 5s - loss: 3.4900e-0 - ETA: 4s - loss: 3.4591e-0 - ETA: 4s - loss: 3.4813e-0 - ETA: 3s - loss: 3.4510e-0 - ETA: 3s - loss: 3.4213e-0 - ETA: 3s - loss: 3.4778e-0 - ETA: 2s - loss: 3.4483e-0 - ETA: 2s - loss: 3.4193e-0 - ETA: 1s - loss: 3.3908e-0 - ETA: 1s - loss: 3.3628e-0 - ETA: 1s - loss: 3.3717e-0 - ETA: 0s - loss: 3.3443e-0 - ETA: 0s - loss: 3.3173e-0 - 53s 7ms/sample - loss: 3.2908e-04 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19c1defe908>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(x=[eng_input_data, fra_input_data], y=target_data,batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder inference model\n",
    "# ecoder_states is the state vectors of the trained model\n",
    "encoder_model_inf = tf.keras.Model(encoder_input, encoder_states)\n",
    "\n",
    "# Create decoder input states for inference\n",
    "# Decoder requires the hidden and cell states of the encoder inference model as the initial state\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# These states will be provided as input to the model and therefore, needs to be initialized as inputs\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Create decoder output states for inference\n",
    "# The decoder is called recursively for each character to be generated in the suffix sequence\n",
    "# On the first call, the hidden and cell states from the encoder will be used to initialize the states of the decoder LSTM\n",
    "# which will generate output and the hidden and the cell states\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, initial_state=decoder_input_states)\n",
    "\n",
    "# These states will be used to generate the nect character in the next iteration\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "# The output of the decoder LSTM is again fed to the dense layer to get the predicted character\n",
    "# Create decoder dense layer\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "# Combining all this together using the model function from keras to build the decoder inference model\n",
    "decoder_model_inf = tf.keras.Model(inputs=[decoder_input] + decoder_input_states, outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V\n"
     ]
    }
   ],
   "source": [
    "# Now that we have the inference models built, we can use these to generate a suffix, given a prefix as input\n",
    "\n",
    "# Get encoder internal state by passing a sentence as input\n",
    "inp_seq = eng_input_data[0:1] # random prefix sequence\n",
    "states_val = encoder_model_inf.predict(inp_seq) # outouts encoder internal states\n",
    "\n",
    "# Seed the first character and get output from the decoder \n",
    "target_seq = np.zeros((1, 1, len(french_vocab))) # defining variable for the suffix to be generated\n",
    "\n",
    "# Initializing the variable with the start token(\\t)\n",
    "target_seq[0, 0, fra_char_to_idx['\\t']] = 1 \n",
    "\n",
    "# Passing target sequence and current values to the decoder inference model to generate the output along with state values\n",
    "decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "# The output is a prob distribution for the next character over the vocabulary\n",
    "\n",
    "# Find out the next character from the Decoder output\n",
    "max_val_index = np.argmax(decoder_out[0,-1,:]) # index with the maximum probability\n",
    "sampled_fra_char = fra_idx_to_char[max_val_index] # this is the character that the index maps to\n",
    "\n",
    "# Print the first character predicted by the decoder\n",
    "print(sampled_fra_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "# The first character can be fed again to the decoder inference model\n",
    "\n",
    "# Update the target sequence with the new char generated \n",
    "target_seq = np.zeros((1, 1, len(french_vocab)))\n",
    "target_seq[0, 0, max_val_index] = 1\n",
    "\n",
    "# Get decoder final states from last time-step\n",
    "states_val = [decoder_h, decoder_c]\n",
    "\n",
    "# Passing this updated seq and ew state values to the decoder inference model to generate the next character\n",
    "decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "\n",
    "# Map the prediction to char and print it\n",
    "max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "sampled_fra_char = fra_idx_to_char[max_val_index]\n",
    "\n",
    "print(sampled_fra_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_eng_sentence(inp_seq):\n",
    "    # Get encoder states \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    # Create a vector for the output sentence\n",
    "    target_seq = np.zeros((1, 1, len(french_vocab)))\n",
    "    \n",
    "    # Initialize the first char of the output to tab\n",
    "    target_seq[0, 0, fra_char_to_idx['\\t']] = 1\n",
    "    \n",
    "    # Keep track of the translated sequence\n",
    "    translated_sent = ''\n",
    "    \n",
    "    # Stop condition will be true when we encounter a newline or maximum lenght of sentence is reached\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        # Get decoder output\n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        \n",
    "        # Get index of most probable next character\n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        \n",
    "        # Map index to the actual character\n",
    "        sampled_fra_char = fra_idx_to_char[max_val_index]\n",
    "        \n",
    "        # Add generated character to the translated sentence so far\n",
    "        translated_sent += sampled_fra_char\n",
    "        \n",
    "        # If newline is encountered or maximum lenght of sentence is reached, stop\n",
    "        if ( (sampled_fra_char == '\\n') or (len(translated_sent) > max_len_fra_sent)) :\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Save current generated character for next iteration\n",
    "        target_seq = np.zeros((1, 1, len(french_vocab)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        # Save states for next iteration\n",
    "        states_val = [decoder_h, decoder_c]\n",
    "    \n",
    "    # Return translated sentence\n",
    "    return translated_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentence: Go.\n",
      "French sentence: Va !\n",
      "\n",
      "English sentence: Hi.\n",
      "French sentence: Salut !\n",
      "\n",
      "English sentence: Hi.\n",
      "French sentence: Salut !\n",
      "\n",
      "English sentence: Run!\n",
      "French sentence: Au feu !\n",
      "\n",
      "English sentence: Run!\n",
      "French sentence: Au feu !\n",
      "\n",
      "English sentence: Who?\n",
      "French sentence: Qh non !\n",
      "\n",
      "English sentence: Wow!\n",
      "French sentence: a alors!\n",
      "\n",
      "English sentence: Fire!\n",
      "French sentence: Au feu !\n",
      "\n",
      "English sentence: Help!\n",
      "French sentence:  l'aide!\n",
      "\n",
      "English sentence: Jump.\n",
      "French sentence: Attaquez !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 French sentences from inp_seq\n",
    "for seq_index in range(10):\n",
    "  \n",
    "    # Get next encoded english sentence\n",
    "    inp_seq = eng_input_data[seq_index:seq_index+1]\n",
    "    \n",
    "    # Get the translated sentence\n",
    "    translated_sent = translate_eng_sentence(inp_seq)\n",
    "    \n",
    "    # Print the original English sentence\n",
    "    print('English sentence:', english_sentences[seq_index])\n",
    "    \n",
    "    # Print the translated French sentence\n",
    "    print('French sentence:', translated_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model complexity can be increased to improve the model performance by\n",
    "    - increasing the number of hidden layers in the encoder\n",
    "    - increasing the number of hidden layers in the decoder\n",
    "    - increasing the number of nodes in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Natural Language Autocomplete Sentences\n",
    "-- Sequence to Sequence (seq2seq) Model\n",
    "    - sentence auto-completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "                       file                                            message\n",
      "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
      "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
      "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
      "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
      "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
     ]
    }
   ],
   "source": [
    "emails = pd.read_csv('C:/Users/himaj/OneDrive/Desktop/BUAN 6V99 - NLP/Project/DataCamp - Natural Language Generation in Python/Chapter4/emails.csv')\n",
    "data = emails[:100]\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_message(raw_message):\n",
    "    lines = raw_message.split('\\n')\n",
    "    email = {}\n",
    "    message = ''\n",
    "    keys_to_extract = ['from', 'to']\n",
    "    for line in lines:\n",
    "        if ':' not in line:\n",
    "            message += line.strip()\n",
    "            email['body'] = message\n",
    "        else:\n",
    "            pairs = line.split(':')\n",
    "            key = pairs[0].lower()\n",
    "            val = pairs[1].strip()\n",
    "            if key in keys_to_extract:\n",
    "                email[key] = val\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_list(emails, key):\n",
    "    results = []\n",
    "    for email in emails:\n",
    "        if key not in email:\n",
    "            results.append('')\n",
    "        else:\n",
    "            results.append(email[key])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_into_emails(messages):\n",
    "    emails = [parse_raw_message(message) for message in messages]\n",
    "    return {\n",
    "        'body': map_to_list(emails, 'body')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here is our forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Randy,Can you send me a schedule of the salary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0                               Here is our forecast\n",
       "1  Traveling to have a business meeting takes the...\n",
       "2                     test successful.  way to go!!!\n",
       "3  Randy,Can you send me a schedule of the salary...\n",
       "4                                                   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df = pd.DataFrame(parse_into_emails(data.message))\n",
    "email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here is our forecast',\n",
       " \"Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\",\n",
       " 'test successful.  way to go!!!',\n",
       " 'Randy,Can you send me a schedule of the salary and level of everyone in thescheduling group.  Plus your thoughts on any changes that need to be made.(Patti S for example)Phillip',\n",
       " '',\n",
       " 'Greg,How about either next Tuesday or Thursday?Phillip',\n",
       " 'Phillip Allen (pallen@enron.com)Mike Grigsby (mike.grigsby@enron.com)Keith Holst (kholst@enron.com)Monique SanchezFrank ErmisJohn LavoratoThank you for your helpPhillip Allen',\n",
       " '',\n",
       " \"I don't think these are required by the ISP2.  static IP address\",\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/16/2000Phillip,> As discussed  during our phone conversation, In a Parallon 75 microturbine> power generation deal for a national accounts customer, I am developing a> proposal to sell power to customer at fixed or collar/floor price. To do> so I need a corresponding term gas price for same. Microturbine is an> onsite generation product developed by Honeywell to generate electricity> on customer site (degen). using natural gas. In doing so,  I need your> best fixed price forward gas price deal for 1, 3, 5, 7 and 10 years for> annual/seasonal supply to microturbines to generate fixed kWh for> customer. We have the opportunity to sell customer kWh 's using> microturbine or sell them turbines themselves. kWh deal must have limited/> no risk forward gas price to make deal work. Therein comes Sempra energy> gas trading, truly you.>> We are proposing installing 180 - 240 units across a large number of> stores (60-100) in San Diego.> Store number varies because of installation hurdles face at small percent.>> Gas requirement for 180 microturbines 227 - 302 MMcf per year> Gas requirement for 240 microturbines 302 - 403 MMcf per year>> Gas will likely be consumed from May through September, during peak> electric period.> Need detail breakout of commodity and transport cost (firm or> interruptible).>> Should you have additional questions, give me a call.> Let me assure you, this is real deal!!>> Buck Buckner, P.E., MBA> Manager, Business Development and Planning> Big Box Retail Sales> Honeywell Power Systems, Inc.> 8725 Pan American Frwy> Albuquerque, NM 87113> 505-798-6424> 505-798-6050x> 505-220-4129> 888/501-3145>\",\n",
       " 'Mr. Buckner,For delivered gas behind San Diego, Enron Energy Services is the appropriateEnron entity.  I have forwarded your request to Zarin Imam at EES.  Her phonenumber is 713-853-7107.Phillip Allen',\n",
       " \"Lucy,Open them and save in the rentroll folder.  Follow these steps so you don'tmisplace these files.1.  Click on Save As4.  Click on the appropriate folderPhillip\",\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/09/2000Richard BurchfieldPhillip,Below is the issues & to do list as we go forward with documenting therequirements for consolidated physical/financial positions and transporttrade capture. What we need to focus on is the first bullet in Allan's list;the need for a single set of requirements. Although the meeting with Keith,on Wednesday,  was informative the solution of creating a infinitely dynamicconsolidated position screen, will be extremely difficult and timeconsuming.  Throughout the meeting on Wednesday, Keith alluded to theinability to get consensus amongst the traders on the presentation of theconsolidated position, so the solution was to make it so that a trader canarrange the position screen to their liking (much like Excel). What needs tohappen on Monday from 3 - 5 is a effort to design a desired layout for theconsolidated position screen, this is critical. This does not excludebuilding a capability to create a more flexible position presentation for thefuture, but in order to create a plan that can be measured we need firmrequirements. Also, to reiterate that the goals of this project is a projectplan on consolidate physical/financial positions and transport trade capture.The other issues that have been raised will be capture as projects on tothemselves, and will need to be prioritised as efforts outside of thisproject.I have been involved in most of the meetings and the discussions have beengood. I believe there has been good communication between the teams, but nowwe need to have focus on the objectives we set out to solve.Richard---------------------- Forwarded by Richard Burchfield/HOU/ECT on 10/06/2000Allan SeverudeMills/HOU/ECT@ECT, Kenny Ha/HOU/ECT@ECTFrom our initial set of meetings with the traders regarding consolidatedWe don't have a single point of contact from the trading group.  We've hadthree meetings which brought out very different issues from differenttraders.  We really need a single point of contact to help drive the traderrequirements and help come to a consensus regarding the requirements.We're getting hit with a lot of different requests, many of which appear tobe outside the scope of position consolidation.I think it may be useful to try to formulate a high level project goal tomake it as clear as possible what we're trying to accomplish with thisproject.  It'll help determine which requests fall under the project scope.Go through the list of requests to determine which are in scope for thisproject and which fall out of scope.For those in scope, work to define relative importance (priority) of each andwork with traders to define the exact requirements of each.drill downs.Use the above to formulate a project plan.Inclusion of Sitara physical deals into the TDS position manager and dealticker.Customized rows and columns in the position manager (ad hoc rows/columns thatadd up existing position manager rows/columns).transport, swaps, options, ...Addition of a curve tab to the position manager to show the real-time valuesof all curves on which the desk has a position.Ability to split the current position grid to allow daily positions to beshown directly above monthly positions.  Each grouped column in the top gridwould be tied to a grouped column in the bottom grid.Ability to properly show curve shift for float-for-float deals; determine theGas Daily for monthly index,Physical gas for Nymex,Physical gas for Inside Ferc,Physical gas for Mid market.Ability for TDS to pull valuation results based on a TDS flag instead ofusing official valuations.Position and P&L aggregation across all gas desks.Inclusion of spread options in our systems.  Ability to handle volatilityskew and correlations.Ability to revalue all options incrementally throughout the trading day.Approximate delta changes between valuations using instantaneous gamma or agamma grid.Valuation of Gas Daily options.A new position screen for options (months x strike x delta).  TBD.Inclusion of positions for exotic options currently managed in spreadsheets.Ability to isolate the position change due to changed deals in the positionmanager.Ability to view change deal P&L in the TDS deal ticker.  Show new deal terms,prior deal terms, and net P&L affect of the change.Eliminate change deals with no economic impact from the TDS deal ticker.Position drill down in the position manager to isolate the impact ofindividual deals on the position total in a grid cell.Benchmark positions in TDS.Deployment of TDS in Canada. Currency and volume uom conversions. Implicitand explicit position break out issues.-- Allan.transport.  Hopefully we'll know much better where that part stands at thatpoint.\",\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/09/2000Richard BurchfieldPhillip,Below is the issues & to do list as we go forward with documenting therequirements for consolidated physical/financial positions and transporttrade capture. What we need to focus on is the first bullet in Allan's list;the need for a single set of requirements. Although the meeting with Keith,on Wednesday,  was informative the solution of creating a infinitely dynamicconsolidated position screen, will be extremely difficult and timeconsuming.  Throughout the meeting on Wednesday, Keith alluded to theinability to get consensus amongst the traders on the presentation of theconsolidated position, so the solution was to make it so that a trader canarrange the position screen to their liking (much like Excel). What needs tohappen on Monday from 3 - 5 is a effort to design a desired layout for theconsolidated position screen, this is critical. This does not excludebuilding a capability to create a more flexible position presentation for thefuture, but in order to create a plan that can be measured we need firmrequirements. Also, to reiterate that the goals of this project is a projectplan on consolidate physical/financial positions and transport trade capture.The other issues that have been raised will be capture as projects on tothemselves, and will need to be prioritised as efforts outside of thisproject.I have been involved in most of the meetings and the discussions have beengood. I believe there has been good communication between the teams, but nowwe need to have focus on the objectives we set out to solve.Richard---------------------- Forwarded by Richard Burchfield/HOU/ECT on 10/06/2000Allan SeverudeMills/HOU/ECT@ECT, Kenny Ha/HOU/ECT@ECTFrom our initial set of meetings with the traders regarding consolidatedWe don't have a single point of contact from the trading group.  We've hadthree meetings which brought out very different issues from differenttraders.  We really need a single point of contact to help drive the traderrequirements and help come to a consensus regarding the requirements.We're getting hit with a lot of different requests, many of which appear tobe outside the scope of position consolidation.I think it may be useful to try to formulate a high level project goal tomake it as clear as possible what we're trying to accomplish with thisproject.  It'll help determine which requests fall under the project scope.Go through the list of requests to determine which are in scope for thisproject and which fall out of scope.For those in scope, work to define relative importance (priority) of each andwork with traders to define the exact requirements of each.drill downs.Use the above to formulate a project plan.Inclusion of Sitara physical deals into the TDS position manager and dealticker.Customized rows and columns in the position manager (ad hoc rows/columns thatadd up existing position manager rows/columns).transport, swaps, options, ...Addition of a curve tab to the position manager to show the real-time valuesof all curves on which the desk has a position.Ability to split the current position grid to allow daily positions to beshown directly above monthly positions.  Each grouped column in the top gridwould be tied to a grouped column in the bottom grid.Ability to properly show curve shift for float-for-float deals; determine theGas Daily for monthly index,Physical gas for Nymex,Physical gas for Inside Ferc,Physical gas for Mid market.Ability for TDS to pull valuation results based on a TDS flag instead ofusing official valuations.Position and P&L aggregation across all gas desks.Inclusion of spread options in our systems.  Ability to handle volatilityskew and correlations.Ability to revalue all options incrementally throughout the trading day.Approximate delta changes between valuations using instantaneous gamma or agamma grid.Valuation of Gas Daily options.A new position screen for options (months x strike x delta).  TBD.Inclusion of positions for exotic options currently managed in spreadsheets.Ability to isolate the position change due to changed deals in the positionmanager.Ability to view change deal P&L in the TDS deal ticker.  Show new deal terms,prior deal terms, and net P&L affect of the change.Eliminate change deals with no economic impact from the TDS deal ticker.Position drill down in the position manager to isolate the impact ofindividual deals on the position total in a grid cell.Benchmark positions in TDS.Deployment of TDS in Canada. Currency and volume uom conversions. Implicitand explicit position break out issues.-- Allan.transport.  Hopefully we'll know much better where that part stands at thatpoint.\",\n",
       " 'Dave,Here are the names of the west desk members by category.  The originationside is very sparse.Phillip',\n",
       " 'Paula,35 million is finePhillip',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/04/2000Enron North America Corp.Neal/HOU/ECT@ECT, John Arnold/HOU/ECT@ECT, Grant Masson/HOU/ECT@ECT, TedMurphy/HOU/ECT@ECT, Vladimir Gorny/HOU/ECT@ECT, Frank Hayden/Corp/Enron@EnronHarder/Corp/Enron@Enron, Kimberly Brown/HOU/ECT@ECT, AraceliRomero/NA/Enron@Enron, Kimberly Hillis/HOU/ECT@ectIf you have any questions/conflicts, please feel free to call me.Thanks,Rainx.31560',\n",
       " 'Tim,mike grigsby is having problems with accessing the west power site.  Can you please make sure he has an active password.Thank you,Phillip',\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/03/2000Please respond to <cbpres@austin.rr.com>WestgateEnclosed are demographics on the Westgate site from Investor's Alliance.Investor's Alliance says that these demographics are similar to the packageon San Marcos that you received earlier.If there are any other questions or information requirements, let me know.Then, let me know your interest level in the Westgate project?San MarcosThe property across the street from the Sagewood units in San Marcos is forsale and approved for 134 units.  The land is selling for $2.50 per squarefoot as it is one of only two remaining approved multifamily parcels in WestSan Marcos, which now has a moratorium on development.Several new studies we have looked at show that the rents for our duplexesand for these new units are going to be significantly higher, roughly $1.25per square foot if leased for the entire unit on a 12-month lease and$1.30-$1.40 psf if leased on a 12-month term, but by individual room.  Thisproperty will have the best location for student housing of all newprojects, just as the duplexes do now.If this project is of serious interest to you, please let me know as thereis a very, very short window of opportunity.  The equity requirement is notyet known, but it would be likely to be $300,000 to secure the land.  I willknow more on this question later today.Sincerely,George W. RichardsPresident, Creekside Builders, LLC- winmail.dat\",\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/03/2000Nancy Hall@ENRONLucci/NA/Enron@Enron, Paul Bieniawski/Corp/Enron@ENRON, TyrellHarrison/NA/Enron@EnronJackson/Corp/Enron@ENRONStorage Strategies in the West.  Please mark your calendars.Thank you!Regards,Nancy HallENA Denver office303-575-6490',\n",
       " 'Brenda,Please use the second check as the October payment.  If you have alreadytossed it, let me know so I can mail you another.Phillip',\n",
       " 'I think Fletch has a good CPA.  I am still doing my own.',\n",
       " 'Brenda,Please use the second check as my October payment.  I have my copy of theoriginal deal.  Do you want me to fax this to you?Phillip',\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/28/2000Liane,As we discussed yesterday, I am concerned there may have been an attempt tomanipulate the  El Paso San Juan monthly index.  It appears that a singlebuyer entered the marketplace on both September 26 and 27 and paid abovemarket prices ($4.70-$4.80) for San Juan gas.  At the time of these trades,offers for physical gas at significantly (10 to 15 cents) lower prices werebypassed in order to establish higher trades to report into the indexcalculation.  Additionally, these trades are out of line with the associatedfinancial swaps for San Juan.We have compiled a list of financial and physical trades executed fromSeptember 25 to September 27.  These are the complete list of trades fromEnron Online (EOL), Enron's direct phone conversations, and three brokeragefirms (Amerex, APB, and Prebon).  Please see the attached spreadsheet for atrade by trade list and a summary.  We have also included a summary of gasdaily prices to illustrate the value of San Juan based on several spread1.  The high physical prices on the 26th & 27th (4.75,4,80) are much greaterthan the high financial trades (4.6375,4.665) on those days.2.  The spread relationship between San Juan and other points (Socal &Northwest)  is  consistent between the end of September andOctober gas daily.  It doesn't make sense to have monthly indices thatare dramatically different.I understand you review the trades submitted for outliers.  Hopefully, thetrades submitted will reveal counterparty names and you will be able todetermine that there was only one buyer in the 4.70's and these trades areoutliers.  I wanted to give you some additional points of reference to aid inestablishing a reasonable index.  It is Enron's belief that the trades at$4.70 and higher  were above market trades that should be excluded from thecalculation of index.It is our desire to have reliable and accurate indices against which toconduct our physical and financial business.  Please contact meanytime I can assist you towards this goal.Sincerely,Phillip Allen\",\n",
       " \"Liane,As we discussed yesterday, I am concerned there has been an attempt tomanipulate the  El Paso San Juan monthly index.  A single buyer entered themarketplace on both September 26 and 27 and paid above market prices($4.70-$4.80) for San Juan gas with the intent to distort the index.  At thetime of these trades, offers for physical gas at significantly (10 to 15cents) lower prices were bypassed in order to establish higher trades toreport into the index calculation.  Additionally, these trades are out ofline with the associated financial swaps for San Juan.We have compiled a list of financial and physical trades executed fromSeptember 25 to September 27.  These are the complete list of trades fromEnron Online (EOL), Enron's direct phone conversations, and three brokeragefirms (Amerex, APB, and Prebon).  Please see the attached spreadsheet for atrade by trade list and a summary.  We have also included a summary of gasdaily prices to illustrate the value of San Juan based on several spread1.  The high physical prices on the 26th & 27th (4.75,4,80) are much greaterthan the high financial trades (4.6375,4.665) on those days.2.  The spread relationship between San Juan and other points (Socal &Northwest)  is  consistent between the end of September andOctober gas daily.  It doesn't make sense to have monthly indeces thatare dramatically different.I understand you review the trades submitted for outliers.  Hopefully, thetrades submitted will reveal counterparty names and you will be able todetermine that there was only one buyer in the 4.70's and these trades areoutliers.  I wanted to give you some additional points of reference to aid inestablishing a reasonable index.  It is Enron's belief that the trades at$4.70 and higher  were above market trades that should be excluded from thecalculation of index.It is our desire to have reliable and accurate indeces against which toconduct our physical and financial business.  Please contact meanytime I can assist you towards this goal.Sincerely,Phillip Allen\",\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000Please respond to <cbpres@austin.rr.com><clclegal2@aol.com>Typically the structure is a limited partnership with a corporate (or LLC)general partner.  The General Partner owns 1% of the project and carries theliability of construction.LAND OWNERSHIP & LOANSThe property would be purchased in the name of the limited partnership andany land loans, land improvements loans and construction loans would be inthe name of the limited partnership.  Each of the individual investors andall of the principals in Creekside would also personally guarantee theloans.  If the investor(s) do not sign on the loans, this generally meansthat a larger amount of cash is required and the investor\\'s share of profitsis reduced.All loans for residential construction, that are intended for re-sale, arefull recourse loans.  If we are pursuing multifamily rental developments,the construction loans are still full recourse but the mortgage can often benon-recourse.USE OF INITIAL INVESTMENTThe initial investment is used for land deposit, engineering &architectural design, soils tests, surveys, filing fees, legal fees fororganization and condominium association formation,  and appraisals.  Unlikemany real estate investment programs, none of the funds are used for fees toCreekside Builders, LLC.  These professional expenses will be incurred overthe estimated 6 month design and approval period.EARLY LAND COSTSThe $4,000 per month costs listed in the cash flow as part of land costrepresent the extension fees due to the seller for up to 4 months ofextensions on closing.  As an alternative, we can close into a land loan atprobably 70% of appraised value.  With a land value equal to the purchaseprice of $680,000 this would mean a land loan of $476,000 with estimatedmonthly interest payments of $3,966, given a 10% annual interest rate, plusapproximately 1.25% of the loan amount for closing costs and loan fees.EQUITY AT IMPROVEMENT LOANOnce the site plan is approved by the City of Austin, the City will requirethe development entity to post funds for fiscal improvements, referred to asthe \"fiscals\".  This cost represents a bond for the completion ofimprovements that COA considers vital and these funds are released once theimprovements have been completed and accepted by COA.  This release will befor 90% of the cost with the remaining 10% released one year aftercompletion.  Releases can be granted once every 90 days and you shouldexpect that the release would occur 6 months after the start of lotimprovement construction.  These fiscals are usually posted in cash or anirrevocable letter of credit.  As such, they have to be counted as adevelopment cost, even though they are not spent.  Because they are notspent no interest is charged on these funds.The lot improvement loan is typically 75% of the appraised value of afinished lot, which I suspect will be at least $20,000 and potentially ashigh as $25,000.  This would produce a loan amount of  $15,000 on $20,000per lot.  With estimated per lot improvement costs of $9,000, \\'fiscals\\' at$2,000 and the land cost at $8,000 , total improved lot cost is $19,000which means $0 to $4,000 per lot in total equity.  The investment prior toobtaining the improvement loan would count towards any equity requirementprovided it was for direct costs.  Thus, the additional equity for theimprovement loan would be $0-$184,000.   Even if the maximum loan wouldcover all costs, it is unlikely the bank would allow reimbursement of fundsspent. The higher estimates of equity investments are shown in thepreliminary proforma to be on the safe side.  The engineer is preparing atentative site layout with an initial evaluation of the phasing, which cansignificantly reduce the cash equity requirement.Phasing works as follows.  If the first phase was say 40 units, the totallot improvement cost might average $31,000 per lot.   Of this, probably$13,000 would be for improvements and $19,000 for the land cost.  Theimprovements are higher to cover large one time up front costs for designcosts, the entry road, water treatment costs, perimeter fencing andlandscaping, and so on, as well as for 100% of the land.  The land loan forundeveloped lots would be 70% of the appraised raw lot value, which I wouldestimate as $10,000 per lot for a loan value of $7,000 per lot.  Then theloan value for each improved lot would be $15,000 per lot.  This would giveyou a total loan of $992,000, total cost of $1,232,645 for equity requiredof $241,000.  This was not presented in the initial analysis as the phasingis depended on a more careful assessment by the Civil Engineer as theseparate phases must each be able to stand on its own from a utilitystandpoint.CONSTRUCTION LOANSThere are three types of  construction loans.  First, is a speculative(spec) loan that is taken out prior to any pre-sales activity.  Second,  isa construction loan for a pre-sold unit, but the loan remains in thebuilder/developers name.  Third, is a pre-sold unit with the constructionloan in the name of the buyer.  We expect to have up to 8 spec loans tostart the project and expect all other loans to be pre-sold units with loansin the name of the builder/developer.  We do not expect to have anyconstruction loans in the name of the buyers, as such loans are toodifficult to manage and please new buyers unfamiliar with the process.Spec loans will be for 70% to 75% of value and construction loans forpre-sold units, if the construction loan is from the mortgage lender,  willbe from 80% to 95% of value.DISBURSEMENTSDisbursements will be handled by the General Partner to cover current andnear term third party costs, then to necessary reserves, then to prioritypayments and then to the partners per the agreement.  The General Partnerwill contract with Creekside Builders, LLC to construct the units and thefee to CB will include a construction management and overhead fee equal to15% of the direct hard cost excluding land, financing and sales costs.These fees are the only monies to Creekside, Larry Lewter or myself prior tocalculation of profit, except for a) direct reimbursement for partnershipexpenses and b) direct payment to CB for any subcontractor costs that it hasto perform.  For example, if CB cannot find a good trim carpenter sub, orcannot find enough trim carpenters, etc., and it decides to undertake thisfunction, it will charge the partnership the same fee it was able to obtainfrom third parties and will disclose those cases to the partnership.Finally, CB will receive a fee for the use of any of its equipment if it isused in lieu of leasing equipment from others.  At present CB does not ownany significant equipment, but it is considering the purchase of a sky trackto facilitate and speed up framing, cornice, roofing and drywall spreading.REPORTINGWe are more than willing to provide reports to track expenses vs. plan.What did you have in mind?  I would like to use some form of internet basedreporting.BOOKKEEPINGI am not sure what you are referring to by the question, \"Bookkeepingprocedures to record actual expenses?\"  Please expand.INVESTOR INPUTWe are glad to have the investor\\'s input on design and materials.  As alwaysthe question will be who has final say if there is disagreement, but in myexperience I have always been able to reach consensus. As you, and I presumeKeith, want to be involved to learn as much as possible we would make everyeffort to be accommodating.CREEKSIDE PROCEEDURESCB procedures for dealing with subs, vendors and professionals is not asformal as your question indicates.  In the EXTREMELY tight labor marketobtaining 3 bids for each labor trade is not feasible.  For the professionalsubs we use those with whom we have developed a previous rapport.  Finally,for vendors they are constantly shopped.PRE-SELECTED PROFESSIONALS, SUBS AND VENDORSYes there are many different subs that have been identified and I canprovide these if you are interested.I know I have not answered everything, but this is a starting point.  Callwhen you have reviewed and we can discuss further.Sincerely,George RichardsPresident, Creekside Builders, LLC- winmail.dat',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000Please respond to <cbpres@austin.rr.com><clclegal2@aol.com>Typically the structure is a limited partnership with a corporate (or LLC)general partner.  The General Partner owns 1% of the project and carries theliability of construction.LAND OWNERSHIP & LOANSThe property would be purchased in the name of the limited partnership andany land loans, land improvements loans and construction loans would be inthe name of the limited partnership.  Each of the individual investors andall of the principals in Creekside would also personally guarantee theloans.  If the investor(s) do not sign on the loans, this generally meansthat a larger amount of cash is required and the investor\\'s share of profitsis reduced.All loans for residential construction, that are intended for re-sale, arefull recourse loans.  If we are pursuing multifamily rental developments,the construction loans are still full recourse but the mortgage can often benon-recourse.USE OF INITIAL INVESTMENTThe initial investment is used for land deposit, engineering &architectural design, soils tests, surveys, filing fees, legal fees fororganization and condominium association formation,  and appraisals.  Unlikemany real estate investment programs, none of the funds are used for fees toCreekside Builders, LLC.  These professional expenses will be incurred overthe estimated 6 month design and approval period.EARLY LAND COSTSThe $4,000 per month costs listed in the cash flow as part of land costrepresent the extension fees due to the seller for up to 4 months ofextensions on closing.  As an alternative, we can close into a land loan atprobably 70% of appraised value.  With a land value equal to the purchaseprice of $680,000 this would mean a land loan of $476,000 with estimatedmonthly interest payments of $3,966, given a 10% annual interest rate, plusapproximately 1.25% of the loan amount for closing costs and loan fees.EQUITY AT IMPROVEMENT LOANOnce the site plan is approved by the City of Austin, the City will requirethe development entity to post funds for fiscal improvements, referred to asthe \"fiscals\".  This cost represents a bond for the completion ofimprovements that COA considers vital and these funds are released once theimprovements have been completed and accepted by COA.  This release will befor 90% of the cost with the remaining 10% released one year aftercompletion.  Releases can be granted once every 90 days and you shouldexpect that the release would occur 6 months after the start of lotimprovement construction.  These fiscals are usually posted in cash or anirrevocable letter of credit.  As such, they have to be counted as adevelopment cost, even though they are not spent.  Because they are notspent no interest is charged on these funds.The lot improvement loan is typically 75% of the appraised value of afinished lot, which I suspect will be at least $20,000 and potentially ashigh as $25,000.  This would produce a loan amount of  $15,000 on $20,000per lot.  With estimated per lot improvement costs of $9,000, \\'fiscals\\' at$2,000 and the land cost at $8,000 , total improved lot cost is $19,000which means $0 to $4,000 per lot in total equity.  The investment prior toobtaining the improvement loan would count towards any equity requirementprovided it was for direct costs.  Thus, the additional equity for theimprovement loan would be $0-$184,000.   Even if the maximum loan wouldcover all costs, it is unlikely the bank would allow reimbursement of fundsspent. The higher estimates of equity investments are shown in thepreliminary proforma to be on the safe side.  The engineer is preparing atentative site layout with an initial evaluation of the phasing, which cansignificantly reduce the cash equity requirement.Phasing works as follows.  If the first phase was say 40 units, the totallot improvement cost might average $31,000 per lot.   Of this, probably$13,000 would be for improvements and $19,000 for the land cost.  Theimprovements are higher to cover large one time up front costs for designcosts, the entry road, water treatment costs, perimeter fencing andlandscaping, and so on, as well as for 100% of the land.  The land loan forundeveloped lots would be 70% of the appraised raw lot value, which I wouldestimate as $10,000 per lot for a loan value of $7,000 per lot.  Then theloan value for each improved lot would be $15,000 per lot.  This would giveyou a total loan of $992,000, total cost of $1,232,645 for equity requiredof $241,000.  This was not presented in the initial analysis as the phasingis depended on a more careful assessment by the Civil Engineer as theseparate phases must each be able to stand on its own from a utilitystandpoint.CONSTRUCTION LOANSThere are three types of  construction loans.  First, is a speculative(spec) loan that is taken out prior to any pre-sales activity.  Second,  isa construction loan for a pre-sold unit, but the loan remains in thebuilder/developers name.  Third, is a pre-sold unit with the constructionloan in the name of the buyer.  We expect to have up to 8 spec loans tostart the project and expect all other loans to be pre-sold units with loansin the name of the builder/developer.  We do not expect to have anyconstruction loans in the name of the buyers, as such loans are toodifficult to manage and please new buyers unfamiliar with the process.Spec loans will be for 70% to 75% of value and construction loans forpre-sold units, if the construction loan is from the mortgage lender,  willbe from 80% to 95% of value.DISBURSEMENTSDisbursements will be handled by the General Partner to cover current andnear term third party costs, then to necessary reserves, then to prioritypayments and then to the partners per the agreement.  The General Partnerwill contract with Creekside Builders, LLC to construct the units and thefee to CB will include a construction management and overhead fee equal to15% of the direct hard cost excluding land, financing and sales costs.These fees are the only monies to Creekside, Larry Lewter or myself prior tocalculation of profit, except for a) direct reimbursement for partnershipexpenses and b) direct payment to CB for any subcontractor costs that it hasto perform.  For example, if CB cannot find a good trim carpenter sub, orcannot find enough trim carpenters, etc., and it decides to undertake thisfunction, it will charge the partnership the same fee it was able to obtainfrom third parties and will disclose those cases to the partnership.Finally, CB will receive a fee for the use of any of its equipment if it isused in lieu of leasing equipment from others.  At present CB does not ownany significant equipment, but it is considering the purchase of a sky trackto facilitate and speed up framing, cornice, roofing and drywall spreading.REPORTINGWe are more than willing to provide reports to track expenses vs. plan.What did you have in mind?  I would like to use some form of internet basedreporting.BOOKKEEPINGI am not sure what you are referring to by the question, \"Bookkeepingprocedures to record actual expenses?\"  Please expand.INVESTOR INPUTWe are glad to have the investor\\'s input on design and materials.  As alwaysthe question will be who has final say if there is disagreement, but in myexperience I have always been able to reach consensus. As you, and I presumeKeith, want to be involved to learn as much as possible we would make everyeffort to be accommodating.CREEKSIDE PROCEEDURESCB procedures for dealing with subs, vendors and professionals is not asformal as your question indicates.  In the EXTREMELY tight labor marketobtaining 3 bids for each labor trade is not feasible.  For the professionalsubs we use those with whom we have developed a previous rapport.  Finally,for vendors they are constantly shopped.PRE-SELECTED PROFESSIONALS, SUBS AND VENDORSYes there are many different subs that have been identified and I canprovide these if you are interested.I know I have not answered everything, but this is a starting point.  Callwhen you have reviewed and we can discuss further.Sincerely,George RichardsPresident, Creekside Builders, LLC- winmail.dat',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000RescheduleThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Fletcher J Sturm/HOU/ECTScott Neal/HOU/ECTHunter S Shively/HOU/ECTPhillip K Allen/HOU/ECTAllan Severude/HOU/ECTScott Mills/HOU/ECTRuss Severson/HOU/ECT---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000ConfirmationThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Fletcher J Sturm/HOU/ECTScott Neal/HOU/ECTHunter S Shively/HOU/ECTPhillip K Allen/HOU/ECTAllan Severude/HOU/ECTScott Mills/HOU/ECTRuss Severson/HOU/ECTFletcher J Sturm -> No ResponseScott Neal -> No ResponseHunter S Shively -> No ResponsePhillip K Allen -> No ResponseAllan Severude -> AcceptedScott Mills -> AcceptedRuss Severson -> No Response---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000RescheduleThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Phillip K Allen/HOU/ECT@ECTHunter S Shively/HOU/ECT@ECTScott Mills/HOU/ECT@ECTAllan Severude/HOU/ECT@ECTJeffrey C Gossett/HOU/ECT@ECTColleen Sullivan/HOU/ECT@ECTRuss Severson/HOU/ECT@ECTJayant Krishnaswamy/HOU/ECT@ECTRussell Long/HOU/ECT@ECT---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000ConfirmationThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Phillip K Allen/HOU/ECT@ECTHunter S Shively/HOU/ECT@ECTScott Mills/HOU/ECT@ECTAllan Severude/HOU/ECT@ECTJeffrey C Gossett/HOU/ECT@ECTColleen Sullivan/HOU/ECT@ECTRuss Severson/HOU/ECT@ECTJayant Krishnaswamy/HOU/ECT@ECTRussell Long/HOU/ECT@ECTPhillip K Allen -> No ResponseHunter S Shively -> No ResponseScott Mills -> No ResponseAllan Severude -> AcceptedJeffrey C Gossett -> AcceptedColleen Sullivan -> No ResponseRuss Severson -> No ResponseJayant Krishnaswamy -> AcceptedRussell Long -> Accepted---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000RescheduleThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Fletcher J Sturm/HOU/ECTScott Neal/HOU/ECTHunter S Shively/HOU/ECTPhillip K Allen/HOU/ECTAllan Severude/HOU/ECTScott Mills/HOU/ECTRuss Severson/HOU/ECT---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000ConfirmationThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Fletcher J Sturm/HOU/ECTScott Neal/HOU/ECTHunter S Shively/HOU/ECTPhillip K Allen/HOU/ECTAllan Severude/HOU/ECTScott Mills/HOU/ECTRuss Severson/HOU/ECTFletcher J Sturm -> No ResponseScott Neal -> No ResponseHunter S Shively -> No ResponsePhillip K Allen -> No ResponseAllan Severude -> AcceptedScott Mills -> AcceptedRuss Severson -> Accepted---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000Mills/HOU/ECT@ECT, Allan Severude/HOU/ECT@ECT, Jeffrey C Gossett/HOU/ECT@ECT,Colleen Sullivan/HOU/ECT@ECT, Russ Severson/HOU/ECT@ECT, JayantKrishnaswamy/HOU/ECT@ECT, Russell Long/HOU/ECT@ECTconfirmation to each of you via Lotus Notes.  Sorry for all of the changesbut there was a scheduling problem with a couple of people for the originaltime slot.',\n",
       " 'Reagan,Just wanted to give you an update.  I have changed the unit mix to include some 1 bedrooms and reduced the number of buildings to 12.  Kipp Flores is working on the construction drawings.  At the same time I am pursuing FHA financing.  Once the construction drawings are complete I will send them to you for a revised bid.  Your original bid was competitive and I am still attracted to your firm because of your strong local presence and contacts.Phillip',\n",
       " 'Nymex expiration is during this time frame.  Please reschedule.',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000InvitationThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Phillip K Allen/HOU/ECTHunter S Shively/HOU/ECTScott Mills/HOU/ECTAllan Severude/HOU/ECTJeffrey C Gossett/HOU/ECTColleen Sullivan/HOU/ECTRuss Severson/HOU/ECTJayant Krishnaswamy/HOU/ECTRussell Long/HOU/ECT',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000Mills/HOU/ECT@ECT, Allan Severude/HOU/ECT@ECT, Russ Severson/HOU/ECT@ECT,Fletcher J Sturm/HOU/ECT@ECT, Scott Neal/HOU/ECT@ECTI have scheduled and entered on each of your calendars a meeting for the',\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000Jeff,?Is the closing today?? After reviewing the  agreement?I find it isn't bindingas far as I can determine.? It is  too vague and it doesn't sound likeanything an attorney or title company  would?draft for a real estateclosing--but, of course, I could be  wrong.??If this?closing is going to take place without  this agreement then there isno point in me  following up on this?document's validity.??I will just need to go back to my closing documents  and see what's there andfind out where I am with that and deal with this as  best I can.?I guess I was expecting something that would be an  exhibit to a recordabledocument or something a little more exact, or  rather?sort of a contract.?This isn't either.? I tried to get a  real estate atty on the phone lastnight but he was out of pocket.? I  talked to a crim. atty friend and he saidthis is out of his area but doesn't  sound binding to him.??I will go back to mine and Phillip Allen's  transaction?and take a look atthat but as vague and general as this is I  doubt that my signature? is evenneeded to complete this transaction.?  I am in after 12 noon if there is anyneed to contact me regarding the  closing.?I really do not want to hold up anything or  generate more work for myselfand I don't want to insult or annoy anyone but  this paper really doesn'tseem to be something required for a closing.? In  the event you do need mysignature on something like this I would rather have  time to have itreviewed before I accept it.?Brenda??\",\n",
       " 'Chris,What is the latest with PG&E?  We have been having good discussionsregarding EOL.Call me when you can. X37041Phillip',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/25/2000RescheduleThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Fletcher J Sturm/HOU/ECTScott Neal/HOU/ECTHunter S Shively/HOU/ECTPhillip K Allen/HOU/ECTAllan Severude/HOU/ECTScott Mills/HOU/ECTRuss Severson/HOU/ECTThe meeting with Richard Burchfield/HOU/ECT was rescheduled.For   1 hourFletcher J Sturm/HOU/ECT (Invited)Scott Neal/HOU/ECT (Invited)Hunter S Shively/HOU/ECT (Invited)Phillip K Allen/HOU/ECT (Invited)Allan Severude/HOU/ECT (Invited)Scott Mills/HOU/ECT (Invited)Russ Severson/HOU/ECT (Invited)Gas Physical/Financail Positions - Room 2537',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/25/2000InvitationThis meeting repeats   starting on    (if the date occurs on a weekend themeeting ).Fletcher J Sturm/HOU/ECTScott Neal/HOU/ECTHunter S Shively/HOU/ECTPhillip K Allen/HOU/ECTAllan Severude/HOU/ECTScott Mills/HOU/ECTRuss Severson/HOU/ECT',\n",
       " 'Greg,Happy B-day. Email me your phone # and I will call you.Keith',\n",
       " 'Kathy,Regarding the guest password for gas daily, can you please relay theinformation to Mike Grigsby at 37031 so he can pass it along to the user atgas daily today.  I will be out of the office on Friday.thank youPhillip',\n",
       " \"John,Denver's short rockies position  beyond 2002 is created by their Trailblazertransport.  They are unhedged 15,000/d in 2003 and 25,000/d in 2004 and2005.They are scrubbing all their books and booking the Hubert deal on Wednesdayand Thursday.Phillip\",\n",
       " 'Jim,Is there going to be a conference call or some type of weekly meeting about all the regulatory issues facing California this week?  Can you make sure the gas desk is included.Phillip',\n",
       " 'George,Below is a list of questions that Keith and I had regarding the WestgateOwnership StructureWhat will be the ownership structure? Limited partnership? General partner?What are all the legal entities that will be involved and in whatcapacity(regarding ownership andliabilities)?Who owns the land? improvements?Who holds the various loans?Is the land collateral?InvestmentWhat happens to initial investment?Is it used to purchase land for cash?Secure future loans?Why is the land cost spread out on the cash flow statement?When is the 700,000 actually needed? Now or for the land closing? Investmentschedule?Investment ReturnIs Equity Repayment the return of the original investment?Is the plan to wait until the last unit is sold and closed before profitsare distributed?DebtWhich entity is the borrower for each loan and what recourse or collateralis associated with eachloan?ImprovementConstructionAre these the only two loans?  Looks like it from the cash flow statement.Terms of each loan?Uses of FundsHow will disbursements be made?  By whom?What type of bank account?  Controls on max disbursement? Internet viewingfor investors?Reports to track expenses vs plan?Bookkeeping procedures to record actual expenses?What is the relationship of Creekside Builders to the project?  Do you getpaid a markup on subcontractors as ageneral contractor and paid gain out of profits?Do you or Larry receive any money in the form of salary or personal expensesbefore the ultimate payout of profits?Design and ConstructionWhen will design be complete?What input will investors have in selecting design and materials for units?What level of investor involvement will be possible during constructionplanning and permitting?Does Creekside have specific procedures for dealing with subcontractors,vendors, and other professionals?Such as always getting 3 bids, payment schedules, or reference checking?Are there any specific companies or individuals that you already plan touse? Names?These questions are probably very basic to you, but as a first time investorin a project like this it is new to me.  Also, I want to learn asmuch as possible from the process.Phillip',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/19/2000Please respond to <cbpres@austin.rr.com>Enclosed is the preliminary proforma for the Westgate property is Austinthat we told you about.  As you can tell from the proforma this projectshould produce a truly exceptional return of over 40% per year over 3 years.This is especially attractive when the project is in a market as strong asAustin and we are introducing new product that in a very low price range forthis market.  This is the best project in terms of risk and reward that wehave uncovered to date in the Austin market.The project does have approved zoning and will only require a site plan.  Asit is in the \"Smart Growth Corridor\" area designated by the City of Austinfor preferred development, this will be fast tracked and should be completein less than 6 months.  Additionally, many of the current and more severewater treatment ordinances have been waived.  I have estimated the lotimprovement costs based on a 28 lot development we investigated in NorthAustin, which included a detention/retention and filtration pond and streetwidening.  Even though this property is not likely to require streetwidening and will have less of a detention/retention and filtration pondrequirement, I used this data to be cautious.The Lone Star gas line easement in the lower portion of the property is notexpected to impact sales significantly.  Other projects have been quitesuccessful with identical relationships to this pipeline, such as theadjoining single family residential and a project at St. Edwards University.As with most infill projects, the quality of the surrounding neighborhoodsis uneven.  We have included a fence around the entire property, but mayonly put it on Westgate and Cameron Loop.  Gated communities are farpreferred so this is a good idea for both screening and current buyerpreferences.The seller accepted our offer Thursday evening with a price of $680,000 andan extended escrow.  This will enable us to probably obtain an approved siteplan before closing on the contract, which will mean that we can close intoan A&D Loan rather than into a land loan and then an improvement loan.This analysis shows your investment at $700,000 for a 50% interest in theprofits of the project.  As we discussed in San Marcos, we can also discusshaving you invest only in the lots, sell the lots to the construction entitywith your profit in the lot.  I believe this would facilitate the use of a1031 Exchange of the proceeds from this deal into another project that is arental deal or at least into the land for a rental project that would thenbe the equity for that project.  You would need to discuss this with anexchange expert first.  Larry Lewter knows an expert in the field in SanAntonio if you do not know anyone.I will send you a package on the property that was prepared by the broker,by Airborne Express today for Saturday delivery.Once you have read the package and reviewed this proforma, we would want toschedule a tour of the site and the area.  Please get back to me as soon asyour schedule permits regarding the site visit and feel free to call at anytime.  You can reach me over the weekend and in the evening at either512-338-1119 or 512-338-1110.  My cell phone is 512-748-7495 and the fax is512-338-1103.   I look forward to hearing from you and to working with youon this project that is sure to be a major winner.I regret that it took so long to get back to you, but we had some unusualevents these past few weeks.  A small freakish wind storm with severe 60+mpgdowndrafts hit the South part of Austin where we are building 10 town homes.One of these units had just had the roof decked with the siding scheduled tostart the next day.  The severe downdraft hitting the decked roof was enoughto knock it down.  The City shut down the project for a week and it tookanother week to get every thing back on tract.  Then last week I had to takemy wife  to emergency.  She has a bulge in the material between the vertebrain her spine and it causes her extreme pain and has kept her bedridden thispast week..  There is nothing like having your wife incapacitated to realizethe enormous number of things she does everyday.   Fortunately, it looks asif she will be ok in the long run.George W. RichardsCreekside Builders, LLC- Westgate Proforma-Phillip Allen.xls',\n",
       " 'George,As you can see his units sold at a variety of prices per square foot.  The1308/1308 model seems to have the most data and looks most similiar to theunits you are selling.  At  2.7 MM, my bid is .70/sf higher than his unitsunder construction.  I am having a hard time justifying paying much more withcompetition on the way.  The price I am bidding is higher than any dealsactually done to date.Let me know what you think.  I will follow up with an email and phone callabout Cherry Creek.  I am sure Deborah Yates let you know that the bid wasrejected on the De Ville property.Phillip Allen',\n",
       " 'Jeff,What is up with Burnet?Phillip',\n",
       " 'Jeff,I need to see the site plan for Burnet.  Remember I must get writtenapproval from Brenda Key Stone before I can sell this property and she hasconcerns about the way the property will be subdivided.    I would also liketo review the closing statements as soon as possible.Phillip',\n",
       " 'Lucy,I want to have an accurate rent roll as soon as possible. I faxed you a copyof this file.  You can fill in on the computer or just write in the correctamounts and I will input.',\n",
       " 'Brenda,I checked my records and I mailed check #1178 for the normal amount onAugust 28th.  I mailed it to 4303 Pate Rd. #29, College Station, TX 77845.  Iwill go ahead and mail you another check.  If the first one shows up you cantreat the 2nd as payment for October.I know your concerns about the site plan.  I will not proceed withoutgetting the details and getting your approval.I will find that amortization schedule and send it soon.Phillip',\n",
       " \"Lucy,You wrote fewer checks this month.  Spent more money on Materials and less onLabor.June  July  AugustTotal Materials  2929  4085  4801Services  53  581  464Labor   3187  3428  27701.  Check 1406  Walmart    Description and unit?2.  Check 1410  Crumps     Detail description and unit?3.  Check 1411  Lucy      What is this?4.  Check 1415  Papes      Detail description and units?5.  Checks 1416, 1417, and 1425  Why overtime?6.  Check 1428    Ralph's   What unit?7.  Check 1438    Walmart?    Description and unit?Try and pull together the support for these items and get back to me.Phillip\",\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/12/2000Michael EtringerPhillip,Attached is the list.  Have your people fill in the columns highlighted inyellow.  As best can we will try not to overlap on accounts.Thanks, Mike',\n",
       " '',\n",
       " \"Ina Rangel-What type of computer do you have?  (Desktop,  Laptop,  Both)  BothDo you have permission to access anyone's Email/Calendar?  NOIf yes, who?Does anyone have permission to access your Email/Calendar?  YESIf yes, who?  INA RANGELAre you responsible for updating anyone else's address book?If yes, who?  NOIs anyone else responsible for updating your address book?If yes, who?  NODo you have access to a shared calendar?If yes, which shared calendar?  YES, West CalendarDo you have any Distribution Groups that Messaging maintains for you (for mass mailings)?Will you be out of the office in the near future for vacation, leave, etc? NO<Embedded StdOleLink>\",\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/11/2000Please respond to <cbpres@austin.rr.com>Enclosed is the preliminary proforma for the Westgate property is Austinthat we told you about.  As you can tell from the proforma this projectshould produce a truly exceptional return of over 40% per year over 3 years.This is especially attractive when the project is in a market as strong asAustin and we are introducing new product that in a very low price range forthis market.  This is the best project in terms of risk and reward that wehave uncovered to date in the Austin market.The project does have approved zoning and will only require a site plan.  Asit is in the \"Smart Growth Corridor\" area designated by the City of Austinfor preferred development, this will be fast tracked and should be completein less than 6 months.  Additionally, many of the current and more severewater treatment ordinances have been waived.  I have estimated the lotimprovement costs based on a 28 lot development we investigated in NorthAustin, which included a detention/retention and filtration pond and streetwidening.  Even though this property is not likely to require streetwidening and will have less of a detention/retention and filtration pondrequirement, I used this data to be cautious.The Lone Star gas line easement in the lower portion of the property is notexpected to impact sales significantly.  Other projects have been quitesuccessful with identical relationships to this pipeline, such as theadjoining single family residential and a project at St. Edwards University.As with most infill projects, the quality of the surrounding neighborhoodsis uneven.  We have included a fence around the entire property, but mayonly put it on Westgate and Cameron Loop.  Gated communities are farpreferred so this is a good idea for both screening and current buyerpreferences.The seller accepted our offer Thursday evening with a price of $680,000 andan extended escrow.  This will enable us to probably obtain an approved siteplan before closing on the contract, which will mean that we can close intoan A&D Loan rather than into a land loan and then an improvement loan.This analysis shows your investment at $700,000 for a 50% interest in theprofits of the project.  As we discussed in San Marcos, we can also discusshaving you invest only in the lots, sell the lots to the construction entitywith your profit in the lot.  I believe this would facilitate the use of a1031 Exchange of the proceeds from this deal into another project that is arental deal or at least into the land for a rental project that would thenbe the equity for that project.  You would need to discuss this with anexchange expert first.  Larry Lewter knows an expert in the field in SanAntonio if you do not know anyone.I will send you a package on the property that was prepared by the broker,by Airborne Express today for Saturday delivery.Once you have read the package and reviewed this proforma, we would want toschedule a tour of the site and the area.  Please get back to me as soon asyour schedule permits regarding the site visit and feel free to call at anytime.  You can reach me over the weekend and in the evening at either512-338-1119 or 512-338-1110.  My cell phone is 512-748-7495 and the fax is512-338-1103.   I look forward to hearing from you and to working with youon this project that is sure to be a major winner.I regret that it took so long to get back to you, but we had some unusualevents these past few weeks.  A small freakish wind storm with severe 60+mpgdowndrafts hit the South part of Austin where we are building 10 town homes.One of these units had just had the roof decked with the siding scheduled tostart the next day.  The severe downdraft hitting the decked roof was enoughto knock it down.  The City shut down the project for a week and it tookanother week to get every thing back on tract.  Then last week I had to takemy wife  to emergency.  She has a bulge in the material between the vertebrain her spine and it causes her extreme pain and has kept her bedridden thispast week..  There is nothing like having your wife incapacitated to realizethe enormous number of things she does everyday.   Fortunately, it looks asif she will be ok in the long run.George W. RichardsCreekside Builders, LLC- Westgate Proforma-Phillip Allen.xls',\n",
       " 'Jeff,I received the rent roll.  I am going to be in San Marcos this weekend but Iam booked with stage coach.  I will drive by Friday evening.I will let you know next week if I need to see the inside.  Can you find outwhen Chelsea Villa last changed hands and for what price?What about getting a look at the site plans for the Burnet deal.  Rememberwe have to get Brenda happy.Phillip',\n",
       " '9/8  9/7  diffSocal  36,600  37,200  -600NWPL  -51,000  -51,250  250San Juan -32,500  -32,000  -500The reason the benchmark report shows net selling San Juan is that thetransport positions were rolled in on 9/8.  This added 800 shorts to San Juanand 200 longs to Socal.  Before this adjustment we bought 300 San Juan andsold 800 Socal.',\n",
       " 'why is aeco basis so low on the list?  Is NWPL mapped differently than AECO?What about the correlation to Nymex on AECO?',\n",
       " 'Jeff,You would clearly receive a commission on a deal on the sagewood.I am surprised by your request for payment on any type of project in whichI might become involved with Creekside.  Are you in the business of brokeringproperties or contacts?  Is your position based on a legal or what youperceive to be an ethical issue?  Did you propose we look at developing aproject from scratch?I am not prepared to pay more than 2.7 for sagewood yet.Phillip',\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/08/2000Please respond to <cbpres@austin.rr.com><invest@bga.com>I was aware that Regan Lehman, the lot developer for the entire 70 lotduplex project, was selling his units in the $180's,  He does have a muchlower basis in the lots than anyone else, but the prime differences are dueto a) he is selling them during construction and b) they are smaller units.We do not know the exact size of each of his units, but we believe one ofthe duplexes is a 1164/1302 sq ft. plan.  This would produce an average sqfootage of 1233, which would be $73.80 psf at $182,000.  (I thought hissales price was $187,000.)  At this price psf our 1,376 sf unit would sellfor $203,108.What is more important, in my view, is a) the rental rate and b) therent-ability.  You have all of our current rental and cost data for your ownevaluation.  As for rent-ability, I believe that we have shown that the3-bedroom, 3.5 bath is strongly preferred in this market.    In fact, if wewere able to purchase additional lots from Regan we would build 4 bedroomunits along with the 3-bedroom plan.Phillip, I will call you today to go over this more thoroughly.Sincerely,George W. RichardsCreekside Builders, LLC\",\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/08/2000Please respond to <cbpres@austin.rr.com>Enclosed is the preliminary proforma for the Westgate property is Austinthat we told you about.  As you can tell from the proforma this projectshould produce a truly exceptional return of over 40% per year over 3 years.This is especially attractive when the project is in a market as strong asAustin and we are introducing new product that in a very low price range forthis market.  This is the best project in terms of risk and reward that wehave uncovered to date in the Austin market.The project does have approved zoning and will only require a site plan.  Asit is in the \"Smart Growth Corridor\" area designated by the City of Austinfor preferred development, this will be fast tracked and should be completein less than 6 months.  Additionally, many of the current and more severewater treatment ordinances have been waived.  I have estimated the lotimprovement costs based on a 28 lot development we investigated in NorthAustin, which included a detention/retention and filtration pond and streetwidening.  Even though this property is not likely to require streetwidening and will have less of a detention/retention and filtration pondrequirement, I used this data to be cautious.The Lone Star gas line easement in the lower portion of the property is notexpected to impact sales significantly.  Other projects have been quitesuccessful with identical relationships to this pipeline, such as theadjoining single family residential and a project at St. Edwards University.As with most infill projects, the quality of the surrounding neighborhoodsis uneven.  We have included a fence around the entire property, but mayonly put it on Westgate and Cameron Loop.  Gated communities are farpreferred so this is a good idea for both screening and current buyerpreferences.The seller accepted our offer Thursday evening with a price of $680,000 andan extended escrow.  This will enable us to probably obtain an approved siteplan before closing on the contract, which will mean that we can close intoan A&D Loan rather than into a land loan and then an improvement loan.This analysis shows your investment at $700,000 for a 50% interest in theprofits of the project.  As we discussed in San Marcos, we can also discusshaving you invest only in the lots, sell the lots to the construction entitywith your profit in the lot.  I believe this would facilitate the use of a1031 Exchange of the proceeds from this deal into another project that is arental deal or at least into the land for a rental project that would thenbe the equity for that project.  You would need to discuss this with anexchange expert first.  Larry Lewter knows an expert in the field in SanAntonio if you do not know anyone.I will send you a package on the property that was prepared by the broker,by Airborne Express today for Saturday delivery.Once you have read the package and reviewed this proforma, we would want toschedule a tour of the site and the area.  Please get back to me as soon asyour schedule permits regarding the site visit and feel free to call at anytime.  You can reach me over the weekend and in the evening at either512-338-1119 or 512-338-1110.  My cell phone is 512-748-7495 and the fax is512-338-1103.   I look forward to hearing from you and to working with youon this project that is sure to be a major winner.I regret that it took so long to get back to you, but we had some unusualevents these past few weeks.  A small freakish wind storm with severe 60+mpgdowndrafts hit the South part of Austin where we are building 10 town homes.One of these units had just had the roof decked with the siding scheduled tostart the next day.  The severe downdraft hitting the decked roof was enoughto knock it down.  The City shut down the project for a week and it tookanother week to get every thing back on tract.  Then last week I had to takemy wife  to emergency.  She has a bulge in the material between the vertebrain her spine and it causes her extreme pain and has kept her bedridden thispast week..  There is nothing like having your wife incapacitated to realizethe enormous number of things she does everyday.   Fortunately, it looks asif she will be ok in the long run.George W. RichardsCreekside Builders, LLC- Westgate Proforma-Phillip Allen.xls',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/06/2000_________________________________________________________________________Share information about yourself, create your own public profile at- utility.xls- utility.xls',\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/06/2000Executive Impact & Influence Program* IMMEDIATE ACTION REQUIRED - Do Not Delete *As part of the Executive Impact and Influence Program, each participantis asked to gather input on the participant's own management styles andpractices as experienced by their immediate manager, each direct report,and up to eight peers/colleagues.You have been requested to provide feedback for a participant attendingthe next program.  Your input (i.e., a Self assessment, Manager assessment,Direct Report assessment, or Peer/Colleague assessment) will be combinedwith the input of others and used by the program participant to develop anaction plan to improve his/her management styles and practices.It is important that you complete this assessmentNO LATER THAN CLOSE OF BUSINESS Thursday, September 14.Since the feedback is such an important part of the program, the participantwill be asked to cancel his/her attendance if not enough feedback isreceived.  Therefore, your feedback is critical.To complete your assessment, please click on the following link or simplyUnique ID - ParticipantEVH3JY - John ArnoldER93FX - John LavoratoEPEXWX - Hunter ShivelyIf you experience technical problems, please call Dennis Ward atFSD Data Services, 713-942-8436.  If you have any questions about thisprocess,you may contact Debbie Nowak at Enron, 713-853-3304, or Christi Smith atKeilty, Goldsmith & Company, 858-450-2554.Thank you for your participation.\",\n",
       " \"Larry,Just a note to touch base on the sagewood townhomes and other developmentopportunities.I stumbled across some other duplexes for sale on the same street. that werebuilt by Reagan Lehmann.  22 Units were sold foraround $2 million. ($182,000/duplex).  I spoke to Reagan and he indicatedthat he had more units under construction that would beavailable in the 180's.  Are the units he is selling significantly differentfrom yours?  He mentioned some of the units are the 1308 floorplan.  My bid of 2.7 million is almost $193,000/duplex.As far as being an investor in a new project, I am still very interested.Call or email with your thoughts.Phillip\",\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 05/01/2001 0=Outlook Migration Team@ENRONerter/NA/Enron@Enron, Brian Ellis/Corp/Enron@Enron, Charles Philpott/HR/Cor=p/Enron@ENRON, Chris P Wood/NA/Enron@Enron, Chris Tull/HOU/ECT@ECT, Dale Sm=ith/Corp/Enron@ENRON, Dave June/NA/Enron@ENRON, Donald Sutton/NA/Enron@Enro=n, Felicia Buenrostro/HR/Corp/Enron@ENRON, Johnna Morrison/Corp/Enron@ENRON=, Joe Dorn/Corp/Enron@ENRON, Kathryn Schultea/HR/Corp/Enron@ENRON, Leon McD=owell/NA/Enron@ENRON, Leticia Barrios/Corp/Enron@ENRON, Milton Brown/HR/Cor=p/Enron@ENRON, Raj Perubhatla/Corp/Enron@Enron, Shekar Komatireddy/NA/Enron=@Enron, Andrea Yowman/Corp/Enron@ENRON, Angie O\\'Brian/HR/Corp/Enron@ENRON, =Bonne Castellano/HR/Corp/Enron@ENRON, Gwynn Gorsuch/NA/Enron@ENRON, Jo Ann =Matson/Corp/Enron@ENRON, LaQuitta Washington/HR/Corp/Enron@ENRON, Rick John=son/HR/Corp/Enron@ENRON, Sandra Lighthill/HR/Corp/Enron@ENRON, Valeria A Ho=pe/HOU/ECT@ECT, Charlotte Brown/HR/Corp/Enron@ENRON, Ronald Fain/HR/Corp/En=ron@ENRON, Gary Fitch/HR/Corp/Enron@Enron, Anna Harris/HR/Corp/Enron@ENRON,=Keith Jones/HR/Corp/Enron@ENRON, Kristi Monson/NA/Enron@Enron, Bobbie McNi=el/HR/Corp/Enron@ENRON, John Stabler/HR/Corp/Enron@ENRON, Michelle Prince/N=A/Enron@Enron, James Gramke/NA/Enron@ENRON, Blair Hicks/NA/Enron@ENRON, Jen=nifer Johnson/Contractor/Enron Communications@Enron Communications, Jim Lit=tle/Enron@EnronXGate, Dale Lukert/NA/Enron@ENRON, Donald Martin/NA/Enron@EN=RON, Andrew Mattei/NA/Enron@ENRON, Darvin Mitchell/NA/Enron@ENRON, Mark Old=ham/NA/Enron@ENRON, Wesley Pearson/NA/Enron@ENRON, Ramon Pizarro/ENRON_DEVE=LOPMENT@ENRON_DEVELOPMENT, Natalie Rau/NA/Enron@ENRON, William Redick/NA/En=ron@ENRON, Mark A Richardson/NA/Enron@ENRON, Joseph Schnieders/NA/Enron@ENR=ON, Gary Simmons/NA/Enron@Enron, Delaney Trimble/NA/Enron@ENRON, David Upto=n/NA/Enron@ENRON, Mike Boegler/HR/Corp/Enron@ENRON, Lyndel Click/HR/Corp/En=ron@ENRON, Gabriel Franco/NA/Enron@Enron, Randy Gross/HR/Corp/Enron@Enron, =Arthur Johnson/HR/Corp/Enron@Enron, Danny Jones/HR/Corp/Enron@ENRON, John O=gden/Houston/Eott@Eott, Edgar Ponce/NA/Enron@Enron, Tracy Pursifull/HR/Corp=/Enron@ENRON, Lance Stanley/HR/Corp/Enron@ENRON, Frank Ermis/HOU/ECT@ECT, J=ane M Tholt/HOU/ECT@ECT, Jay Reitmeyer/HOU/ECT@ECT, Keith Holst/HOU/ECT@ect=, Matthew Lenhart/HOU/ECT@ECT, Mike Grigsby/HOU/ECT@ECT, Monique Sanchez/HO=U/ECT@ECT, Phillip K Allen/HOU/ECT@ECT, Randall L Gay/HOU/ECT@ECT, Tori Kuy=kendall/HOU/ECT@ECT, Brenda H Fletcher/HOU/ECT@ECT, Jeanne Wukasch/Corp/Enr=on@ENRON, Mary Theresa Franklin/HOU/ECT@ECT, Mike Potter/NA/Enron@Enron, Na=talie Baker/HOU/ECT@ECT, Suzanne Calcagno/NA/Enron@Enron, Alvin Thompson/Co=rp/Enron@Enron, Cynthia Franklin/Corp/Enron@ENRON, Jesse Villarreal/HOU/ECT=@ECT, Joan Collins/HOU/EES@EES, Joe A Casas/HOU/ECT@ECT, Kelly Loocke/ENRON=@enronXgate, Lia Halstead/NA/Enron@ENRON, Meredith Homco/HOU/ECT@ECT, Rober=t Allwein/HOU/ECT@ECT, Scott Loving/NA/Enron@ENRON, Shanna Boudreaux/ENRON@=enronXgate, Steve Gillespie/Corp/Enron@ENRON, Tamara Carter/NA/Enron@ENRON,=Tracy Wood/NA/Enron@ENRON, Gabriel Fuzat/Enron Communications@Enron Commun=ications, Jack Netek/Enron Communications@Enron Communications, Lam Nguyen/=NA/Enron@Enron, Camille Gerard/Corp/Enron@ENRON, Craig Taylor/HOU/ECT@ECT, =Jessica Hangach/NYC/MGUSA@MGUSA, Kathy Gagel/NYC/MGUSA@MGUSA, Lisa Goulart/=NYC/MGUSA@MGUSA, Ruth Balladares/NYC/MGUSA@MGUSA, Sid Strutt/NYC/MGUSA@MGUS=AREASONS FOR USING OUTLOOK WEB ACCESS (OWA)1. Once your mailbox has been migrated from Notes to Outlook, the Outlook c=lient will be configured on your computer.After migration of your mailbox, you will not be able to send or recieve ma=il via Notes, and you will not be able to start using Outlook until it is c=onfigured by the Outlook Migration team the morning after your mailbox is m=igrated.  During this period, you can use Outlook Web Access (OWA) via your=web browser (Internet Explorer 5.0) to read and send mail.o-Do entries imported from Notes will not be available until the Outlook cl=ient is configured on your desktop.2. Remote access to your mailbox.After your Outlook client is configured, you can use Outlook Web Access (OW=A) for remote access to your mailbox.ing to the Enron network (LAN).  There are future plans to make OWA availab=le from your home or when traveling abroad.HOW TO ACCESS OUTLOOK WEB ACCESS (OWA)-msowa01p/exchange/john.doeSubstitute \"john.doe\" with your first and last name, then click ENTER.  You=will be prompted with a sign in box as shown below.  Type in \"corp/your us=er id\" for the user name and your NT password to logon to OWA and click OK.=You will now be able to view your mailbox.=09n the Outlook and OWA clients.  You will not be able to do many of the thin=gs in OWA that you can do in Outlook.  Below is a brief list of *some* of t=-  Tasks-  Journal-  Spell Checker-  Offline Use-  Printing Templates-  Reminders-  Timed Delivery-  Expiration-  Outlook Rules-  Voting, Message Flags and Message Recall-  Sharing Contacts with others-  Task Delegation-  Direct Resource Booking-  Personal Distribution ListsQUESTIONS OR CONCERNS?If you have questions or concerns using the OWA client, please contact the ==09Outlook.2000@enron.com=09713-853-1411Thank you,Outlook 2000 Migration Team',\n",
       " 'Ina,',\n",
       " 'jay.reitmeyer@enron.com, frank.ermis@enron.com---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/06/2000Jeff RichterAM ---------------------------Crandall/PDX/ECT@ECT, Tim Belden/HOU/ECT@ECT, Jeff Richter/HOU/ECT@ECT, JohnM Forney/HOU/ECT@ECT, Matt Motley/PDX/ECT@ECT, Tom Alonso/PDX/ECT@ECT, MarkFischer/PDX/ECT@ECT---------------------------Enron Capital & Trade Resources Corp.Will/HOU/ECT@ECT, Doug Gilbert-Smith/Corp/Enron@ENRON, MikeSwerzbin/HOU/ECT@ECTDo not underestimate the effects of the Internet economy on load growth.  Ihave been preaching the tremendous growth described below for the last year.The utility infrastructure simply cannot handle these loads at thedistribution level and ultimatley distributed generation will be required forpower quality reasons.The City of Austin, TX has experienced 300+ MW of load growth this year dueto server farms and technology companies.  There is a 100 MW server farmtrying to hook up to HL&P as we speak and they cannot deliver for 12 monthsdue to distribution infrastructure issues.  Obviously, Seattle, Porltand,Boise, Denver, San Fran and San Jose in your markets are in for a rudeawakening in the next 2-3 years.---------------------- Forwarded by Kevin M Presto/HOU/ECT on 09/05/2000Enron North America Corp.Broderick/HOU/ECT@ECT, Jeffrey Miller/NA/Enron@EnronPM ---------------------------George HopleyCOMMUNICATIONS@ENRONInternet Data Gain Is a Major Power Drain onLocal Utilities( September 05, 2000 )In 1997, a little-known Silicon Valley company called ExodusCommunications opened a 15,000-square-foot data center inTukwila.The mission was to handle the Internet traffic andcomputer servers for theregion\\'s growing number of dot-coms.Fast-forward to summer 2000. Exodus is now wrapping upconstructionon a new 13-acre, 576,000-square-foot data center less thana mile from itsoriginal facility. Sitting at the confluence of severalfiber optic backbones, theExodus plant will consume enough power for a small town andeventuallyhouse Internet servers for firms such as Avenue A,Microsoft and Onvia.com.Exodus is not the only company building massive datacenters near Seattle.More than a dozen companies -- with names like AboveNet,Globix andHostPro -- are looking for facilities here that will housethe networkingequipment of the Internet economy.It is a big business that could have an effect oneverything from yourmonthly electric bill to the ease with which you accessyour favorite Web sites.Data centers, also known as co-location facilities andserver farms, aresprouting at such a furious pace in Tukwila and the KentValley that somehave expressed concern over whether Seattle City Light andPuget SoundEnergy can handle the power necessary to run these 24-hour,high-securityfacilities.\"We are talking to about half a dozen customers thatare requesting 445megawatts of power in a little area near Southcenter Mall,\"said KarlKarzmar, manager of revenue requirements for Puget SoundEnergy. \"That isthe equivalent of six oil refineries.\"A relatively new phenomenon in the utility business,the rise of the Internetdata center has some utility veterans scratching theirheads.Puget Sound Energy last week asked the WashingtonUtilities andTransportation Commission to accept a tariff on the newdata centers. Thetariff is designed to protect the company\\'s existingresidential and businesscustomers from footing the bill for the new base stationsnecessary to supportthe projects. Those base stations could cost as much as $20million each,Karzmar said.Not to be left behind, Seattle City Light plans tobring up the data centerissue on Thursday at the Seattle City Council meeting.For the utilities that provide power to homes,businesses and schools in theregion, this is a new and complex issue.On one hand, the data centers -- with their amazingappetite for power --represent potentially lucrative business customers. Thefacilities run 24 hours aday, seven days a week, and therefore could become aconstant revenuestream. On the other hand, they require so much energy thatthey couldpotentially flood the utilities with exorbitant capitalexpenditures.Who will pay for those expenditures and what it willmean for power ratesin the area is still open to debate.\"These facilities are what we call extremely denseloads,\" said Bob Royer,director of communications and public affairs at SeattleCity Light.\"The entire University of Washington, from stadiumlights at the footballgame to the Medical School, averages 31 megawatts per day.We have datacenter projects in front of us that are asking for 30, 40and 50 megawatts.\"With more than 1.5 million square feet, the Intergatecomplex in Tukwila isone of the biggest data centers. Sabey Corp. re-purchasedthe 1.35 millionsquare-foot Intergate East facility last September fromBoeing Space &Defense. In less than 12 months, the developer has leased92 percent of thesix-building complex to seven different co-locationcompanies.\"It is probably the largest data center park in thecountry,\" boasts LaurentPoole, chief operating officer at Sabey. Exodus, ICGCommunications,NetStream Communications, Pac West Telecomm and ZamaNetworks alllease space in the office park.After building Exodus\\' first Tukwila facility in 1997,Sabey has become anexpert in the arena and now has facilities either undermanagement ordevelopment in Los Angeles, Spokane and Denver. Pooleclaims his firm isone of the top four builders of Internet data centers inthe country.As more people access the Internet and conductbandwidth-heavy taskssuch as listening to online music, Poole said the need forco-location space inSeattle continues to escalate.But it is not just Seattle. The need for data centerspace is growing at arapid clip at many technology hubs throughout the country,causing similarconcerns among utilities in places such as Texas andCalifornia.Exodus, one of the largest providers of co-locationspace, plans to nearlydouble the amount of space it has by the end of the year.While companiessuch as Amazon.com run their own server farms, manyhigh-tech companieshave decided to outsource the operations to companies suchas Exodus thatmay be better prepared for dealing with Internet trafficmanagement.\"We have 2 million square feet of space underconstruction and we plan todouble our size in the next nine months , yet there is moredemand right nowthan data center space,\" said Steve Porter, an accountexecutive at Exodus inSeattle.The booming market for co-location space has left somein the local utilityindustry perplexed.\"It accelerates in a quantum way what you have to doto serve the growth,\"said Seattle City Light\\'s Royer. \"The utility industry isalmost stunned by this, ina way.\"',\n",
       " \"Ina,Can you pull Tori K.'s and Martin Cuilla's resumes and past performancereviews from H.R.---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/06/2000John J Lavorato@ENRONThe commercial support people that you and Hunter want to make commercialmanagers.\",\n",
       " 'resumes of whom?',\n",
       " \"Program---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/05/2000Please respond to <christi.smith@lrinet.com>ProgramWe have not received your completed Team Selection information.  It isimperative that we receive your team's information (email, phone number,office) asap.  We cannot start your administration without this information,and your raters will have less time to provide feedback for you.Thank you for your assistance.Christi-----Original Message-----ProgramHi Phillip.  We appreciate your prompt attention and completing the TeamSelection information.Ideally, we needed to receive your team of raters on the Team Selection formwe sent you.  The information needed is then easily transferred into thedatabase directly from that Excel spreadsheet.  If you do not have theability to complete that form, inserting what you listed below, we stillrequire additional information.We need each person's email address.  Without the email address, we cannotemail them their internet link and ID to provide feedback for you, nor canwe send them an automatic reminder via email.  It would also be good to haveeach person's phone number, in the event we need to reach them.So, we do need to receive that complete TS Excel spreadsheet, or if you needto instead, provide the needed information via email.Thank you for your assistance Phillip.Christi L. SmithProject Manager for Client ServicesKeilty, Goldsmith & Company858/450-2554-----Original Message-----John Lavorato-MMike Grigsby-DKeith Holst-DFrank Ermis-DSteve South-DJanie Tholt-DScott Neal-PHunter Shively-PTom Martin-PJohn Arnold-P\",\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/05/2000Mark,Here is a spreadsheet detailing our September Socal trades. (I did notdistinguish between buys vs. sells.)Phillip',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/01/2000Enron North America Corp.--- Ray Niles on Price Caps.pdf',\n",
       " 'Richard,Compare your california production to the numbers in the 2000 California GasReport.  It shows 410.  But again that might be just what the two utilitiesreceive.',\n",
       " 'Cooper,Can you give access to the new west power site to Jay Reitmeyer.  He is ananalyst in our group.Phillip',\n",
       " \"Program---------------------- Forwarded by Phillip K Allen/HOU/ECT on 08/31/2000Please respond to <christi.smith@lrinet.com><debe@fsddatasvc.com>Hi Phillip.  We appreciate your prompt attention and completing the TeamSelection information.Ideally, we needed to receive your team of raters on the Team Selection formwe sent you.  The information needed is then easily transferred into thedatabase directly from that Excel spreadsheet.  If you do not have theability to complete that form, inserting what you listed below, we stillrequire additional information.We need each person's email address.  Without the email address, we cannotemail them their internet link and ID to provide feedback for you, nor canwe send them an automatic reminder via email.  It would also be good to haveeach person's phone number, in the event we need to reach them.So, we do need to receive that complete TS Excel spreadsheet, or if you needto instead, provide the needed information via email.Thank you for your assistance Phillip.Christi L. SmithProject Manager for Client ServicesKeilty, Goldsmith & Company858/450-2554-----Original Message-----John Lavorato-MMike Grigsby-DKeith Holst-DFrank Ermis-DSteve South-DJanie Tholt-DScott Neal-PHunter Shively-PTom Martin-PJohn Arnold-P\",\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 05/01/2001 0=Outlook Migration Team@ENRONerter/NA/Enron@Enron, Brian Ellis/Corp/Enron@Enron, Charles Philpott/HR/Cor=p/Enron@ENRON, Chris P Wood/NA/Enron@Enron, Chris Tull/HOU/ECT@ECT, Dale Sm=ith/Corp/Enron@ENRON, Dave June/NA/Enron@ENRON, Donald Sutton/NA/Enron@Enro=n, Felicia Buenrostro/HR/Corp/Enron@ENRON, Johnna Morrison/Corp/Enron@ENRON=, Joe Dorn/Corp/Enron@ENRON, Kathryn Schultea/HR/Corp/Enron@ENRON, Leon McD=owell/NA/Enron@ENRON, Leticia Barrios/Corp/Enron@ENRON, Milton Brown/HR/Cor=p/Enron@ENRON, Raj Perubhatla/Corp/Enron@Enron, Shekar Komatireddy/NA/Enron=@Enron, Andrea Yowman/Corp/Enron@ENRON, Angie O'Brian/HR/Corp/Enron@ENRON, =Bonne Castellano/HR/Corp/Enron@ENRON, Gwynn Gorsuch/NA/Enron@ENRON, Jo Ann =Matson/Corp/Enron@ENRON, LaQuitta Washington/HR/Corp/Enron@ENRON, Rick John=son/HR/Corp/Enron@ENRON, Sandra Lighthill/HR/Corp/Enron@ENRON, Valeria A Ho=pe/HOU/ECT@ECT, Charlotte Brown/HR/Corp/Enron@ENRON, Ronald Fain/HR/Corp/En=ron@ENRON, Gary Fitch/HR/Corp/Enron@Enron, Anna Harris/HR/Corp/Enron@ENRON,=Keith Jones/HR/Corp/Enron@ENRON, Kristi Monson/NA/Enron@Enron, Bobbie McNi=el/HR/Corp/Enron@ENRON, John Stabler/HR/Corp/Enron@ENRON, Michelle Prince/N=A/Enron@Enron, James Gramke/NA/Enron@ENRON, Blair Hicks/NA/Enron@ENRON, Jen=nifer Johnson/Contractor/Enron Communications@Enron Communications, Jim Lit=tle/Enron@EnronXGate, Dale Lukert/NA/Enron@ENRON, Donald Martin/NA/Enron@EN=RON, Andrew Mattei/NA/Enron@ENRON, Darvin Mitchell/NA/Enron@ENRON, Mark Old=ham/NA/Enron@ENRON, Wesley Pearson/NA/Enron@ENRON, Ramon Pizarro/ENRON_DEVE=LOPMENT@ENRON_DEVELOPMENT, Natalie Rau/NA/Enron@ENRON, William Redick/NA/En=ron@ENRON, Mark A Richardson/NA/Enron@ENRON, Joseph Schnieders/NA/Enron@ENR=ON, Gary Simmons/NA/Enron@Enron, Delaney Trimble/NA/Enron@ENRON, David Upto=n/NA/Enron@ENRON, Mike Boegler/HR/Corp/Enron@ENRON, Lyndel Click/HR/Corp/En=ron@ENRON, Gabriel Franco/NA/Enron@Enron, Randy Gross/HR/Corp/Enron@Enron, =Arthur Johnson/HR/Corp/Enron@Enron, Danny Jones/HR/Corp/Enron@ENRON, John O=gden/Houston/Eott@Eott, Edgar Ponce/NA/Enron@Enron, Tracy Pursifull/HR/Corp=/Enron@ENRON, Lance Stanley/HR/Corp/Enron@ENRON, Frank Ermis/HOU/ECT@ECT, J=ane M Tholt/HOU/ECT@ECT, Jay Reitmeyer/HOU/ECT@ECT, Keith Holst/HOU/ECT@ect=, Matthew Lenhart/HOU/ECT@ECT, Mike Grigsby/HOU/ECT@ECT, Monique Sanchez/HO=U/ECT@ECT, Phillip K Allen/HOU/ECT@ECT, Randall L Gay/HOU/ECT@ECT, Tori Kuy=kendall/HOU/ECT@ECT, Brenda H Fletcher/HOU/ECT@ECT, Jeanne Wukasch/Corp/Enr=on@ENRON, Mary Theresa Franklin/HOU/ECT@ECT, Mike Potter/NA/Enron@Enron, Na=talie Baker/HOU/ECT@ECT, Suzanne Calcagno/NA/Enron@Enron, Alvin Thompson/Co=rp/Enron@Enron, Cynthia Franklin/Corp/Enron@ENRON, Jesse Villarreal/HOU/ECT=@ECT, Joan Collins/HOU/EES@EES, Joe A Casas/HOU/ECT@ECT, Kelly Loocke/ENRON=@enronXgate, Lia Halstead/NA/Enron@ENRON, Meredith Homco/HOU/ECT@ECT, Rober=t Allwein/HOU/ECT@ECT, Scott Loving/NA/Enron@ENRON, Shanna Boudreaux/ENRON@=enronXgate, Steve Gillespie/Corp/Enron@ENRON, Tamara Carter/NA/Enron@ENRON,=Tracy Wood/NA/Enron@ENRON, Gabriel Fuzat/Enron Communications@Enron Commun=ications, Jack Netek/Enron Communications@Enron Communications, Lam Nguyen/=NA/Enron@Enron, Camille Gerard/Corp/Enron@ENRON, Craig Taylor/HOU/ECT@ECT, =Jessica Hangach/NYC/MGUSA@MGUSA, Kathy Gagel/NYC/MGUSA@MGUSA, Lisa Goulart/=NYC/MGUSA@MGUSA, Ruth Balladares/NYC/MGUSA@MGUSA, Sid Strutt/NYC/MGUSA@MGUS=ATo ensure that you experience a successful migration from Notes to Outlook,=it is necessary to gather individual user information prior to your date o=f migration.  Please take a few minutes to completely fill out the followin=g survey.  When you finish, simply click on the 'Reply' button then hit 'Se=nd'  Your survey will automatically be sent to the Outlook 2000 Migration M=ailbox.Thank you.Outlook 2000 Migration Team---------------------------------------------------------------------------=-----------------------------------------------------------------What type of computer do you have?  (Desktop,  Laptop,  Both) =20t, Jornada) =20Do you have permission to access anyone's Email/Calendar? =20If yes, who? =20Does anyone have permission to access your Email/Calendar? =20If yes, who? =20Are you responsible for updating anyone else's address book? =20If yes, who? =20Is anyone else responsible for updating your address book? =20If yes, who? =20Do you have access to a shared calendar? =20If yes, which shared calendar? =20Do you have any Distribution Groups that Messaging maintains for you (for m=ass mailings)? =20In our efforts to plan the exact date/time of your migration, we also will =Will you be out of the office in the near future for vacation, leave, etc?\",\n",
       " 'John Lavorato-MMike Grigsby-DKeith Holst-DFrank Ermis-DSteve South-DJanie Tholt-DScott Neal-PHunter Shively-PTom Martin-PJohn Arnold-P',\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 08/31/2000Mark,Here is a spreadsheet detailing our September Socal trades. (I did notdistinguish between buys vs. sells.)Phillip',\n",
       " 'Greg,Got your message.  Good luck on the bike ride.What were you doing to your apartment?  Are you setting up a studio?The kids are back in school.  Otherwise just work is going on here.Keith',\n",
       " 'Why are his requests coming to me?',\n",
       " 'Mark,Here is a spreadsheet detailing our September Socal trades. (I did notdistinguish between buys vs. sells.)Phillip',\n",
       " 'Mark,Were you able to log in to enron online and find socal today?I will follow up with a list of our physical deals done yesterday and today.Phillip',\n",
       " 'BrendaCan you send me your address in College Station.Phillip',\n",
       " 'frank.ermis@enron.com, jay.reitmeyer@enron.com---------------------- Forwarded by Phillip K Allen/HOU/ECT on 08/28/2000Kristian J LandeVickers/HOU/ECT@ECT, Elliot Mainzer/PDX/ECT@ECT, Michael McDonald/SF/ECT@ECT,David Parquet/SF/ECT@ECT, Laird Dyer/SF/ECT@ECT, Jim Buerkle/PDX/ECT@ECT, JimGilbert/PDX/ECT@ECT, Terry W Donovan/HOU/ECT@ECT, Jeff GSlaughter/ENRON_DEVELOPMENT@ENRON_DEVELOPMENT, Ed Clark/PDX/ECT@ECTMotley/PDX/ECT@ECT, Phillip K Allen/HOU/ECT@ECTSorry,Report as of August 24, 2000',\n",
       " 'Mark,The following is a guest password that will allow you temporary view onlyaccess to EnronOnline.  Please note, the user ID and password are CASESENSITIVE.Log in to www.enrononline.com and install shockwave using instructionsbelow.  I have set up a composite page with western basis and cash prices tohelp you filter through the products.  The title of the composite page isMark\\'s Page.  If you have any problems logging in you can call me at(713)853-7041 or Kathy Moore, EnronOnline HelpDesk, 713/853-HELP (4357).The Shockwave installer can be found within \"About EnronOnline\" on the homepage.  After opening \"About EnronOnline\", using right scroll bar, go to thebottom.  Click on \"download Shockwave\" and follow the directions.  Afterloading Shockwave, shut down and reopen browser (i.e. Microsoft InternetExplorer/Netscape).I hope you will find this site useful.Sincerely,Phillip Allen',\n",
       " 'Mark,Attached is a spreadsheet that lists the end of day midmarkets for socalbasis and socal/san juan spreads.  I listed the days during bidweek thatreflected financial trading for Socal Index and the actual gas daily printsbefore and after bidweek.July 1.  The basis market  anticipated a Socal/San Juan spread of .81 vsactual of .792.  Perceived index was 4.95 vs actual of 4.913.  Socal Gas Daily Swaps are trading at a significant premium.Aug. 1.  The basis market  anticipated a Socal/San Juan spread of 1.04 vsactual of .992.  Perceived index was 4.54 vs actual of 4.493.  Gas daily spreads were much wider before and after bidweek than themonthly postings4.  Socal Gas Daily Swaps are trading at a significant premium.Enron Online will allow you to monitor the value of financial swaps againstthe index, as well as, spreads to other locations.  Please call with anyquestions.Phillip',\n",
       " 'Alan,You should have received updated numbers from Keith Holst.  Call me if you did not receive them.Phillip',\n",
       " 'Suzanne,Can you give me more details or email  the plan prior to meeting?  What do Ineed to provide besides headcount?Otherwise any afternoon next week would be finePhillip',\n",
       " 'Colleen,Please add Mike Grigsby to the distribution.On another note, do you have any idea how Patti is holding up?Phillip',\n",
       " 'Brad,With regard to Tori Kuykendall, I would like to promote her to commercialmanager instead of converting her from a commercial support manager to anassociate.  Her duties since the beginning of the year have been those of acommercial manager.  I have no doubt that she will compare favorably toothers in that category at year end.Martin Cuilla on the central desk is in a similiar situation as Tori.Hunter would like Martin handled the same as Tori.Let me know if there are any issues.Phillip',\n",
       " 'Bruce,Can you stop by and set up my reuters.Phillip',\n",
       " 'Lucy,The rent roll spreadsheet is starting to look better.  See if you can add1.  Use a formula in column E.  Add the value in column C to column D.  Itshould read =c6+d6.  Then copy this formula to the rows below.2.  Column H needs a formula.  Subtract amount paid from amount owed.=e6-g6.3.  Column F is filled with the #### sign.  this is because the column widthis too narrow.  Use you mouse to click on the line beside theletter F.  Hold the left mouse button down and drag the column wider.4.  After we get the rent part fixed, lets bring the database columns up tothis sheet and place them to the right in columns J and beyond.Phillip',\n",
       " \"Lucy,I got your email with the attachment.  Let's work together today to get thisdonePhillip\",\n",
       " 'you have my approval',\n",
       " 'Lucy,We can discuss your email later.  How is progress on creating thespreadsheets.  You will probably need to close the file before you attach tofiles.Phillip',\n",
       " 'Lucy,Please open this excel file and input the rents and names due for this week.Then email the file back.',\n",
       " 'Open the \"utility\" spreadsheet and try to complete the analysis of whether itis better to be a small commercial or a medium commercial (LP-1).You will need to get the usage for that meter for the last 12 months.  If wehave one year of data, we can tell which will be cheaper.  Use the ratesdescribed in the spreadsheet.  This is a great chance for you to practiceexcel.',\n",
       " 'Alan ComnesPhillip,I got this request.  On the gas side, I think Kean/Lay need an update to a table you prepared for me a few months ago, which I\\'ve attached..  Can you oblige?  Thanks,Alan ComnesJanel Guerrero@ENRONAlan,Steve has asked that you update the power point below so that it reflects all of the \"stupid regulatory/legislative decisions\" since the beginning of the year.  Ken wants to have this updated chart in his briefing book for next week\\'s \"Ken Lay Tour\" to CA.He also wants a forward price curve for both gas and power in CA.  Can we get these three documents by Monday afternoon?',\n",
       " \"Mac,Gas Sales 916,000/day x 365 days = 334,340,000/yearEstimated Gas Prices $985,721,000/334,340,000= $2.95/mcfActual gas prices are around $1.00/mcf higher and rising.(334,340,000 mct X $1/mcf)/116,897,000 shares outst = $2.86 additional EPSX 12 P/E multiple = $34 a shareThat is just a back of the envelope valuation based on gas prices.  I thinkcrude price are undervalued by the tune of $10/share.Current price 37Nat. Gas 34Crude  10Total  81Can you take a look at these numbers and play devil's advocate?  To me thislooks like the best stock to own Also can you send me a report on Calpine,Tosco, and SLB?Thank you,Phillip\",\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 08/20/2000Phillip,We have been working on different apartments today and having tolisten to different, people about what Mary is saying should i be worried?ants seem to be invading my apartment.You got my other fax's Wade is workingon the bulletin board that I need up so that I can let tenants know aboutwhat is going on.Gave #25 a notice about having to many people staying inthat apt and that problem has been resolved.Also I have a tenant in #29 thatis complaining about #28 using fowl language.I sent #28 a lease violation wewill see how that goescall you tomorrowThanx Lucy________________________________________________________________________\",\n",
       " \"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 08/20/2000Phillip,The a/c I bought today for #17 cost $166.71 pd by ck#14298/16/00 at WAL-MART.Also on 8/15/00 Ralph's Appliance Centerck#1428frig & stove for apt #20-B IVOICE # 000119 AMT=308.56 (STOVE=150.00(frig=125.00)DEL CHRG=15.00\\\\TAX=18.56 TOTAL=308.56.FAX MACHINE FORFFICE CK # 1427=108.25 FROM sTEELMAN OFFICE PRODUCTS.                                           Thanxs, Lucy________________________________________________________________________\",\n",
       " '---------------------- Forwarded by Phillip K Allen/HOU/ECT on 08/20/2000Phillip,Today was one of those days because Wade had to go pay his fine andI had to go take him that takes alot of time out of my schedule.If you get achance will you mention to him that he needs to, try to fix his van so ththe can go get what ever he needs. Tomorrow gary is going to be here.I haveto go but Iwill E-Mail you tomorrowLucy________________________________________________________________________',\n",
       " 'I checked into exercising options with Smith Barney, but Enron has some kindof exclusive with Paine Weber.  I am starting to exercise now, but I am goingto use the proceeds to buy another apartment complex.What do you think about selling JDSU and buying SDLI?Also can you look at EOG as a play on rising oil and gas prices.Thanks,Phillip']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = email_df.body.tolist()\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists to store the prefixes and the suffixes\n",
    "prefix_sentences = []\n",
    "suffix_sentences = []\n",
    "\n",
    "# Create one prefix and one suffix at each character of each email\n",
    "for email in corpus:\n",
    "    for index in range(len(email)):\n",
    "        # Find the prefix and suffix\n",
    "        prefix = email[: index+1]\n",
    "        suffix = '\\t' + email[index+1 :] + '\\n'\n",
    "        \n",
    "        # Add the prefix and suffix to the list of prefix and suffix sentences\n",
    "        prefix_sentences.append(prefix)\n",
    "        suffix_sentences.append(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vocabulary with the start and end token\n",
    "vocabulary = set(['\\t', '\\n'])\n",
    "\n",
    "# Iterate for each char in each email\n",
    "for email in corpus:\n",
    "    for char in email:\n",
    "        # Add the char if not in vocabulary, \n",
    "        if (char not in vocabulary):\n",
    "            vocabulary.add(char)            \n",
    "# Sort the vocabulary\n",
    "vocabulary = sorted(vocabulary)\n",
    "\n",
    "# Create char to int and int to char mapping\n",
    "char_to_idx = dict((char, idx) for idx, char in enumerate(vocabulary))\n",
    "idx_to_char = dict((idx, char) for idx, char in enumerate(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the length of the longest prefix\n",
    "max_len_prefix_sent = max([len(prefix) for prefix in prefix_sentences])\n",
    "\n",
    "# Find the length of the longest suffix\n",
    "max_len_suffix_sent = max([len(suffix) for suffix in suffix_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 3-D zero vector for the prefix sentences\n",
    "input_data_prefix = np.zeros((len(prefix_sentences), max_len_prefix_sent,len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Define a 3-D zero vector for the suffix sentences\n",
    "input_data_suffix = np.zeros((len(suffix_sentences), max_len_suffix_sent,len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Define a 3-D zero vector for the target data\n",
    "target_data = np.zeros((len(suffix_sentences), max_len_suffix_sent,len(vocabulary)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(prefix_sentences)):\n",
    "    # Iterate over each character in each prefix\n",
    "    for k, ch in enumerate(prefix_sentences[i]):\n",
    "        # Convert the character to a one-hot encoded vector\n",
    "        input_data_prefix[i, k, char_to_idx[ch]] = 1\n",
    "        \n",
    "    # Iterate over each character in each suffix\n",
    "    for k, ch in enumerate(suffix_sentences[i]):\n",
    "        # Convert the character to a one-hot encoded vector\n",
    "        input_data_suffix[i, k, char_to_idx[ch]] = 1\n",
    "\n",
    "        # Target data is one timestep ahead and excludes start character\n",
    "        if k > 0:\n",
    "            target_data[i, k-1, char_to_idx[ch]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just like the encoder-decoder architecture in the previous use case, \n",
    "    - the encoder accepts the input sequences and summarizes th einformation in its internal state vectors which are used in the decoder as the intial states. \n",
    "    - the encoder is implemented using LSTM and so the states refer to the hidden and cell states from the LSTM layer\n",
    "    - Encoder learns these states from the input sequences. Intuitively, the states consolidate all the useful information from the input sequences need to generate the output sequences\n",
    "    - The encoder output is ignored\n",
    "    - The decoder produces the output sequence\n",
    "    - The final deocder states are ignored\n",
    "    - During training, the input to the decoder are the target sequences\n",
    "    - During inference, the input at each time step is the predicted output from the previous step\n",
    "    \n",
    "    \n",
    "    - The encoder takes the prefixes as input and summarizes the information in its state vectors which are passed to the decoder as the initial states. These state vectors consolidate all the useful information from the prefix sequences which are needed in the decoder to generate the suffix sentences. The decoder takes the suffixes as input. The target sequences from the decoder will be the suffixes, but they will be one time-step ahead and skip the first character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input layer of the encoder\n",
    "encoder_input = Input(shape=(None, len(vocabulary)))\n",
    "\n",
    "# Create LSTM Layer of size 256\n",
    "encoder_LSTM = LSTM(256, return_state = True)\n",
    "\n",
    "# Save encoder output, hidden and cell state\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM(encoder_input)\n",
    "\n",
    "# Save encoder states\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decoder input layer\n",
    "decoder_input = Input(shape=(None, len(vocabulary)))\n",
    "\n",
    "# Create LSTM layer of size 256\n",
    "decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
    "\n",
    "# Save decoder output\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "\n",
    "# Create a `Dense` layer with softmax activation\n",
    "decoder_dense = Dense(len(vocabulary),activation='softmax')\n",
    "\n",
    "# Save the decoder output\n",
    "decoder_out = decoder_dense(decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_out])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Print model summary\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(x=[input_data_prefix, input_data_suffix], y=target_data,\n",
    "          batch_size=64, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autocomplete sentences using inference models\n",
    "\n",
    "- Let's use the trained model for predictions\n",
    "    - Input will be incomplete sentences or prefixes  \n",
    "    - and predictions will be the suffix which completes the sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Create decoder input states for inference\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Get decoder output and feed it to the dense layer for final output prediction\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, initial_state=decoder_input_states)\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "# Create decoder inference model\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states, outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "# Pass input prefix to the Encoder inference model and get the states\n",
    "inp_seq = input_data_prefix[4:5]\n",
    "states_val = encoder_model_inf.predict(inp_seq)\n",
    "\n",
    "# Seed the first character and get output from the decoder \n",
    "target_seq = np.zeros((1, 1, len(vocabulary)))\n",
    "target_seq[0, 0, char_to_idx['\\t']] = 1  \n",
    "decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "\n",
    "# Find out the next character from the Decoder output\n",
    "max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "sampled_suffix_char = idx_to_char[max_val_index]\n",
    "\n",
    "# Print the first character\n",
    "print(sampled_suffix_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n"
     ]
    }
   ],
   "source": [
    "# Insert the generated character from last time to the target sequence \n",
    "target_seq = np.zeros((1, 1, len(vocabulary)))\n",
    "target_seq[0, 0, max_val_index] = 1\n",
    "\n",
    "# Initialize the decoder state to the states from last iteration\n",
    "states_val = [decoder_h, decoder_c]\n",
    "\n",
    "# Get decoder output\n",
    "decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "\n",
    "# Get most probable next character and print it.\n",
    "max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "sampled_suffix_char = idx_to_char[max_val_index]\n",
    "print(sampled_suffix_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suffix_sentence(inp_seq):\n",
    "\n",
    "    # Initialize states value to the final states of the encoder\n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "\n",
    "    # Initialize the target sequence to contain the start token\n",
    "    target_seq = np.zeros((1, 1, len(vocabulary)))\n",
    "    target_seq[0, 0, char_to_idx['\\t']] = 1\n",
    "\n",
    "    # Define a variable to store the suffix sentence\n",
    "    suffix_sent = ''\n",
    "\n",
    "    # Define stop condition flag\n",
    "    stop_condition = False\n",
    "\n",
    "    # Iterate until the end token is found or maximum length of the suffix sentence is reached\n",
    "    while not stop_condition:\n",
    "\n",
    "        # Get output from decoder inference model\n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "\n",
    "        # Get most probable next character\n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_output_char = idx_to_char[max_val_index]\n",
    "\n",
    "        # Append the generated char to the suffix sentence\n",
    "        suffix_sent += sampled_output_char\n",
    "\n",
    "        # Check if end token is encountered or maximum length of the suffix sentence is exceeded\n",
    "        if ((sampled_output_char == '\\n') or (len(suffix_sent) > max_len_suffix_sent)) :\n",
    "            stop_condition = True\n",
    "\n",
    "        # Add the new generated char to the existing target sequence\n",
    "        target_seq = np.zeros((1, 1, len(vocabulary)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "\n",
    "        # Save state values to use in the next iteration\n",
    "        states_val = [decoder_h, decoder_c]\n",
    "\n",
    "    # Return the suffix sentence\n",
    "    return suffix_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix Sentence: h\n",
      "Suffix Sentence: ttp:www.denverpost.combroncosbrnx0408sa.htm\n",
      "Prefix Sentence: he\n",
      "Suffix Sentence: y: do you have jp's email address?\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 suffixes\n",
    "for seq_index in range(2):\n",
    "  \n",
    "    # Get the next tokenized sentence\n",
    "    inp_seq = input_data_prefix[seq_index:seq_index+1]\n",
    "    \n",
    "    # Generate the suffix sentence\n",
    "    suffix_sent = generate_suffix_sentence(inp_seq)\n",
    "    \n",
    "    # Print the prefix sentence\n",
    "    print('Prefix Sentence:', prefix_sentences[seq_index])\n",
    "    \n",
    "    # Print the suffix sentence\n",
    "    print('Suffix Sentence:', suffix_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy of the model can be improved by\n",
    "    - increasing the model complexity\n",
    "    - training for more epochs\n",
    "    - training with bigger dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
